
@article{jiang_gesfabri_2022,
	title = {{GesFabri}: {Exploring} {Affordances} and {Experience} of {Textile} {Interfaces} for {Gesture}-based {Interaction}},
	volume = {6},
	shorttitle = {{GesFabri}},
	url = {https://doi.org/10.1145/3534522},
	doi = {10.1145/3534522},
	abstract = {Textile interfaces are of interest to ubiquitous computing as they are easy to carry and manipulate. However, interesting questions remain about what type of natural gestures people make when interacting with textile interfaces and their emotional response to this interaction. We introduce GesFabri, a set of five interactive textile interfaces with distinct textures, created to investigate the intuitive interaction gestures and accompanied the emotional experience. This research sought to (1) design textile interfaces with intuitive gesture affordance, (2) explore the emotional effects of the developed gesture-based interfaces under four feedback modes (touch-only, visual feedback, audio feedback, multisensory feedback). The experimental results verify our hypotheses that (1) textile texture could provide natural gesture affordances; (2) the GesFabri interfaces' feedback mode was the main factor in the differences of emotional valence, arousal, GSR; and (3) both gesture-based interaction on textiles and the feedback mode had an impact on user emotions. These results highlight the gesture affordances of the e-textile interfaces and contribute to a better understanding of the user experience when interacting with gesture-based textile interfaces.},
	number = {EICS},
	urldate = {2024-11-18},
	journal = {Proc. ACM Hum.-Comput. Interact.},
	author = {Jiang, Mengqi and Nanjappan, Vijayakumar and Liang, Hai-Ning and ten Bhömer, Martijn},
	month = jun,
	year = {2022},
	keywords = {Read},
	pages = {168:1--168:23},
	file = {Notes - GesFabri_ Exploring Affordances and Experience of Textile Interfaces for Gesture-based Interaction:C\:\\Users\\giand\\Zotero\\storage\\XIHFXVJJ\\Notes - GesFabri_ Exploring Affordances and Experience of Textile Interfaces for Gesture-based Interaction.pdf:application/pdf;PDF:C\:\\Users\\giand\\Zotero\\storage\\UJ7DE846\\GesFabri_ Exploring Affordances and Experience of Textile Interfaces for Gesture-based Interaction.pdf:application/pdf},
}

@inproceedings{dong_disappearing_2019,
	address = {Utrecht Netherlands},
	title = {Disappearing textile interface with inherent feedforwards},
	isbn = {978-1-4503-6920-6},
	url = {https://dl.acm.org/doi/10.1145/3349263.3349598},
	doi = {10.1145/3349263.3349598},
	abstract = {Currently, interactive devices can easily disappear into a wide range of physical context due to the development of microcontrollers, sensors and actuators. However, this disappearing interaction scenario may cause confusion to the users regarding where and how to interact with it. Therefore, a research project has been conducted to investigate different inherent feedforwards for this disappearing interaction scenario in textile surfaces. A Tangible User Interface (TUI) for volume adjusting was designed, which can provide both visual and shape-changing feedforwards. This interface can be implemented in ubiquitous soft surfaces, in this demo, a textile-based Human-Machine Interaction (HMI) in the vehicle seat. The textile interface provides a both natural and enjoyable HMI concept. This report describes the theoretical background, prototype, user test and demo setup and contribution.},
	language = {en},
	urldate = {2024-11-18},
	booktitle = {Proceedings of the 11th {International} {Conference} on {Automotive} {User} {Interfaces} and {Interactive} {Vehicular} {Applications}: {Adjunct} {Proceedings}},
	publisher = {ACM},
	author = {Dong, Haoyu},
	month = sep,
	year = {2019},
	keywords = {Read},
	pages = {489--493},
	file = {Notes - Disappearing textile interface with inherent feedforwards:C\:\\Users\\giand\\Zotero\\storage\\6FMG49NW\\Notes - Disappearing textile interface with inherent feedforwards.pdf:application/pdf;PDF:C\:\\Users\\giand\\Zotero\\storage\\VX243R72\\Disappearing textile interface with inherent feedforwards.pdf:application/pdf},
}

@inproceedings{khorsandi_fabricar_2023,
	address = {Pittsburgh PA USA},
	title = {{FabriCar}: {Enriching} the {User} {Experience} of {In}-{Car} {Media} {Interactions} with {Ubiquitous} {Vehicle} {Interiors} using {E}-textile {Sensors}},
	isbn = {978-1-4503-9893-0},
	shorttitle = {{FabriCar}},
	url = {https://dl.acm.org/doi/10.1145/3563657.3595988},
	doi = {10.1145/3563657.3595988},
	abstract = {This work explores e-textiles in the design space of Human-Vehicle Interaction (HVI) and compares distraction levels between e-textile and screen-based interactions during driving tasks. We developed three prototypes (in the steering wheel, headrest cover, and seat-belt pad) to support tactile interactions (tap, press, and swipe) with car interior elements for non-driving applications (such as media control). Our designs used digital embroidery to achieve aesthetic design qualities and wireless connection. In a deployment study with 16 participants, we collected quantitative and qualitative data through video recording, field observations, and user interviews. The study repeated all scenarios using screen-based interaction for comparison. Our findings present insights into fabric-based sensors including fewer collisions and a 302.7\% decrease in eye distraction. These findings suggest new design opportunities, such as retrofitting existing vehicles, designing ideation toolkits for diverse users, devising an e-textile Fitts’ Law for reachability, and expanding vehicle interaction research within the HCI community.},
	language = {en},
	urldate = {2024-11-18},
	booktitle = {Proceedings of the 2023 {ACM} {Designing} {Interactive} {Systems} {Conference}},
	publisher = {ACM},
	author = {Khorsandi, Pouya M and Jones, Lee and Davoodnia, Vandad and Lampen, Timothy J and Conrad, Aliya and Etemad, Ali and Nabil, Sara},
	month = jul,
	year = {2023},
	keywords = {Read, in-vehicle interactions, Important, non-wearable},
	pages = {1438--1456},
	file = {Full Text:C\:\\Users\\giand\\Zotero\\storage\\6342T3ES\\Khorsandi et al. - 2023 - FabriCar Enriching the User Experience of In-Car Media Interactions with Ubiquitous Vehicle Interio.pdf:application/pdf;Notes - FabriCar_ Enriching the User Experience of In-Car Media Interactions with Ubiquitous Vehicle Interiors using E-textile Sensors (1):C\:\\Users\\giand\\Zotero\\storage\\CTXLSVHX\\Notes - FabriCar_ Enriching the User Experience of In-Car Media Interactions with Ubiquitous Vehicle Interiors using E-textile Sensors (1).pdf:application/pdf},
}

@article{khorsandi_interactive_nodate,
	title = {Interactive {Interior} {Spaces} in {Cars} using e-textiles},
	abstract = {Future vehicles are envisioned to enable much more functions than mere transportation and -with the rise of automated vehicles- cars will be living spaces that support an array of activities beyond driving. While current research mostly focuses on user interaction with in-car systems to enhance usability, performance and functionality, we focus on enhancing experience of users and the aspects of enjoying non-driving activities by using e-textiles. This paper introduces e-textiles (i.e. fabric-based sensors, circuits and actuators) to the design space of human-vehicle interaction (HVI) to enrich user experience within car interiors. Through this research, we aim to introduce a new modality to in-car interactions through e-textiles and design user interfaces for drivers and passengers according to user experience goals.},
	language = {en},
	author = {Khorsandi, Pouya M and Nabil, Sara},
	keywords = {Started Reading/Skimmed, Not important},
	file = {PDF:C\:\\Users\\giand\\Zotero\\storage\\EAWJNQM5\\Khorsandi - Interactive Interior Spaces in Cars using e-textiles.pdf:application/pdf;Poster - Interactive Interior Spaces in Cars using e-textiles:C\:\\Users\\giand\\Zotero\\storage\\LTHS67GL\\Poster - Interactive Interior Spaces in Cars using e-textiles.pdf:application/pdf},
}

@incollection{denning_coming_1997,
	address = {New York, NY},
	title = {The {Coming} {Age} of {Calm} {Technology}},
	isbn = {978-0-387-98588-6 978-1-4612-0685-9},
	url = {http://link.springer.com/10.1007/978-1-4612-0685-9_6},
	language = {en},
	urldate = {2024-11-19},
	booktitle = {Beyond {Calculation}},
	publisher = {Springer New York},
	author = {Weiser, Mark and Brown, John Seely},
	collaborator = {Denning, Peter J. and Metcalfe, Robert M.},
	year = {1997},
	doi = {10.1007/978-1-4612-0685-9\_6},
	keywords = {Read},
	pages = {75--85},
	file = {PDF:C\:\\Users\\giand\\Zotero\\storage\\DJLIE2MV\\Weiser and Brown - 1997 - The Coming Age of Calm Technology.pdf:application/pdf},
}

@inproceedings{schartmuller_automated_2020,
	address = {New York, NY, USA},
	series = {{CHI} {EA} '20},
	title = {Automated {Cars} as {Living} {Rooms} and {Offices}: {Challenges} and {Opportunities}},
	isbn = {978-1-4503-6819-3},
	shorttitle = {Automated {Cars} as {Living} {Rooms} and {Offices}},
	url = {https://dl.acm.org/doi/10.1145/3334480.3381054},
	doi = {10.1145/3334480.3381054},
	abstract = {With increasing automation of the driving task, cars' cockpits are transforming towards living spaces rather than pure modalities of transport. The promise of automated vehicles being individual places for relaxation and productivity while on-the-go, however, requires significant research. Not only safety-critical questions, but also issues related to ergonomic design, human factors for interactive systems, and social aspects have to be investigated. This special interests group presents an opportunity for connecting various CHI communities on these problems, which need to be solved under time-pressure, because automated vehicles are coming - whether or not the HCI-related issues are solved.},
	urldate = {2024-11-19},
	booktitle = {Extended {Abstracts} of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Schartmüller, Clemens and Sarcar, Sayan and Riener, Andreas and Kun, Andrew L. and Shaer, Orit and Boyle, Linda Ng and Iqbal, Shamsi},
	month = apr,
	year = {2020},
	keywords = {Read},
	pages = {1--4},
	file = {Full Text PDF:C\:\\Users\\giand\\Zotero\\storage\\IY2PBM34\\Schartmüller et al. - 2020 - Automated Cars as Living Rooms and Offices Challenges and Opportunities.pdf:application/pdf},
}

@inproceedings{khorsandi_functioning_2022,
	title = {Functioning {E}-{Textile} {Sensors} for {Car} {Infotainment} {Applications}},
	copyright = {https://creativecommons.org/licenses/by/4.0/},
	url = {https://www.mdpi.com/2673-4591/15/1/22},
	doi = {10.3390/engproc2022015022},
	language = {en},
	urldate = {2024-11-19},
	booktitle = {The 3rd {International} {Conference} on the {Challenges}, {Opportunities}, {Innovations} and {Applications} in {Electronic} {Textiles}},
	publisher = {MDPI},
	author = {Khorsandi, Pouya M. and Nousir, Alaa and Nabil, Sara},
	month = jul,
	year = {2022},
	pages = {22},
	file = {Full Text:C\:\\Users\\giand\\Zotero\\storage\\DVV68WI5\\Khorsandi et al. - 2022 - Functioning E-Textile Sensors for Car Infotainment Applications.pdf:application/pdf},
}

@inproceedings{mlakar_design_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Design {Investigation} of {Embroidered} {Interactive} {Elements} on {Non}-{Wearable} {Textile} {Interfaces}},
	isbn = {978-1-4503-6708-0},
	url = {https://dl.acm.org/doi/10.1145/3313831.3376692},
	doi = {10.1145/3313831.3376692},
	abstract = {As smart textiles are becoming more present in our lives, investigating and designing textile interfaces has started getting more and more attention. Still, very little research has been done on how to design interactive elements for non-wearable textile interfaces for the best recognition, perception, and interaction. In this paper, we present initial assumptions for designing such interfaces, which we derived from working intensively with our partners from the industry. These have been further explored with experts from the field during interviews, and finally tested in a user study. As a conclusion of the study, we define five design recommendations for textile interfaces and present several prototypes that demonstrate them in practice. Our recommendations cover tactile contrast between textures, heights, and shapes; minimal recognizable size of elements; perception of concave and convex shapes as interactive elements; indication of interaction through shape; and recognition of tactile symbols.},
	urldate = {2024-11-20},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Mlakar, Sara and Haller, Michael},
	month = apr,
	year = {2020},
	keywords = {Read},
	pages = {1--10},
	file = {Full Text PDF:C\:\\Users\\giand\\Zotero\\storage\\QVR6YGBR\\Mlakar and Haller - 2020 - Design Investigation of Embroidered Interactive Elements on Non-Wearable Textile Interfaces.pdf:application/pdf;Video:C\:\\Users\\giand\\Zotero\\storage\\MJX4X8ZN\\Mlakar and Haller - 2020 - Design Investigation of Embroidered Interactive Elements on Non-Wearable Textile Interfaces.mp4:video/mp4},
}

@inproceedings{mlakar_exploring_2021,
	address = {New York, NY, USA},
	series = {{DIS} '21},
	title = {Exploring {Affordances} of {Surface} {Gestures} on {Textile} {User} {Interfaces}},
	isbn = {978-1-4503-8476-6},
	url = {https://dl.acm.org/doi/10.1145/3461778.3462139},
	doi = {10.1145/3461778.3462139},
	abstract = {This pictorial explores the design space for communicating surface gestures to users of textile interfaces by experimenting with the interfaces’ physical design and affordances. First, we created a collection of functional and non-functional textile samples. Their development was based on three aspects: design, fabrication, and sensing. The design aspect covered different visual (shape, color) and haptic (details, textures) designs, fabrication explored three textile-specific fabrication methods, and electronic sensing offered options for adding touch-sensing capabilities. Second, we reflected on created samples and their characteristics contrasting different designs and speculating on why some work better than others. Our main findings and insights are presented in five clusters: ergonomics, visual affordances, perception of textures, the direction of movement, and the economic usage of design elements. This intermediate-level knowledge can provide a starting point for each professional or novice designer to take inspiration from, when creating their own textile user interfaces.},
	urldate = {2024-11-20},
	booktitle = {Proceedings of the 2021 {ACM} {Designing} {Interactive} {Systems} {Conference}},
	publisher = {Association for Computing Machinery},
	author = {Mlakar, Sara and Alida Haberfellner, Mira and Jetter, Hans-Christian and Haller, Michael},
	month = jun,
	year = {2021},
	keywords = {Read, Important},
	pages = {1159--1170},
	file = {Full Text PDF:C\:\\Users\\giand\\Zotero\\storage\\E9AP66EW\\Mlakar et al. - 2021 - Exploring Affordances of Surface Gestures on Textile User Interfaces.pdf:application/pdf},
}

@inproceedings{nabil_interioractive_2017,
	address = {New York, NY, USA},
	series = {{DIS} '17},
	title = {Interioractive: {Smart} {Materials} in the {Hands} of {Designers} and {Architects} for {Designing} {Interactive} {Interiors}},
	isbn = {978-1-4503-4922-2},
	shorttitle = {Interioractive},
	url = {https://dl.acm.org/doi/10.1145/3064663.3064745},
	doi = {10.1145/3064663.3064745},
	abstract = {The application of Organic User Interface (OUI) technologies will revolutionize interior design, through the development of interactive and actuated surfaces, furnishings and decorative artefacts. However, to adequately explore these new design landscapes we must support multidisciplinary collaboration between Architects, Interior Designers and Technologists. Herein, we present the results of two workshops, with a total of 45 participants from the disciplines of Architecture and Interior Design, supported by a group of HCI researchers. Our objective was to study how design disciplines can productively engage with smart materials as a design resource using an evolving set of techniques to prototype new interactive interior spaces. Our paper reports on our experiences across the two workshops and contributes an understanding of techniques for supporting multidisciplinary collaboration when designing interactive interior spaces.},
	urldate = {2024-11-20},
	booktitle = {Proceedings of the 2017 {Conference} on {Designing} {Interactive} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Nabil, Sara and Kirk, David S. and Plötz, Thomas and Trueman, Julie and Chatting, David and Dereshev, Dmitry and Olivier, Patrick},
	month = jun,
	year = {2017},
	keywords = {Read, home},
	pages = {379--390},
	file = {Full Text PDF:C\:\\Users\\giand\\Zotero\\storage\\PXJ3PZB5\\Nabil et al. - 2017 - Interioractive Smart Materials in the Hands of Designers and Architects for Designing Interactive I.pdf:application/pdf;Notes - Interioractive_ Smart Materials in the Hands of Designers and Architects for Designing Interactive Interiors:C\:\\Users\\giand\\Zotero\\storage\\RDUTNXVY\\Notes - Interioractive_ Smart Materials in the Hands of Designers and Architects for Designing Interactive Interiors.pdf:application/pdf},
}

@inproceedings{nowak_shaping_2022,
	address = {New Orleans LA USA},
	title = {Shaping {Textile} {Sliders}: {An} {Evaluation} of {Form} {Factors} and {Tick} {Marks} for {Textile} {Sliders}},
	isbn = {978-1-4503-9157-3},
	shorttitle = {Shaping {Textile} {Sliders}},
	url = {https://dl.acm.org/doi/10.1145/3491102.3517473},
	doi = {10.1145/3491102.3517473},
	language = {en},
	urldate = {2024-11-20},
	booktitle = {{CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Nowak, Oliver and Schäfer, René and Brocker, Anke and Wacker, Philipp and Borchers, Jan},
	month = apr,
	year = {2022},
	keywords = {Read, non-wearable, home},
	pages = {1--14},
	file = {Notes - Shaping Textile Sliders_ An Evaluation of Form Factors and Tick Marks for Textile Sliders:C\:\\Users\\giand\\Zotero\\storage\\JJ25GUYT\\Notes - Shaping Textile Sliders_ An Evaluation of Form Factors and Tick Marks for Textile Sliders.pdf:application/pdf;PDF:C\:\\Users\\giand\\Zotero\\storage\\PFHW68LK\\Nowak et al. - 2022 - Shaping Textile Sliders An Evaluation of Form Factors and Tick Marks for Textile Sliders.pdf:application/pdf;Video:C\:\\Users\\giand\\Zotero\\storage\\9E9QA57M\\Nowak et al. - 2022 - Shaping Textile Sliders An Evaluation of Form Factors and Tick Marks for Textile Sliders.mp4:video/mp4},
}

@article{nanjappan_towards_2019,
	title = {Towards a {Taxonomy} for {In}-{Vehicle} {Interactions} {Using} {Wearable} {Smart} {Textiles}: {Insights} from a {User}-{Elicitation} {Study}},
	volume = {3},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2414-4088},
	shorttitle = {Towards a {Taxonomy} for {In}-{Vehicle} {Interactions} {Using} {Wearable} {Smart} {Textiles}},
	url = {https://www.mdpi.com/2414-4088/3/2/33},
	doi = {10.3390/mti3020033},
	abstract = {Textiles are a vital and indispensable part of our clothing that we use daily. They are very flexible, often lightweight, and have a variety of application uses. Today, with the rapid developments in small and flexible sensing materials, textiles can be enhanced and used as input devices for interactive systems. Clothing-based wearable interfaces are suitable for in-vehicle controls. They can combine various modalities to enable users to perform simple, natural, and efficient interactions while minimizing any negative effect on their driving. Research on clothing-based wearable in-vehicle interfaces is still underexplored. As such, there is a lack of understanding of how to use textile-based input for in-vehicle controls. As a first step towards filling this gap, we have conducted a user-elicitation study to involve users in the process of designing in-vehicle interactions via a fabric-based wearable device. We have been able to distill a taxonomy of wrist and touch gestures for in-vehicle interactions using a fabric-based wrist interface in a simulated driving setup. Our results help drive forward the investigation of the design space of clothing-based wearable interfaces for in-vehicle secondary interactions.},
	language = {en},
	number = {2},
	urldate = {2024-11-21},
	journal = {Multimodal Technologies and Interaction},
	author = {Nanjappan, Vijayakumar and Shi, Rongkai and Liang, Hai-Ning and Lau, Kim King-Tong and Yue, Yong and Atkinson, Katie},
	month = jun,
	year = {2019},
	note = {Number: 2
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {Read, in-vehicle interactions, user-elicitation, wearable interfaces},
	pages = {33},
	file = {Full Text PDF:C\:\\Users\\giand\\Zotero\\storage\\WGX7EDY5\\Nanjappan et al. - 2019 - Towards a Taxonomy for In-Vehicle Interactions Using Wearable Smart Textiles Insights from a User-E.pdf:application/pdf},
}

@inproceedings{frison_ux_2019,
	address = {New York, NY, USA},
	series = {{CHI} '19},
	title = {In {UX} {We} {Trust}: {Investigation} of {Aesthetics} and {Usability} of {Driver}-{Vehicle} {Interfaces} and {Their} {Impact} on the {Perception} of {Automated} {Driving}},
	isbn = {978-1-4503-5970-2},
	shorttitle = {In {UX} {We} {Trust}},
	url = {https://dl.acm.org/doi/10.1145/3290605.3300374},
	doi = {10.1145/3290605.3300374},
	abstract = {In the evolution of technical systems, freedom from error and early adoption plays a major role for market success and to maintain competitiveness. In the case of automated driving, we see that faulty systems are put into operation and users trust these systems, often without any restrictions. Trust and use are often associated with users' experience of the driver-vehicle interfaces and interior design. In this work, we present the results of our investigations on factors that influence the perception of automated driving. In a simulator study, N=48 participants had to drive a SAE level 2 vehicle with either perfect or faulty driving function. As a secondary activity, participants had to solve tasks on an infotainment system with varying aesthetics and usability (2x2). Results reveal that the interaction of conditions significantly influences trust and UX of the vehicle system. Our conclusion is that all aspects of vehicle design cumulate to system and trust perception.},
	urldate = {2024-11-21},
	booktitle = {Proceedings of the 2019 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Frison, Anna-Katharina and Wintersberger, Philipp and Riener, Andreas and Schartmüller, Clemens and Boyle, Linda Ng and Miller, Erika and Weigl, Klemens},
	year = {2019},
	keywords = {Read},
	pages = {1--13},
	file = {Full Text PDF:C\:\\Users\\giand\\Zotero\\storage\\VAMYYMVT\\Frison et al. - 2019 - In UX We Trust Investigation of Aesthetics and Usability of Driver-Vehicle Interfaces and Their Imp.pdf:application/pdf},
}

@article{wilson_non-driving_2022,
	title = {Non-{Driving} {Related} tasks and journey types for future autonomous vehicle owners},
	volume = {85},
	issn = {1369-8478},
	url = {https://www.sciencedirect.com/science/article/pii/S1369847822000043},
	doi = {10.1016/j.trf.2022.01.004},
	abstract = {Highly automated vehicles (AVs) have the potential to improve the journey experience for all users by allowing them to partake in Non-Driving Related Tasks (NDRTs). Using a 42-question online survey of drivers (n = 1378, 59\% males, 40\% females), and in-depth interviews (n = 18, 56\% males, 44\% females), this study investigated NDRTs and the motivations for private ownership of highly automated vehicles (AVs). 42\% of participants were identified to be more likely to own an AV and, believed that they were safer, would reduce congestion and the risk of accidents. There was also a genuine desire to actively fill the non-driving time being productive or using a device rather than passive tasks such as listening to music or watching their surroundings. Commuting was reported to be the most likely journey type amongst those more likely to own an AV. The commuting journey also showed the most diverse range of NDRTs including social (e.g., conversation, playing games), wellbeing (e.g., eating a meal, sleep), leisure (e.g., watching a video), and being productive (e.g., working on a laptop). This study provides insights into NDRTs to inform future interior vehicle design and motivations for owning highly automated vehicles.},
	urldate = {2024-11-21},
	journal = {Transportation Research Part F: Traffic Psychology and Behaviour},
	author = {Wilson, Christopher and Gyi, Diane and Morris, Andrew and Bateman, Robert and Tanaka, Hiroyuki},
	month = feb,
	year = {2022},
	keywords = {Read, Important},
	pages = {150--160},
	file = {NDRTs:C\:\\Users\\giand\\Zotero\\storage\\K6BZIMAW\\NDRTs.png:image/png;Notes - Non-Driving Related tasks and journey types for future autonomous vehicle owners:C\:\\Users\\giand\\Zotero\\storage\\HAT6F7H4\\Notes - Non-Driving Related tasks and journey types for future autonomous vehicle owners.pdf:application/pdf;ScienceDirect Full Text PDF:C\:\\Users\\giand\\Zotero\\storage\\TFL94T96\\Wilson et al. - 2022 - Non-Driving Related tasks and journey types for future autonomous vehicle owners.pdf:application/pdf},
}

@article{detjen_how_2021,
	title = {How to {Increase} {Automated} {Vehicles}’ {Acceptance} through {In}-{Vehicle} {Interaction} {Design}: {A} {Review}},
	volume = {37},
	issn = {1044-7318},
	shorttitle = {How to {Increase} {Automated} {Vehicles}’ {Acceptance} through {In}-{Vehicle} {Interaction} {Design}},
	url = {https://doi.org/10.1080/10447318.2020.1860517},
	doi = {10.1080/10447318.2020.1860517},
	abstract = {Automated vehicles (AVs) are on the edge of being available on the mass market. Research often focuses on technical aspects of automation, such as computer vision, sensing, or artificial intelligence. Nevertheless, researchers also identified several challenges from a human perspective that need to be considered for a successful introduction of these technologies. In this paper, we first analyze human needs and system acceptance in the context of AVs. Then, based on a literature review, we provide a summary of current research on in-car driver-vehicle interaction and related human factor issues. This work helps researchers, designers, and practitioners to get an overview of the current state of the art.},
	number = {4},
	urldate = {2024-11-21},
	journal = {International Journal of Human–Computer Interaction},
	author = {Detjen, Henrik and Faltaous, Sarah and Pfleging, Bastian and Geisler, Stefan and Schneegass, Stefan},
	month = feb,
	year = {2021},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/10447318.2020.1860517},
	keywords = {Read},
	pages = {308--330},
	file = {Notes - How to Increase Automated Vehicles’ Acceptance through In-Vehicle Interaction Design_ A Review:C\:\\Users\\giand\\Zotero\\storage\\25632V8D\\Notes - How to Increase Automated Vehicles’ Acceptance through In-Vehicle Interaction Design_ A Review.pdf:application/pdf;PDF:C\:\\Users\\giand\\Zotero\\storage\\GP3T2K72\\Detjen et al. - 2021 - How to Increase Automated Vehicles’ Acceptance through In-Vehicle Interaction Design A Review.pdf:application/pdf},
}

@incollection{desmet_towards_2012,
	address = {Berlin, Heidelberg},
	title = {Towards {Happiness}: {Possibility}-{Driven} {Design}},
	isbn = {978-3-642-25691-2},
	shorttitle = {Towards {Happiness}},
	url = {https://doi.org/10.1007/978-3-642-25691-2\_1},
	abstract = {This chapter suggests possibility-driven design as an alternative to the common problem-driven approach. A first part explores the concept of "possibilities" and how it relates to happiness and well-being. We further develop the notion of designing for the pleasurable life and the good life through a number of exemplary design cases. Each takes a possibility-driven approach, thereby highlighting potential challenges and merits. By that, we hope to lay ground for an approach to design, which draws upon happiness to motivate the design of future technologies. This will help establishing a culture of humane innovation, which understands technology as a possibility to improve life directly.},
	language = {en},
	urldate = {2024-11-21},
	booktitle = {Human-{Computer} {Interaction}: {The} {Agency} {Perspective}},
	publisher = {Springer},
	author = {Desmet, Pieter and Hassenzahl, Marc},
	editor = {Zacarias, Marielba and de Oliveira, José Valente},
	year = {2012},
	doi = {10.1007/978-3-642-25691-2\_1},
	keywords = {Started Reading/Skimmed, Important},
	pages = {3-27},
	file = {Full Text PDF:C\:\\Users\\giand\\Zotero\\storage\\UFI4INBI\\Desmet and Hassenzahl - 2012 - Towards Happiness Possibility-Driven Design.pdf:application/pdf},
}

@book{case_calm_2015,
	title = {Calm {Technology}: {Principles} and {Patterns} for {Non}-{Intrusive} {Design}},
	isbn = {978-1-4919-2585-0},
	shorttitle = {Calm {Technology}},
	abstract = {How can you design technology that becomes a part of a user’s life and not a distraction from it? This practical book explores the concept of calm technology, a method for smoothly capturing a user’s attention only when necessary, while calmly remaining in the background most of the time. You’ll learn how to design products that work well, launch well, are easy to support, easy to use, and remain unobtrusive.Author Amber Case presents ideas first introduced by researchers at Xerox PARC in 1995, and explains how they apply to our current technology landscape, especially the Internet of Things. This book is ideal for UX and product designers, managers, creative directors, and developers. You’ll learn:The importance and challenge of designing technology that respects our attentionPrinciples of calm design—peripheral attention, context, and ambient awarenessCalm communication patterns—improving attention through a variety of sensesExercises for improving existing products through calm technologyPrinciples and patterns of calm technology for companies and teamsThe origins of calm technology at Xerox PARC},
	language = {en},
	publisher = {"O'Reilly Media, Inc."},
	author = {Case, Amber},
	month = dec,
	year = {2015},
	note = {Google-Books-ID: DZ88CwAAQBAJ},
	keywords = {Not important},
}

@incollection{gowrishankar_strategy_2017,
	address = {Cham},
	title = {A {Strategy} for {Material}-{Specific} e-{Textile} {Interaction} {Design}},
	isbn = {978-3-319-50124-6},
	url = {https://doi.org/10.1007/978-3-319-50124-6_11},
	abstract = {The interaction design of electronic textile (or e-Textile) products is often characterised by conventions adopted from electronic devices rather than developing interactions that are specific to e-Textiles. We argue that textile materials feature a vast potential for the design of novel digital interactions. In particular, the shape-reformation capabilities of textiles may inform the design of expressive and aesthetically rewarding applications. In this chapter, we propose ways in which the textileness of e-Textiles can be better harnessed. We outline an e-Textile Interaction Design strategy that is based on defining the material specificity of e-Textiles as its ability to deform in ways that match the expectations we have of textile materials. It embraces an open-ended exploration of interactions related to textiles (e.g., stretching, folding, turning inside out) and their potential for electronic recognisability for deriving material-specific concepts and applications for e-Textiles.},
	language = {en},
	urldate = {2024-12-02},
	booktitle = {Smart {Textiles}: {Fundamentals}, {Design}, and {Interaction}},
	publisher = {Springer International Publishing},
	author = {Gowrishankar, Ramyah and Bredies, Katharina and Ylirisku, Salu},
	editor = {Schneegass, Stefan and Amft, Oliver},
	year = {2017},
	doi = {10.1007/978-3-319-50124-6\_11},
	keywords = {Everyday Object, Interaction Design, Textile Contact, Textile Interaction, Textile Sensor, Started Reading/Skimmed},
	pages = {233--257},
	file = {Full Text PDF:C\:\\Users\\giand\\Zotero\\storage\\TEMQMEAZ\\Gowrishankar et al. - 2017 - A Strategy for Material-Specific e-Textile Interaction Design.pdf:application/pdf},
}

@inproceedings{schafer_whats_2023,
	address = {New York, NY, USA},
	series = {{CHI} '23},
	title = {What’s {That} {Shape}? {Investigating} {Eyes}-{Free} {Recognition} of {Textile} {Icons}},
	isbn = {978-1-4503-9421-5},
	shorttitle = {What’s {That} {Shape}?},
	url = {https://dl.acm.org/doi/10.1145/3544548.3580920},
	doi = {10.1145/3544548.3580920},
	abstract = {Textile surfaces, such as on sofas, cushions, and clothes, offer promising alternative locations to place controls for digital devices. Textiles are a natural, even abundant part of living spaces, and support unobtrusive input. While there is solid work on technical implementations of textile interfaces, there is little guidance regarding their design—especially their haptic cues, which are essential for eyes-free use. In particular, icons easily communicate information visually in a compact fashion, but it is unclear how to adapt them to the haptics-centric textile interface experience. Therefore, we investigated the recognizability of 84 haptic icons on fabrics. Each combines a shape, height profile (raised, recessed, or flat), and affected area (filled or outline). Our participants clearly preferred raised icons, and identified them with the highest accuracy and at competitive speeds. We also provide insights into icons that look very different, but are hard to distinguish via touch alone.},
	urldate = {2024-12-02},
	booktitle = {Proceedings of the 2023 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Schäfer, René and Nowak, Oliver and Suchmann, Lovis Bero and Schröder, Sören and Borchers, Jan},
	month = apr,
	year = {2023},
	keywords = {Read, non-wearable, home},
	pages = {1--12},
	file = {Full Text PDF:C\:\\Users\\giand\\Zotero\\storage\\AMPBPBUB\\Schäfer et al. - 2023 - What’s That Shape Investigating Eyes-Free Recognition of Textile Icons.pdf:application/pdf},
}

@inproceedings{olwal_e-textile_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {E-{Textile} {Microinteractions}: {Augmenting} {Twist} with {Flick}, {Slide} and {Grasp} {Gestures} for {Soft} {Electronics}},
	isbn = {978-1-4503-6708-0},
	shorttitle = {E-{Textile} {Microinteractions}},
	url = {https://dl.acm.org/doi/10.1145/3313831.3376236},
	doi = {10.1145/3313831.3376236},
	abstract = {E-textile microinteractions advance cord-based interfaces by enabling the simultaneous use of precise continuous control and casual discrete gestures. We leverage the recently introduced I/O Braid sensing architecture to enable a series of user studies and experiments which help design suitable interactions and a real-time gesture recognition pipeline. Informed by a gesture elicitation study with 36 participants, we developed a user-dependent classifier for eight discrete gestures with 94\% accuracy for 12 participants. In a formal evaluation we show that we can enable precise manipulation with the same architecture. Our quantitative targeting experiment suggests that twisting is faster than existing headphone button controls and is comparable in speed to a capacitive touch surface. Qualitative interview feedback indicates a preference for I/O Braid's interaction over that of in-line headphone controls. Our applications demonstrate how continuous and discrete gestures can be combined to form new, integrated e-textile microinteraction techniques for real-time continuous control, discrete actions and mode switching.},
	urldate = {2024-12-02},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Olwal, Alex and Starner, Thad and Mainini, Gowa},
	month = apr,
	year = {2020},
	keywords = {Started Reading/Skimmed},
	pages = {1--13},
	file = {Full Text PDF:C\:\\Users\\giand\\Zotero\\storage\\L3CV53NL\\Olwal et al. - 2020 - E-Textile Microinteractions Augmenting Twist with Flick, Slide and Grasp Gestures for Soft Electron.pdf:application/pdf},
}

@inproceedings{gilliland_textile_2010,
	title = {The {Textile} {Interface} {Swatchbook}: {Creating} graphical user interface-like widgets with conductive embroidery},
	shorttitle = {The {Textile} {Interface} {Swatchbook}},
	url = {https://ieeexplore.ieee.org/document/5665876},
	doi = {10.1109/ISWC.2010.5665876},
	abstract = {The Textile Interface Swatchbook demonstrates how conductive embroidery can render graphical user interface-like (GUI) widgets on fabric. Such widgets might be used to control mobile electronics such as a music player, mobile phone, or projected display. At present, six swatches have been created for the swatchbook: pleat, menu, rocker, multi-touch gesture, zipper, and proximity. The three most diverse and original are discussed here. In addition, we develop a hybrid resistive-capacitive touch sensing technique designed to be more tolerant to the flexing typical of fabric. We hope to develop the Textile Interface Swatchbook into a reference tool for textile interfaces.},
	urldate = {2024-12-02},
	booktitle = {International {Symposium} on {Wearable} {Computers} ({ISWC}) 2010},
	author = {Gilliland, Scott and Komor, Nicholas and Starner, Thad and Zeagler, Clint},
	month = oct,
	year = {2010},
	note = {ISSN: 2376-8541},
	keywords = {Read, Fabrics, non-wearable},
	pages = {1--8},
	file = {Full Text PDF:C\:\\Users\\giand\\Zotero\\storage\\QUT6Y8HF\\Gilliland et al. - 2010 - The Textile Interface Swatchbook Creating graphical user interface-like widgets with conductive emb.pdf:application/pdf;IEEE Xplore Abstract Record:C\:\\Users\\giand\\Zotero\\storage\\PM9SAEQV\\5665876.html:text/html},
}

@book{shishoo_textile_2008,
	title = {Textile {Advances} in the {Automotive} {Industry}},
	isbn = {978-1-84569-504-0},
	abstract = {Automotive textiles represent one of the most valuable international markets for technical textiles. Textile advances in the automotive industry provides an in-depth review of the design and development of automotive textiles and the recent advances made in technical textiles for a variety of automotive applications.Part one discusses issues such as automotive textile requirements from a car producer's perspective, mapping the automotive textile supply chain, advances in textile fabrics including nonwoven fabrics, and recycling issues. Part two focuses on automotive interiors with chapters on performance and style of interior textiles, materials and design for car seats, and the reduction of interior noise in vehicles. Part three discusses the important safety applications of automotive textiles, including airbags and tyres. Part four concludes by assessing how textiles can be used in automotive bodywork.With its distinguished editor and a team of contributors from both academia and industry, this book is an essential reference for a broad spectrum of readers, ranging from scientists, designers, product development staff to company strategists. - Provides an in-depth review of recent advances in the design and development of automotive textiles - Comprehensively examines the automotive textile industry covering key requirements, the supply chain, fabrics and recycling - Addresses important safety considerations in automotive textiles including airbags and tyres},
	language = {en},
	publisher = {Elsevier},
	author = {Shishoo, Roshan},
	month = oct,
	year = {2008},
	note = {Google-Books-ID: 6aajAgAAQBAJ},
	keywords = {Read, in-vehicle interactions},
}

@article{mortensen_how_nodate,
	title = {How to {Create} an {Intuitive} {Design}},
	language = {en},
	author = {Mortensen, Ditte},
	keywords = {Read, Intuitiveness},
	file = {PDF:C\:\\Users\\giand\\Zotero\\storage\\N9T4ZCQQ\\Mortensen - How to Create an Intuitive Design.pdf:application/pdf},
}

@inproceedings{brauner_interactive_2017,
	address = {New York, NY, USA},
	series = {{ISS} '17},
	title = {Interactive {FUrniTURE}: {Evaluation} of {Smart} {Interactive} {Textile} {Interfaces} for {Home} {Environments}},
	isbn = {978-1-4503-4691-7},
	shorttitle = {Interactive {FUrniTURE}},
	url = {https://dl.acm.org/doi/10.1145/3132272.3134128},
	doi = {10.1145/3132272.3134128},
	abstract = {Ubiquitous computing strives to reach the calm computing state where sensors and actuators disappear from the foreground of our surroundings into the fabric of everyday objects. Despite the great progress in embedded technology, artificial interfaces, such as remote controls and touch screens, remain the dominant media for interacting with smart everyday objects. Motivated by recent advancements in smart textile technologies, we investigate the usability and acceptance of fabric-based controllers in the smart home environment. In this article we describe the development and evaluation of three textile interfaces for controlling a motorized recliner armchair in a living room setting. The core of this contribution is the empirical study with twenty participants that contrasted the user experience of three textile-based interaction techniques to a standard remote control. Despite the slightly lower reliability of the textile interfaces, their overall acceptance was higher. The study shows that the hedonic quality and attractiveness of textile interfaces have higher impact on user acceptance compared to pragmatic qualities, such as efficiency, fluidity of interaction, and reliability. Attractiveness profits from the direct and nearly invisible integration of the interaction device into textile objects such as furniture.},
	urldate = {2024-12-16},
	booktitle = {Proceedings of the 2017 {ACM} {International} {Conference} on {Interactive} {Surfaces} and {Spaces}},
	publisher = {Association for Computing Machinery},
	author = {Brauner, Philipp and van Heek, Julia and Ziefle, Martina and Hamdan, Nur Al-huda and Borchers, Jan},
	year = {2017},
	keywords = {Read, Important, home},
	pages = {151--160},
	file = {Full Text PDF:C\:\\Users\\giand\\Zotero\\storage\\EIDI354C\\Brauner et al. - 2017 - Interactive FUrniTURE Evaluation of Smart Interactive Textile Interfaces for Home Environments.pdf:application/pdf},
}

@article{guerino_usability_2020,
	title = {Usability and user experience evaluation of natural user interfaces: a systematic mapping study},
	volume = {14},
	copyright = {© 2020 The Institution of Engineering and Technology},
	issn = {1751-8814},
	shorttitle = {Usability and user experience evaluation of natural user interfaces},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1049/iet-sen.2020.0051},
	doi = {10.1049/iet-sen.2020.0051},
	abstract = {Natural user interface (NUI) is considered a recent topic in human–computer interaction (HCI) and provides innovative forms of interaction, which are performed through natural movements of the human body like gestures, voice, and gaze. In the software development process, usability and user eXperience (UX) evaluations are a relevant step, since they evaluate several aspects of the system, such as efficiency, effectiveness, user satisfaction, and immersion. Thus, the goal of the authors’ systematic mapping study (SMS) is to identify usability and UX evaluation technologies used by researchers and developers in software with NUIs. Their SMS selected 56 papers containing evaluation technologies for NUI. Overall, the authors identified 30 different usability and UX evaluation technologies for NUI. The analysis of these technologies reveals most of them are used to evaluate software in general, without considering the specificities of NUI. Besides, most technologies evaluate only one aspect, Usability or UX. In other words, these technologies do not consider Usability and UX together. For future work, they intend to develop an evaluation technology for NUIs that fills the gaps identified in their SMS and combining Usability and UX.},
	language = {en},
	number = {5},
	urldate = {2024-12-17},
	journal = {IET Software},
	author = {Guerino, Guilherme Corredato and Valentim, Natasha Malveira Costa},
	year = {2020},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1049/iet-sen.2020.0051},
	keywords = {Read, natural user interface, NUI},
	pages = {451--467},
	file = {Full Text PDF:C\:\\Users\\giand\\Zotero\\storage\\LPSRCQUB\\Guerino and Valentim - 2020 - Usability and user experience evaluation of natural user interfaces a systematic mapping study.pdf:application/pdf;Snapshot:C\:\\Users\\giand\\Zotero\\storage\\M8B3W8WP\\iet-sen.2020.html:text/html},
}

@inproceedings{weinberg_evaluating_2011,
	address = {New York, NY, USA},
	series = {{AutomotiveUI} '11},
	title = {Evaluating the usability of a head-up display for selection from choice lists in cars},
	isbn = {978-1-4503-1231-8},
	url = {https://dl.acm.org/doi/10.1145/2381416.2381423},
	doi = {10.1145/2381416.2381423},
	abstract = {It has been established that head-down displays (HDDs), such as those commonly placed in the dashboard of commercial automobiles, negatively affect drivers' visual attention [1]. This problem can be exacerbated when screens are "busy" with graphics or rich information. In this paper, which is an extension of a user-preference study [23], we present the results of a driving simulator experiment where we examined two potential alternatives to HDDs for presenting textual lists. Subjects conducted a series of street name finding tasks using each of three system variants: one with a head-down display (HDD), one with a head-up display (HUD), and one with only an auditory display. We found that the auditory display had the least impact on driving performance and mental load, but at the expense of task completion efficiency. The HUD variant had a low impact on mental load and scored highest in user satisfaction, and therefore appears to be the most viable target for future study.},
	urldate = {2024-12-17},
	booktitle = {Proceedings of the 3rd {International} {Conference} on {Automotive} {User} {Interfaces} and {Interactive} {Vehicular} {Applications}},
	publisher = {Association for Computing Machinery},
	author = {Weinberg, Garrett and Harsham, Bret and Medenica, Zeljko},
	month = nov,
	year = {2011},
	keywords = {Started Reading/Skimmed, Not important},
	pages = {39--46},
	file = {Full Text PDF:C\:\\Users\\giand\\Zotero\\storage\\58ZTRHKN\\Weinberg et al. - 2011 - Evaluating the usability of a head-up display for selection from choice lists in cars.pdf:application/pdf},
}

@inproceedings{zhu_value_2020,
	address = {New York, NY, USA},
	series = {{AIAM2020}},
	title = {The {Value} and {Application} of {Car} {Head}-{Up} {Display} in {Interactive} {Design}},
	isbn = {978-1-4503-7553-5},
	url = {https://dl.acm.org/doi/10.1145/3421766.3421796},
	doi = {10.1145/3421766.3421796},
	abstract = {The HUD (head-up display) technology was first applied to aircraft. The collected data is displayed on the windshield panel of the aircraft. The purpose is to avoid errors when the pilot looks down at the required data, resulting in some irreversible problems. as a result of. The so-called head-up display refers to the integration of the flight assistance technology of the aircraft into the car. The automobile HUD also integrates some important driving data and projects it on the front windshield, and feeds it back to the driver, reducing the frequency of looking down at the instrument, preventing the driver from distracting, and reducing the occurrence of traffic accidents. The purpose of this research is to combine HUD technology with interactive design to improve the safety of vehicle driving.This research takes as the starting point which functions should be provided by the automobile HUD, and provides a reasonable "export" between the conversion between aircraft and automobile. Perfect integration of traditional cars and modern technology, thereby reducing the occurrence of car accidents. At the same time, the user-centered design ideal is used to enable consumers to quickly accept and proficiently use the technology.},
	urldate = {2024-12-17},
	booktitle = {Proceedings of the 2nd {International} {Conference} on {Artificial} {Intelligence} and {Advanced} {Manufacture}},
	publisher = {Association for Computing Machinery},
	author = {Zhu, Aijun and Zhang, Caizhong},
	year = {2020},
	keywords = {Started Reading/Skimmed, Not important},
	pages = {478--483},
	file = {Full Text PDF:C\:\\Users\\giand\\Zotero\\storage\\7V3VF68F\\Zhu and Zhang - 2020 - The Value and Application of Car Head-Up Display in Interactive Design.pdf:application/pdf},
}

@inproceedings{pfleging_investigating_2016,
	address = {New York, NY, USA},
	series = {{MUM} '16},
	title = {Investigating user needs for non-driving-related activities during automated driving},
	isbn = {978-1-4503-4860-7},
	url = {https://dl.acm.org/doi/10.1145/3012709.3012735},
	doi = {10.1145/3012709.3012735},
	abstract = {In this paper, we investigate which non-driving-related activities drivers want to perform while driving highly or fully automated. Beyond the available advanced driving assistance functions, we expect that highly automated driving will soon be available in production vehicles. While many technological aspects have been investigated, it is not yet clear (a) which activities the drivers want to perform once they do not have to steer or monitor their car any more and (b) which of those will be feasible. In contrast to prior (survey-based) research, we investigate the driver's needs for such activities by employing a combination of a web survey, in-situ observations, and an in-situ survey. Also, we have a look at the specific requirements of the European / German market in contrast to prior research conducted mostly for English-speaking countries.The findings indicate that besides traditional activities (talking to passengers, listening to music), daydreaming, writing text messages, eating and drinking, browsing the Internet, and calling are most wanted for highly automated driving. This shows the potential for mobile and ubiquitous multimedia applications in the car.},
	urldate = {2025-02-18},
	booktitle = {Proceedings of the 15th {International} {Conference} on {Mobile} and {Ubiquitous} {Multimedia}},
	publisher = {Association for Computing Machinery},
	author = {Pfleging, Bastian and Rang, Maurice and Broy, Nora},
	year = {2016},
	keywords = {Read, Important},
	pages = {91--99},
	file = {Full Text PDF:C\:\\Users\\giand\\Zotero\\storage\\2RL5KN65\\Pfleging et al. - 2016 - Investigating user needs for non-driving-related activities during automated driving.pdf:application/pdf},
}

@inproceedings{may_multimodal_2014,
	address = {New York, NY, USA},
	series = {{AutomotiveUI} '14},
	title = {A {Multimodal} {Air} {Gesture} {Interface} for {In} {Vehicle} {Menu} {Navigation}},
	isbn = {978-1-4503-0725-3},
	url = {https://dl.acm.org/doi/10.1145/2667239.2667280},
	doi = {10.1145/2667239.2667280},
	abstract = {Multimodal and visual-only air gesture systems for navigating menus in the vehicle were developed and compared to a conventional direct touch system in a driving simulator using various distraction metrics. Participants using the multimodal air gesture system exhibited safer secondary task dwell patterns, but took longer to complete tasks and reported higher workload compared to the touch system.},
	urldate = {2025-02-18},
	booktitle = {Adjunct {Proceedings} of the 6th {International} {Conference} on {Automotive} {User} {Interfaces} and {Interactive} {Vehicular} {Applications}},
	publisher = {Association for Computing Machinery},
	author = {May, Keenan R and Gable, Thomas M and Walker, Bruce N},
	month = sep,
	year = {2014},
	keywords = {Read},
	pages = {1--6},
	file = {Full Text PDF:C\:\\Users\\giand\\Zotero\\storage\\XR9YN9NC\\May et al. - 2014 - A Multimodal Air Gesture Interface for In Vehicle Menu Navigation.pdf:application/pdf},
}

@article{kun_shifting_2016,
	title = {Shifting {Gears}: {User} {Interfaces} in the {Age} of {Autonomous} {Driving}},
	volume = {15},
	issn = {1558-2590},
	shorttitle = {Shifting {Gears}},
	url = {https://ieeexplore.ieee.org/document/7389268},
	doi = {10.1109/MPRV.2016.14},
	abstract = {The field of automotive user interfaces has developed rapidly over the last several years. To date, the field has primarily focused on creating user interfaces that promote safe driving, including when the driver is engaged in a secondary task in addition to operating the vehicle. However, researchers now need to prepare for a major change in the automotive domain: the automated driving revolution. The authors argue for a new research agenda that focuses on four challenges for automotive user interfaces: assuring safety in the age of automation, transforming vehicles into places for productivity and play, taking advantage of new mobility options made possible by automated vehicles, while throughout all this preserving user privacy and data security. This article is part of a special issue on smart vehicle spaces.},
	number = {1},
	urldate = {2025-02-20},
	journal = {IEEE Pervasive Computing},
	author = {Kun, Andrew L. and Boll, Susanne and Schmidt, Albrecht},
	month = jan,
	year = {2016},
	note = {Conference Name: IEEE Pervasive Computing},
	keywords = {Read, human-computer interaction, Automation, Automotive engineering, autonomous driving, driving, Electric vehicles, HCI, intelligent systems, Intelligent vehicles, mobile, pervasive computing, Pervasive computing, Safety, Smart devices, smart vehicle spaces, transportation, User interfaces},
	pages = {32--38},
	file = {Full Text PDF:C\:\\Users\\giand\\Zotero\\storage\\4SITB88S\\Kun et al. - 2016 - Shifting Gears User Interfaces in the Age of Autonomous Driving.pdf:application/pdf;IEEE Xplore Abstract Record:C\:\\Users\\giand\\Zotero\\storage\\X6YKXYDX\\7389268.html:text/html},
}

@inproceedings{riener_standardization_2013,
	address = {New York, NY, USA},
	series = {{AutomotiveUI} '13},
	title = {Standardization of the in-car gesture interaction space},
	isbn = {978-1-4503-2478-6},
	url = {https://dl.acm.org/doi/10.1145/2516540.2516544},
	doi = {10.1145/2516540.2516544},
	abstract = {Driven by technological advancements, gesture interfaces have recently found their way into vehicular prototypes of various kind. Unfortunately, their application is less than perfect and detailed information about preferred gesture execution regions, spatial extent, and time behavior are not available yet. Providing car (interior) manufacturer with gesture characteristics would allow them to design future in-vehicle concepts in a way to not interfere with gestural interaction. To tackle the problem, this research aims as preliminary work for a later standardization of the diverse properties of gestures and gesture classes similarly to what is already standardized in norms such as ISO 3958/4040 for placement and reachability of traditional controls and indicators. We have set up a real driving experiment recording trajectories and time behavior of gestures related to car and media control tasks. Data evaluation reveals that most of the subjects perform gestures in the same region (bounded by a "triangle" steering wheel, rear mirror, and gearshift) and with similar spatial extent (on average below 2 sec.). The generated density plots can be further used for an initial discussion about gesture execution in the passenger compartment. The final aim is to propose a new standard on permitted gesture properties (time, space) in the car.},
	urldate = {2025-02-20},
	booktitle = {Proceedings of the 5th {International} {Conference} on {Automotive} {User} {Interfaces} and {Interactive} {Vehicular} {Applications}},
	publisher = {Association for Computing Machinery},
	author = {Riener, A. and Ferscha, A. and Bachmair, F. and Hagmüller, P. and Lemme, A. and Muttenthaler, D. and Pühringer, D. and Rogner, H. and Tappe, A. and Weger, F.},
	year = {2013},
	keywords = {Started Reading/Skimmed},
	pages = {14--21},
	file = {Full Text PDF:C\:\\Users\\giand\\Zotero\\storage\\TT3DLU7F\\Riener et al. - 2013 - Standardization of the in-car gesture interaction space.pdf:application/pdf},
}

@article{morris_reducing_2014,
	title = {Reducing legacy bias in gesture elicitation studies},
	volume = {21},
	issn = {1072-5520},
	url = {https://dl.acm.org/doi/10.1145/2591689},
	doi = {10.1145/2591689},
	number = {3},
	urldate = {2025-02-20},
	journal = {interactions},
	author = {Morris, Meredith Ringel and Danielescu, Andreea and Drucker, Steven and Fisher, Danyel and Lee, Bongshin and schraefel, m. c. and Wobbrock, Jacob O.},
	year = {2014},
	keywords = {Read},
	pages = {40--45},
	file = {Full Text PDF:C\:\\Users\\giand\\Zotero\\storage\\4SMKFUMP\\Morris et al. - 2014 - Reducing legacy bias in gesture elicitation studies.pdf:application/pdf},
}

@article{villarreal-narvaez_brave_2024,
	title = {Brave {New} {GES} {World}: {A} {Systematic} {Literature} {Review} of {Gestures} and {Referents} in {Gesture} {Elicitation} {Studies}},
	volume = {56},
	issn = {0360-0300},
	shorttitle = {Brave {New} {GES} {World}},
	url = {https://dl.acm.org/doi/10.1145/3636458},
	doi = {10.1145/3636458},
	abstract = {How do we determine highly effective and intuitive gesture sets for interactive systems tailored to end users’ preferences? A substantial body of knowledge is available on this topic, among which gesture elicitation studies stand out distinctively. In these studies, end users are invited to propose gestures for specific referents, which are the functions to control for an interactive system. The vast majority of gesture elicitation studies conclude with a consensus gesture set identified following a process of consensus or agreement analysis. However, the information about specific gesture sets determined for specific applications is scattered across a wide landscape of disconnected scientific publications, which poses challenges to researchers and practitioners to effectively harness this body of knowledge. To address this challenge, we conducted a systematic literature review and examined a corpus of N= 267 studies encompassing a total of 187,265 gestures elicited from 6,659 participants for 4,106 referents. To understand similarities in users’ gesture preferences within this extensive dataset, we analyzed a sample of 2,304 gestures extracted from the studies identified in our literature review. Our approach consisted of (i) identifying the context of use represented by end users, devices, platforms, and gesture sensing technology; (ii) categorizing the referents; (iii) classifying the gestures elicited for those referents; and (iv) cataloging the gestures based on their representation and implementation modalities. Drawing from the findings of this review, we propose guidelines for conducting future end-user gesture elicitation studies.},
	number = {5},
	urldate = {2025-02-20},
	journal = {ACM Comput. Surv.},
	author = {Villarreal-Narvaez, Santiago and Sluÿters, Arthur and Vanderdonckt, Jean and Vatavu, Radu-Daniel},
	month = jan,
	year = {2024},
	keywords = {Read},
	pages = {128:1--128:55},
	file = {Full Text PDF:C\:\\Users\\giand\\Zotero\\storage\\Z84ZUJE8\\Villarreal-Narvaez et al. - 2024 - Brave New GES World A Systematic Literature Review of Gestures and Referents in Gesture Elicitation.pdf:application/pdf},
}

@incollection{vatavu_gesture-based_2023,
	title = {Gesture-{Based} {Interaction}},
	isbn = {978-3-319-27648-9},
	url = {https://link.springer.com/referenceworkentry/10.1007/978-3-319-27648-9_20-1},
	abstract = {Many interactive devices and systems, from smartphones and tablets to smart wearables, video game consoles, ambient displays and interactive surfaces to systems rendering virtual and augmented reality environments, leverage users\&\#8217; capabilities to communicate...},
	language = {en},
	urldate = {2025-02-20},
	booktitle = {Handbook of {Human} {Computer} {Interaction}},
	publisher = {Springer, Cham},
	author = {Vatavu, Radu-Daniel},
	year = {2023},
	doi = {10.1007/978-3-319-27648-9_20-1},
	keywords = {Read},
	pages = {1--47},
	file = {Full Text PDF:C\:\\Users\\giand\\Zotero\\storage\\2HSQ5B2X\\Vatavu - 2023 - Gesture-Based Interaction.pdf:application/pdf},
}

@article{goth_brave_2011,
	title = {Brave {NUI} world},
	volume = {54},
	issn = {0001-0782},
	url = {https://dl.acm.org/doi/10.1145/2043174.2043181},
	doi = {10.1145/2043174.2043181},
	abstract = {Natural user interface developments, such as Microsoft's Kinect, may indicate the beginning of the end for the mouse.},
	number = {12},
	urldate = {2025-02-27},
	journal = {Commun. ACM},
	author = {Goth, Gregory},
	year = {2011},
	keywords = {Started Reading/Skimmed},
	pages = {14--16},
	file = {Full Text PDF:C\:\\Users\\giand\\Zotero\\storage\\3KDAM9FY\\Goth - 2011 - Brave NUI world.pdf:application/pdf},
}

@article{del_ra_brave_2011,
	title = {Brave {NUI} world: designing natural user interfaces for touch and gesture by {Daniel} {Wigdor} and {Dennis} {Wixon}},
	volume = {36},
	issn = {0163-5948},
	shorttitle = {Brave {NUI} world},
	url = {https://dl.acm.org/doi/10.1145/2047414.2047439},
	doi = {10.1145/2047414.2047439},
	number = {6},
	urldate = {2025-02-27},
	journal = {SIGSOFT Softw. Eng. Notes},
	author = {Del Ra, William},
	month = nov,
	year = {2011},
	keywords = {Started Reading/Skimmed},
	pages = {29--30},
	file = {Full Text PDF:C\:\\Users\\giand\\Zotero\\storage\\635I5FWS\\Del Ra - 2011 - Brave NUI world designing natural user interfaces for touch and gesture by Daniel Wigdor and Dennis.pdf:application/pdf},
}

@inproceedings{morris_understanding_2010,
	address = {CAN},
	series = {{GI} '10},
	title = {Understanding users' preferences for surface gestures},
	isbn = {978-1-56881-712-5},
	abstract = {We compare two gesture sets for interactive surfaces---a set of gestures created by an end-user elicitation method and a set of gestures authored by three HCI researchers. Twenty-two participants who were blind to the gestures' authorship evaluated 81 gestures presented and performed on a Microsoft Surface. Our findings indicate that participants preferred gestures authored by larger groups of people, such as those created by end-user elicitation methodologies or those proposed by more than one researcher. This preference pattern seems to arise in part because the HCI researchers proposed more physically and conceptually complex gestures than end-users. We discuss our findings in detail, including the implications for surface gesture design.},
	urldate = {2025-02-27},
	booktitle = {Proceedings of {Graphics} {Interface} 2010},
	publisher = {Canadian Information Processing Society},
	author = {Morris, Meredith Ringel and Wobbrock, Jacob O. and Wilson, Andrew D.},
	year = {2010},
	keywords = {Gesture},
	pages = {261--268},
	file = {Full Text PDF:C\:\\Users\\giand\\Zotero\\storage\\GW8Q7EWE\\Morris et al. - 2010 - Understanding users' preferences for surface gestures.pdf:application/pdf},
}

@inproceedings{wobbrock_user-defined_2009,
	address = {New York, NY, USA},
	series = {{CHI} '09},
	title = {User-defined gestures for surface computing},
	isbn = {978-1-60558-246-7},
	url = {https://dl.acm.org/doi/10.1145/1518701.1518866},
	doi = {10.1145/1518701.1518866},
	abstract = {Many surface computing prototypes have employed gestures created by system designers. Although such gestures are appropriate for early investigations, they are not necessarily reflective of user behavior. We present an approach to designing tabletop gestures that relies on eliciting gestures from non-technical users by first portraying the effect of a gesture, and then asking users to perform its cause. In all, 1080 gestures from 20 participants were logged, analyzed, and paired with think-aloud data for 27 commands performed with 1 and 2 hands. Our findings indicate that users rarely care about the number of fingers they employ, that one hand is preferred to two, that desktop idioms strongly influence users' mental models, and that some commands elicit little gestural agreement, suggesting the need for on-screen widgets. We also present a complete user-defined gesture set, quantitative agreement scores, implications for surface technology, and a taxonomy of surface gestures. Our results will help designers create better gesture sets informed by user behavior.},
	urldate = {2025-02-27},
	booktitle = {Proceedings of the {SIGCHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Wobbrock, Jacob O. and Morris, Meredith Ringel and Wilson, Andrew D.},
	month = apr,
	year = {2009},
	keywords = {Gesture},
	pages = {1083--1092},
	file = {Full Text PDF:C\:\\Users\\giand\\Zotero\\storage\\549CZH6S\\Wobbrock et al. - 2009 - User-defined gestures for surface computing.pdf:application/pdf},
}

@article{bilius_multistudy_2020,
	title = {A multistudy investigation of drivers and passengers’ gesture and voice input preferences for in-vehicle interactions},
	volume = {25},
	issn = {1547-2450},
	url = {https://doi.org/10.1080/15472450.2020.1846127},
	doi = {10.1080/15472450.2020.1846127},
	abstract = {We conduct an examination of the preferences of drivers and passengers alike for in-vehicle interactions with a multistudy approach consisting of (1) a targeted literature survey of applications and user interfaces designed to support interactions with in-vehicle controls and systems based on gesture and voice input; (2) a large-scale survey (N = 160 participants) to understand drivers and passengers’ preferences for driving and traveling by car; and (3) an end-user elicitation study (N = 40 drivers and passengers) to collect preferences for gesture and voice input commands for in-vehicle interaction. We analyze and discuss the gesture and voice commands proposed by our participants and describe their characteristics, such as production times for gesture input and the vocabulary size of voice commands.},
	number = {2},
	urldate = {2025-02-27},
	journal = {Journal of Intelligent Transportation Systems},
	author = {Bilius, Laura-Bianca and Vatavu, Radu-Daniel},
	month = nov,
	year = {2020},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/15472450.2020.1846127},
	keywords = {gesture input, study, voice input, Not important},
	pages = {197--220},
}

@article{norman_gestural_2010,
	title = {Gestural interfaces: a step backward in usability},
	volume = {17},
	issn = {1072-5520},
	shorttitle = {Gestural interfaces},
	url = {https://dl.acm.org/doi/10.1145/1836216.1836228},
	doi = {10.1145/1836216.1836228},
	number = {5},
	urldate = {2025-02-27},
	journal = {interactions},
	author = {Norman, Donald A. and Nielsen, Jakob},
	month = sep,
	year = {2010},
	keywords = {Read},
	pages = {46--49},
	file = {Full Text PDF:C\:\\Users\\giand\\Zotero\\storage\\TPQR9NCV\\Norman and Nielsen - 2010 - Gestural interfaces a step backward in usability.pdf:application/pdf},
}

@inproceedings{may_designing_2017,
	address = {New York, NY, USA},
	series = {{AutomotiveUI} '17},
	title = {Designing an {In}-{Vehicle} {Air} {Gesture} {Set} {Using} {Elicitation} {Methods}},
	isbn = {978-1-4503-5150-8},
	url = {https://dl.acm.org/doi/10.1145/3122986.3123015},
	doi = {10.1145/3122986.3123015},
	abstract = {In-air gestures have become more prevalent in the vehicle cockpit in recent years. However, air gesture interfaces are still quite young and users have very little experience with such interactions. In the vehicle, ease of use relates directly to driver safety. Previous work has suggested that gesture sets created through participatory methods tend to be easier for people to grasp and use than designer-designed sets. In the present study, two novel participatory design activities -- an elicitation activity in which participants produced gestures, and an online survey in which they assessed the workload associated with those gestures -- were conducted to assess possible air gestures for control of in-vehicle menus. A recommended gesture set is presented alongside broader recommendations for vehicle gesture design.},
	urldate = {2025-02-27},
	booktitle = {Proceedings of the 9th {International} {Conference} on {Automotive} {User} {Interfaces} and {Interactive} {Vehicular} {Applications}},
	publisher = {Association for Computing Machinery},
	author = {May, Keenan R. and Gable, Thomas M. and Walker, Bruce N.},
	month = sep,
	year = {2017},
	keywords = {Not important},
	pages = {74--83},
	file = {Full Text PDF:C\:\\Users\\giand\\Zotero\\storage\\XDIGCIQP\\May et al. - 2017 - Designing an In-Vehicle Air Gesture Set Using Elicitation Methods.pdf:application/pdf},
}

@inproceedings{koelle_social_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {Social {Acceptability} in {HCI}: {A} {Survey} of {Methods}, {Measures}, and {Design} {Strategies}},
	isbn = {978-1-4503-6708-0},
	shorttitle = {Social {Acceptability} in {HCI}},
	url = {https://dl.acm.org/doi/10.1145/3313831.3376162},
	doi = {10.1145/3313831.3376162},
	abstract = {With the increasing ubiquity of personal devices, social acceptability of human-machine interactions has gained relevance and growing interest from the HCI community. Yet, there are no best practices or established methods for evaluating social acceptability. Design strategies for increasing social acceptability have been described and employed, but so far not been holistically appraised and evaluated. We offer a systematic literature analysis (N=69) of social acceptability in HCI and contribute a better understanding of current research practices, namely, methods employed, measures and design strategies. Our review identified an unbalanced distribution of study approaches, shortcomings in employed measures, and a lack of interweaving between empirical and artifact-creating approaches. The latter causes a discrepancy between design recommendations based on user research, and design strategies employed in artifact creation. Our survey lays the groundwork for a more nuanced evaluation of social acceptability, the development of best practices, and a future research agenda.},
	urldate = {2025-02-27},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Koelle, Marion and Ananthanarayan, Swamy and Boll, Susanne},
	month = apr,
	year = {2020},
	keywords = {Started Reading/Skimmed},
	pages = {1--19},
	file = {Full Text PDF:C\:\\Users\\giand\\Zotero\\storage\\XHQ7ESHA\\Koelle et al. - 2020 - Social Acceptability in HCI A Survey of Methods, Measures, and Design Strategies.pdf:application/pdf},
}

@inproceedings{vatavu_formalizing_2015,
	address = {New York, NY, USA},
	series = {{CHI} '15},
	title = {Formalizing {Agreement} {Analysis} for {Elicitation} {Studies}: {New} {Measures}, {Significance} {Test}, and {Toolkit}},
	isbn = {978-1-4503-3145-6},
	shorttitle = {Formalizing {Agreement} {Analysis} for {Elicitation} {Studies}},
	url = {https://dl.acm.org/doi/10.1145/2702123.2702223},
	doi = {10.1145/2702123.2702223},
	abstract = {We address in this work the process of agreement rate analysis for characterizing the level of consensus between participants' proposals elicited during guessability studies. Two new measures, i.e., disagreement rate for referents and coagreement rate between referents, are proposed to accompany the widely-used agreement rate formula of Wobbrock et al. [37] when reporting participants' consensus for symbolic input. A statistical significance test for comparing the agreement rates of k\&gt;=2 referents is presented in analogy with Cochran's success/failure Q test [5], for which we express the test statistic in terms of agreement and coagreement rates. We deliver a toolkit to assist practitioners to compute agreement, disagreement, and coagreement rates, and run statistical tests for agreement rates at p=.05, .01, and .001 levels of significance. We validate our theoretical development of agreement rate analysis in relation with several previously published elicitation studies. For example, when we present the probability distribution function of the agreement rate measure, we also use it (1) to explain the magnitude of agreement rates previously reported in the literature, and (2) to propose qualitative interpretations for agreement rates, in analogy with Cohen's guidelines for effect sizes [6]. We also re-examine previously published elicitation data from the perspective of the agreement rate test statistic, and highlight new findings on the effect of referents over agreement rates, unattainable prior to this work. We hope that our contributions will advance the current knowledge in agreement rate analysis, providing researchers and practitioners with new techniques and tools to help them understand user-elicited data at deeper levels of detail and sophistication.},
	urldate = {2025-03-03},
	booktitle = {Proceedings of the 33rd {Annual} {ACM} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Vatavu, Radu-Daniel and Wobbrock, Jacob O.},
	month = apr,
	year = {2015},
	keywords = {To Read},
	pages = {1325--1334},
	file = {Full Text PDF:C\:\\Users\\giand\\Zotero\\storage\\85LCWL44\\Vatavu and Wobbrock - 2015 - Formalizing Agreement Analysis for Elicitation Studies New Measures, Significance Test, and Toolkit.pdf:application/pdf},
}

@inproceedings{haeuslschmid_design_2016,
	address = {New York, NY, USA},
	series = {{CHI} '16},
	title = {A {Design} {Space} to {Support} the {Development} of {Windshield} {Applications} for the {Car}},
	isbn = {978-1-4503-3362-7},
	url = {https://dl.acm.org/doi/10.1145/2858036.2858336},
	doi = {10.1145/2858036.2858336},
	abstract = {In this paper we present a design space for interactive windshield displays in vehicles and discuss how this design space can support designers in creating windshield applications for drivers, passengers, and pedestrians. Our work is motivated by numerous examples in other HCI-related areas where seminal design space papers served as a valuable basis to evolve the respective field -- most notably mobile devices, automotive user interfaces, and interactive public displays. The presented design space is based on a comprehensive literature review. Furthermore we present a classification of 211 windshield applications, derived from a survey of research projects and commercial products as well as from focus groups. We showcase the utility of our work for designers of windshield applications through two scenarios. Overall, our design space can help building applications for diverse use cases. This includes apps inside and outside the car as well as applications for specific areas (fire fighters, police, ambulance).},
	urldate = {2025-03-06},
	booktitle = {Proceedings of the 2016 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Haeuslschmid, Renate and Pfleging, Bastian and Alt, Florian},
	year = {2016},
	keywords = {Read, Important},
	pages = {5076--5091},
	file = {Full Text PDF:C\:\\Users\\giand\\Zotero\\storage\\SDTW8RJM\\Haeuslschmid et al. - 2016 - A Design Space to Support the Development of Windshield Applications for the Car.pdf:application/pdf},
}

@inproceedings{stevens_using_2019,
	address = {New York, NY, USA},
	series = {{CHI} '19},
	title = {Using {Time} and {Space} {Efficiently} in {Driverless} {Cars}: {Findings} of a {Co}-{Design} {Study}},
	isbn = {978-1-4503-5970-2},
	shorttitle = {Using {Time} and {Space} {Efficiently} in {Driverless} {Cars}},
	url = {https://dl.acm.org/doi/10.1145/3290605.3300635},
	doi = {10.1145/3290605.3300635},
	abstract = {The alternative use of travel time is a widely discussed benefits of driverless cars. We therefore conducted 14 co-design sessions to examine how people manage their time, to determine how they perceive the value of time in driverless cars and derive design implications. Our findings suggest that driverless mobility will affect people's use of travel time and their time management in general. The participants repeatedly stated the desire of completing tasks while traveling to save time for activities that are normally neglected in everyday life. Using travel time efficiently requires using car space efficiently. We found out that the design concept of tiny houses could serve as common design pattern to deal with the limited space within cars and support diverse needs.},
	urldate = {2025-03-11},
	booktitle = {Proceedings of the 2019 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Stevens, Gunnar and Bossauer, Paul and Vonholdt, Stephanie and Pakusch, Christina},
	year = {2019},
	keywords = {Read},
	pages = {1--14},
	file = {Full Text PDF:C\:\\Users\\giand\\Zotero\\storage\\5IDS92BD\\Stevens et al. - 2019 - Using Time and Space Efficiently in Driverless Cars Findings of a Co-Design Study.pdf:application/pdf},
}

@article{schlosmacher_audi_nodate,
	title = {Audi {Aicon} concept car – autonomous on course for the future},
	language = {en},
	author = {Schloßmacher, Josef},
	file = {PDF:C\:\\Users\\giand\\Zotero\\storage\\F3XL6LEJ\\Schloßmacher - Audi Aicon concept car – autonomous on course for the future.pdf:application/pdf},
}

@article{stiegemeier_i_2022,
	title = {\textit{“{Do} {I} really need it?”:} {An} explorative study of acceptance and usage of in-vehicle technology},
	volume = {84},
	issn = {1369-8478},
	shorttitle = {\textit{“{Do} {I} really need it?}},
	url = {https://www.sciencedirect.com/science/article/pii/S1369847821002618},
	doi = {10.1016/j.trf.2021.11.011},
	abstract = {The vehicle is increasingly equipped with additional technology assisting and entertaining the driver. To improve the systems and increase their usage, it is important to understand what influences the acceptance of technology in the vehicle. An online survey was conducted assessing which systems drivers own and use in their vehicles today. For the equipped systems, the reasons why N = 304 drivers do not use their in-vehicle technology were qualitatively explored. An inductive content analysis revealed 13 categories in total. The three categories “Need”, “Context and Task”, and “Reliability” were associated with Perceived Usefulness while “Increased Effort” and “Aversion” were associated with Perceived Ease of Use (Venkatesh, 2000). In addition, the influencing factors are further extended with the “Preference for Own Action”, “Distrust”, “Safety”, “Knowledge”, and “Habit”. The findings reveal subjectively important antecedents of the acceptance of in-vehicle technology and provide new insights, especially on usage barriers. An Integrated Acceptance Model (IAM) is derived from the identified categories to inform future research and facilitate a holistic view on factors influencing technology acceptance.},
	urldate = {2025-03-12},
	journal = {Transportation Research Part F: Traffic Psychology and Behaviour},
	author = {Stiegemeier, Dina and Bringeland, Sabrina and Kraus, Johannes and Baumann, Martin},
	month = jan,
	year = {2022},
	keywords = {Assistance systems, In-vehicle infotainment systems, Qualitative research, Technology acceptance, Technology acceptance model, User-centered design},
	pages = {65--82},
	file = {PDF:C\:\\Users\\giand\\Zotero\\storage\\Q5FW4G48\\Stiegemeier et al. - 2022 - “Do I really need it” An explorative study of acceptance and usage of in-vehicle technology.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\giand\\Zotero\\storage\\WM5NU89S\\S1369847821002618.html:text/html},
}

@inproceedings{berger_tactile_2019,
	address = {New York, NY, USA},
	series = {{AutomotiveUI} '19},
	title = {A tactile interaction concept for in-car passenger infotainment systems},
	isbn = {978-1-4503-6920-6},
	url = {https://dl.acm.org/doi/10.1145/3349263.3351914},
	doi = {10.1145/3349263.3351914},
	abstract = {Many modern cars offer in-vehicle infotainment systems to enable information and entertainment features. Often, these systems use touchscreen-based interaction concepts, which can be tedious (holding the arm) and imprecise due to the mobile context. In addition, most systems are driver-targeted and neglect the interaction by passengers. In this paper, we therefore investigate the use of an absolute indirect touch interaction concept with tactile feedback to enable passenger interaction with an infotainment system with the goal to ease screen navigation and improve user experience. Results from an experiment (N=18) reveal that this approach performs well regarding usability and user experience for both entertainment and infotainment functions.},
	urldate = {2025-03-12},
	booktitle = {Proceedings of the 11th {International} {Conference} on {Automotive} {User} {Interfaces} and {Interactive} {Vehicular} {Applications}: {Adjunct} {Proceedings}},
	publisher = {Association for Computing Machinery},
	author = {Berger, Melanie and Bernhaupt, Regina and Pfleging, Bastian},
	month = sep,
	year = {2019},
	keywords = {Read, in-vehicle interactions},
	pages = {109--114},
	file = {Full Text PDF:C\:\\Users\\giand\\Zotero\\storage\\87JDEEH5\\Berger et al. - 2019 - A tactile interaction concept for in-car passenger infotainment systems.pdf:application/pdf},
}

@article{bakker_interaction-attention_2016,
	title = {The interaction-attention continuum : considering various levels of human attention in interaction design},
	volume = {10},
	issn = {1991-3761},
	shorttitle = {The interaction-attention continuum},
	url = {http://www.ijdesign.org/ojs/index.php/IJDesign/article/view/2341/737},
	abstract = {Interactive systems are traditionally operated with undivided attention. Recently, such systems have begun to involve autonomous system behavior that takes place outside the user’s behest and attentional field. In everyday life, people perform actions with varying levels of attention. For example, we routinely wash our hands in our periphery of attention while focusing on having a conversation, or we might consciously focus on washing our hands if trying to remove paint from them. We argue that interactive systems currently cover only two extreme ends of a full spectrum of human attention abilities. With computing technology becoming ubiquitously present, the need increases to seamlessly fit interactions with technology into everyday routines. Inspired by influential early visions on ubiquitous computing (Weiser, 1991; Weiser \& Brown, 1997), we believe that interfaces should facilitate interaction at varied levels of attention to achieve this, these being focused interaction, peripheral interaction and implicit interaction. The concept of the interaction-attention continuum presented here aims to support design researchers in facilitating Human-Computer Interaction to shift between these interaction types. We use four case studies on the design of interfaces for interactive lighting systems to illustrate the application of the interaction-attention continuum and to discuss considerations for design along the continuum.},
	number = {2},
	urldate = {2025-03-15},
	journal = {International Journal of Design},
	author = {Bakker, S. and Niemantsverdriet, K.},
	month = aug,
	year = {2016},
	keywords = {Started Reading/Skimmed, Calm Technology, Tangible Interaction, Ubiquitous Computing},
	pages = {1--14},
	file = {PDF:C\:\\Users\\giand\\Zotero\\storage\\LF6B8CC4\\Bakker and Niemantsverdriet - 2016 - The interaction-attention continuum  considering various levels of human attention in interaction d.pdf:application/pdf},
}

@inproceedings{parzer_flextiles_2016,
	address = {New York, NY, USA},
	series = {{CHI} {EA} '16},
	title = {{FlexTiles}: {A} {Flexible}, {Stretchable}, {Formable}, {Pressure}-{Sensitive}, {Tactile} {Input} {Sensor}},
	isbn = {978-1-4503-4082-3},
	shorttitle = {{FlexTiles}},
	url = {https://dl.acm.org/doi/10.1145/2851581.2890253},
	doi = {10.1145/2851581.2890253},
	abstract = {In the FlexTiles demonstration, we present a flexible, stretchable, pressure-sensitive, tactile input sensor consisting of three layers of fabric. We demonstrate the implementation of FlexTiles for covering large areas, 3D objects, and deformable underlying shapes. In order to measure these large areas with high framerate, we demonstrate a simple measurement implementation. Finally, we outline the benefits of our system compared to other tactile sensing techniques.},
	urldate = {2025-03-15},
	booktitle = {Proceedings of the 2016 {CHI} {Conference} {Extended} {Abstracts} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Parzer, Patrick and Probst, Kathrin and Babic, Teo and Rendl, Christian and Vogl, Anita and Olwal, Alex and Haller, Michael},
	year = {2016},
	keywords = {Not important},
	pages = {3754--3757},
	file = {Full Text PDF:C\:\\Users\\giand\\Zotero\\storage\\2GFEYT2W\\Parzer et al. - 2016 - FlexTiles A Flexible, Stretchable, Formable, Pressure-Sensitive, Tactile Input Sensor.pdf:application/pdf},
}

@inproceedings{naumann_intuitive_2007,
	title = {Intuitive {Use} of {User} {Interfaces}: {Defining} a {Vague} {Concept}},
	isbn = {978-3-540-73331-7},
	shorttitle = {Intuitive {Use} of {User} {Interfaces}},
	url = {https://link.springer.com/chapter/10.1007/978-3-540-73331-7_14},
	doi = {10.1007/978-3-540-73331-7_14},
	abstract = {In this paper we present a general definition of the concept \&\#8217;intuitive use of user interfaces\&\#8217; on the basis of our current interdisciplinary work. \&\#8217;Intuitive use\&\#8217; is regarded as a characteristic of human-machine systems. It refers to a...},
	language = {en},
	urldate = {2025-03-20},
	booktitle = {Engineering {Psychology} and {Cognitive} {Ergonomics}},
	publisher = {Springer, Berlin, Heidelberg},
	author = {Naumann, Anja and Hurtienne, Jörn and Israel, Johann Habakuk and Mohs, Carsten and Kindsmüller, Martin Christof and Meyer, Herbert A. and Hußlein, Steffi},
	year = {2007},
	note = {ISSN: 1611-3349},
	keywords = {Read, Intuitiveness},
	pages = {128--136},
	file = {Full Text PDF:C\:\\Users\\giand\\Zotero\\storage\\XHLNCJQG\\Naumann et al. - 2007 - Intuitive Use of User Interfaces Defining a Vague Concept.pdf:application/pdf},
}

@inproceedings{ullrich_magical_2010,
	address = {New York, NY, USA},
	series = {{NordiCHI} '10},
	title = {From magical experience to effortlessness: an exploration of the components of intuitive interaction},
	isbn = {978-1-60558-934-3},
	shorttitle = {From magical experience to effortlessness},
	url = {https://dl.acm.org/doi/10.1145/1868914.1869033},
	doi = {10.1145/1868914.1869033},
	abstract = {Though researchers, industry and users largely agree that products must be 'intuitive' to use, there is little agreement on what is meant by this claim. In order to clarify the concept and, in particular, its differentiation to usability we choose a phenomenological approach. Overall, we identify four relevant subcomponents of intuitive interaction, whose origin is rooted in HCI and decision making research: Effortlessness, Gut Feeling, Verbalizability, and Magical Experience. Two user studies (N=115, N=37) provide further insights into the complex nature of intuitiveness. We conclude that there are systematic variations in the respective components' specification which can be regarded as particular patterns of intuitive interaction. Amongst others, these patterns depend on the product category and one's prior knowledge in the product domain.},
	urldate = {2025-03-20},
	booktitle = {Proceedings of the 6th {Nordic} {Conference} on {Human}-{Computer} {Interaction}: {Extending} {Boundaries}},
	publisher = {Association for Computing Machinery},
	author = {Ullrich, Daniel and Diefenbach, Sarah},
	year = {2010},
	keywords = {Read, Intuitiveness},
	pages = {801--804},
	file = {Full Text PDF:C\:\\Users\\giand\\Zotero\\storage\\ZJSV72AN\\Ullrich and Diefenbach - 2010 - From magical experience to effortlessness an exploration of the components of intuitive interaction.pdf:application/pdf},
}

@inproceedings{naumann_design_2008,
	address = {New York, NY, USA},
	series = {{CHI} {EA} '08},
	title = {Design for intuitive use: beyond usability},
	isbn = {978-1-60558-012-8},
	shorttitle = {Design for intuitive use},
	url = {https://dl.acm.org/doi/10.1145/1358628.1358688},
	doi = {10.1145/1358628.1358688},
	abstract = {After a short introduction to our concept of intuitive use of user interfaces we would like to invite the interdisci-plinary CHI community to discuss at least two impor-tant issues, namely: How does intuitive use and aes-thetics relate? And, does physicality enable intuitive use? In the following, we present some provoking the-ses to trigger the discussion of these questions.},
	urldate = {2025-03-20},
	booktitle = {{CHI} '08 {Extended} {Abstracts} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Naumann, Anja B. and Pohlmeyer, Anna E. and Husslein, Steffi and Kindsmüller, Martin Christof and Mohs, Carsten and Israel, Johann Habakuk},
	month = apr,
	year = {2008},
	keywords = {Started Reading/Skimmed, Intuitiveness, Not important},
	pages = {2375--2378},
	file = {Full Text PDF:C\:\\Users\\giand\\Zotero\\storage\\P23VWG65\\Naumann et al. - 2008 - Design for intuitive use beyond usability.pdf:application/pdf},
}

@article{osiurak_what_2017,
	title = {What is an affordance? 40 years later},
	volume = {77},
	issn = {0149-7634},
	shorttitle = {What is an affordance?},
	url = {https://www.sciencedirect.com/science/article/pii/S0149763416305061},
	doi = {10.1016/j.neubiorev.2017.04.014},
	abstract = {About 40 years ago, James J. Gibson coined the term “affordance” to describe the action possibilities offered to an animal by the environment with reference to the animal’s action capabilities. Since then, this notion has acquired a multitude of meanings, generating confusion in the literature. Here, we offer a clear operationalization of the concept of affordances and related concepts in the field of tool use. Our operationalization is organized around the distinction between the physical (what is objectively observable) and neurocognitive (what is subjectively experienced) levels. This leads us to propose that motor control (dorso-dorsal system), mechanical knowledge (ventro-dorsal system) and function knowledge (ventral system) could be neurocognitive systems respectively involved in the perception of affordances, the understanding of mechanical actions and the storage of contextual relationships (three action-system model; 3AS). We end by turning to two key issues that can be addressed within 3AS. These issues concern the link between affordances and tool incorporation, and the constraints posed by affordances for tool use.},
	urldate = {2025-03-20},
	journal = {Neuroscience \& Biobehavioral Reviews},
	author = {Osiurak, François and Rossetti, Yves and Badets, Arnaud},
	month = jun,
	year = {2017},
	keywords = {Affordance, Not important},
	pages = {403--417},
	file = {PDF:C\:\\Users\\giand\\Zotero\\storage\\KYXGBYS8\\Osiurak et al. - 2017 - What is an affordance 40 years later.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\giand\\Zotero\\storage\\Y94RD2GH\\S0149763416305061.html:text/html},
}

@article{mcgrenere_affordances_2000,
	title = {Affordances: {Clarifying} and {Evolving} a {Concept}},
	volume = {Montréal},
	copyright = {Permission is granted to quote short excerpts and to reproduce figures and tables from these proceedings, provided that the source of such material is fully acknowledged.},
	issn = {0713-5424},
	shorttitle = {Affordances},
	url = {http://graphicsinterface.org/proceedings/gi2000/gi2000-24/},
	doi = {10.20380/GI2000.24},
	abstract = {The concept of affordance is popular in the HCI community but not well understood. Donald Norman appropriated the concept of affordances from James J. Gibson for the design of common objects and both implicitly and explicitly adjusted the meaning given by Gibson. There was, however, ambiguity in Norman's original definition and use of affordances which he has subsequently made efforts to clarify. His definition germinated quickly and through a review of the HCI literature we show that this ambiguity has lead to widely varying uses of the concept. Norman has recently acknowledged the ambiguity, however, important clarifications remain. Using affordances as a basis, we elucidate the role of the designer and the distinction between usefulness and usability. We expand Gibson's definition into a framework for design.},
	language = {en},
	urldate = {2025-03-21},
	journal = {Proceedings of Graphics Interface 2000},
	author = {McGrenere, Joanna and Ho, Wayne},
	editor = {Fels, Sidney and Poulin, Pierre},
	year = {2000},
	note = {Artwork Size: 8 pages, 142.86 KB
ISBN: 9780969533894
Medium: application/pdf
Publisher: Canadian Human-Computer Communications Society},
	keywords = {Started Reading/Skimmed, Affordance},
	pages = {8 pages, 142.86 KB},
	file = {PDF:C\:\\Users\\giand\\Zotero\\storage\\BU9R3KQA\\McGrenere and Ho - 2000 - Affordances Clarifying and Evolving a Concept.pdf:application/pdf},
}

@inproceedings{vyas_affordance_2006,
	address = {New York, NY, USA},
	series = {{ECCE} '06},
	title = {Affordance in interaction},
	isbn = {978-3-906509-23-5},
	url = {https://dl.acm.org/doi/10.1145/1274892.1274907},
	doi = {10.1145/1274892.1274907},
	abstract = {The concept of affordance has different interpretations in the field of Human-Computer Interaction (HCI). However, its treatment has been merely as a one-to-one relationship between a user and a technology. We believe that a broader view of affordances is needed which encompasses social and cultural aspects of our everyday life. We propose an interaction-centered view of affordance that can be useful for developing better understandings of designed artefacts. An interaction-centered view of affordance suggests that affordance is an interpretative relationship between users and the technology that emerges during the users' interaction with the technology in the lived environments. We distinguish two broad classes of affordances: affordance in Information and affordance in Articulation. Affordance in information refers to users' understanding of a technology based on their semantic and syntactic interpretation; and affordance in articulation refers to users' interpretations about the use of the technology. We also argue that the notion of affordance should be treated at two levels: at the 'artefact level' and at the 'practice level'. Consequently, we provide two examples to demonstrate our arguments.},
	urldate = {2025-03-21},
	booktitle = {Proceedings of the 13th {Eurpoean} conference on {Cognitive} ergonomics: trust and control in complex socio-technical systems},
	publisher = {Association for Computing Machinery},
	author = {Vyas, Dhaval and Chisalita, Cristina M. and van der Veer, Gerrit C.},
	month = sep,
	year = {2006},
	keywords = {Started Reading/Skimmed, Affordance},
	pages = {92--99},
	file = {Full Text PDF:C\:\\Users\\giand\\Zotero\\storage\\5DKVX9PV\\Vyas et al. - 2006 - Affordance in interaction.pdf:application/pdf},
}

@inproceedings{heijboer_physical_2019,
	address = {New York, NY, USA},
	series = {{AutomotiveUI} '19},
	title = {Physical fights back: introducing a model for bridging analog digital interactions},
	isbn = {978-1-4503-6920-6},
	shorttitle = {Physical fights back},
	url = {https://dl.acm.org/doi/10.1145/3349263.3351510},
	doi = {10.1145/3349263.3351510},
	abstract = {Current transformational developments in automotive user interface (UI) technology are causing a shift in emphasis from safety and efficiency to emotion and flexibility. The many factors to consider in parallel make this a difficult process, in which technological affordances all too easily push the user to the background. To address this issue, this paper introduces an interaction model linking the different tangible control elements, including smartphone functionality, and shows how non-driving-related activities (e.g. climate control, multimedia access) can be represented physically. Next, a working prototype is presented that supports the design and development of novel tactile UIs. By integrating layers of sensors and actuators, a flexible UI is created that pushes technology to the background, giving proper attention to the user again and enabling effective research on how to make the digital world tangible for users.},
	urldate = {2025-03-26},
	booktitle = {Proceedings of the 11th {International} {Conference} on {Automotive} {User} {Interfaces} and {Interactive} {Vehicular} {Applications}: {Adjunct} {Proceedings}},
	publisher = {Association for Computing Machinery},
	author = {Heijboer, Stefan and Schumann, Josef and Tempelman, Erik and Groen, Pim},
	month = sep,
	year = {2019},
	pages = {93--98},
	file = {Full Text PDF:C\:\\Users\\giand\\Zotero\\storage\\8IQHYVS2\\Heijboer et al. - 2019 - Physical fights back introducing a model for bridging analog digital interactions.pdf:application/pdf},
}

@inproceedings{poupyrev_project_2016,
	address = {New York, NY, USA},
	series = {{CHI} '16},
	title = {Project {Jacquard}: {Interactive} {Digital} {Textiles} at {Scale}},
	isbn = {978-1-4503-3362-7},
	shorttitle = {Project {Jacquard}},
	url = {https://dl.acm.org/doi/10.1145/2858036.2858176},
	doi = {10.1145/2858036.2858176},
	abstract = {Project Jacquard presents manufacturing technologies that enable deploying invisible ubiquitous interactivity at scale. We propose novel interactive textile materials that can be manufactured inexpensively using existing textile weaving technology and equipment.The development of touch-sensitive textiles begins with the design and engineering of a new highly conductive yarn. The yarns and textiles can be produced by standard textile manufacturing processes and can be dyed to any color, made with a number of materials, and designed to a variety of thicknesses and textures to be consistent with garment designers' needs.We describe the development of yarn, textiles, garments, and user interactivity; we present the opportunities and challenges of creating a manufacturable interactive textile for wearable computing.},
	urldate = {2025-03-26},
	booktitle = {Proceedings of the 2016 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Poupyrev, Ivan and Gong, Nan-Wei and Fukuhara, Shiho and Karagozler, Mustafa Emre and Schwesig, Carsten and Robinson, Karen E.},
	year = {2016},
	keywords = {Fabrics, Not important},
	pages = {4216--4227},
	file = {PDF:C\:\\Users\\giand\\Zotero\\storage\\S75QQ2CH\\Poupyrev et al. - 2016 - Project Jacquard Interactive Digital Textiles at Scale.pdf:application/pdf;Video:C\:\\Users\\giand\\Zotero\\storage\\TSHU2BWL\\p4216-poupyrev.mp4:video/mp4},
}

@inproceedings{wensveen_interaction_2004,
	address = {New York, NY, USA},
	series = {{DIS} '04},
	title = {Interaction frogger: a design framework to couple action and function through feedback and feedforward},
	isbn = {978-1-58113-787-3},
	shorttitle = {Interaction frogger},
	url = {https://dl.acm.org/doi/10.1145/1013115.1013140},
	doi = {10.1145/1013115.1013140},
	abstract = {In this paper we present a design framework to analyze person-product interaction. Its focus is on how the user's action and the product's function are coupled through different types of feedback and feedforward: inherent and augmented information. Instead of using the notion of 'coupling' in an abstract sense, our framework tries to give six practical characteristics for coupling action and information, i.e., time, location, direction, dynamics, modality and expression. Unifying action and information on each of these aspects makes the interaction intuitive. The framework invites and challenges designers to explore couplings leading towards embodied freedom of interaction.},
	urldate = {2025-03-26},
	booktitle = {Proceedings of the 5th conference on {Designing} interactive systems: processes, practices, methods, and techniques},
	publisher = {Association for Computing Machinery},
	author = {Wensveen, S. A. G. and Djajadiningrat, J. P. and Overbeeke, C. J.},
	month = aug,
	year = {2004},
	keywords = {Important, Read},
	pages = {177--184},
	file = {Full Text PDF:C\:\\Users\\giand\\Zotero\\storage\\XGXG4LJU\\Wensveen et al. - 2004 - Interaction frogger a design framework to couple action and function through feedback and feedforwa.pdf:application/pdf},
}

@inproceedings{riegler_investigating_2018,
	address = {New York, NY, USA},
	series = {{PerDis} '18},
	title = {Investigating {User} {Preferences} for {Windshield} {Displays} in {Automated} {Vehicles}},
	isbn = {978-1-4503-5765-4},
	url = {https://dl.acm.org/doi/10.1145/3205873.3205885},
	doi = {10.1145/3205873.3205885},
	abstract = {Windshield displays are a promising technology for automotive applications. They easily allow to augment the capabilities of drivers or display content relevant for non-driving related activities. However, little information is available on how potential users would utilize these displays. In this paper we present the results of a user study (N=31) addressing user preferences for windshield displays in automated driving. Our goal was to find out how potential users would like applications to appear in terms of size, position, and content type. Participants could freely choose preferred position and size of multiple windows on an artificial "ideal" windshield display. We further distinguished between two levels of automation (conditional and full). Initial results of our experiment (presented in form of heatmaps) indicate differences considering the level of vehicle automation and reveal the most important areas for various content types. This can help designers and developers of automotive applications to enhance user experience.},
	urldate = {2025-03-27},
	booktitle = {Proceedings of the 7th {ACM} {International} {Symposium} on {Pervasive} {Displays}},
	publisher = {Association for Computing Machinery},
	author = {Riegler, Andreas and Wintersberger, Philipp and Riener, Andreas and Holzmann, Clemens},
	month = jun,
	year = {2018},
	keywords = {Read, Important},
	pages = {1--7},
	file = {Full Text PDF:C\:\\Users\\giand\\Zotero\\storage\\6UIELHTD\\Riegler et al. - 2018 - Investigating User Preferences for Windshield Displays in Automated Vehicles.pdf:application/pdf},
}

@article{riegler_augmented_2019,
	title = {Augmented {Reality} {Windshield} {Displays} and {Their} {Potential} to {Enhance} {User} {Experience} in {Automated} {Driving}},
	volume = {18},
	copyright = {De Gruyter expressly reserves the right to use all content for commercial text and data mining within the meaning of Section 44b of the German Copyright Act.},
	issn = {2196-6826},
	url = {https://www.degruyter.com/document/doi/10.1515/icom-2018-0033/html},
	doi = {10.1515/icom-2018-0033},
	abstract = {Increasing vehicle automation presents challenges as drivers of highly automated vehicles become more disengaged from the primary driving task. However, even with fully automated driving, there will still be activities that require interfaces for vehicle-passenger interactions. Windshield displays are a technology with a promising potential for automated driving, as they are able to provide large content areas supporting drivers in non-driving related activities. However, it is still unknown how potential drivers or passengers would use these displays. This work addresses user preferences for windshield displays in automated driving. Participants of a user study (N=63N=63) were presented two levels of automation (conditional and full), and could freely choose preferred positions, content types, as well as size, transparency levels and importance levels of content windows using a simulated “ideal” windshield display. We visualized the results in form of heatmap data which show that user preferences differ with respect to the level of automation, age, gender, or environment aspects. These insights can help designers of interiors and in-vehicle applications to provide a rich user experience in highly automated vehicles.},
	language = {en},
	number = {2},
	urldate = {2025-03-28},
	journal = {i-com},
	author = {Riegler, Andreas and Wintersberger, Philipp and Riener, Andreas and Holzmann, Clemens},
	month = aug,
	year = {2019},
	note = {Publisher: Oldenbourg Wissenschaftsverlag},
	keywords = {Started Reading/Skimmed},
	pages = {127--149},
	file = {Full Text PDF:C\:\\Users\\giand\\Zotero\\storage\\3YWHJL4M\\Riegler et al. - 2019 - Augmented Reality Windshield Displays and Their Potential to Enhance User Experience in Automated Dr.pdf:application/pdf},
}

@inproceedings{riegler_stickywsd_2020,
	address = {New York, NY, USA},
	series = {{MUM} '20},
	title = {{StickyWSD}: {Investigating} {Content} {Positioning} on a {Windshield} {Display} for {Automated} {Driving}},
	isbn = {978-1-4503-8870-2},
	shorttitle = {{StickyWSD}},
	url = {https://dl.acm.org/doi/10.1145/3428361.3428405},
	doi = {10.1145/3428361.3428405},
	abstract = {Windshield displays (WSDs) are a promising new technology to augment the entire windscreen with additional information about vehicle state, highlight critical objects in the surrounding, or use the screen as replacement for a conventional display. Typically, augmentation is provided in a screen-fixed manner as overlay on the windscreen. However, it is unclear to date if this is optimal in terms of usability/UX and further there is no golden standard suggesting where to place and how to manage content on such large displays in a vehicular environment. In this work, we propose ”StickyWSD” – a world-fixed positioning strategy – and evaluate its impact on quantitative and qualitative measures compared to screen-fixed positioning. Results from a user study conducted in a virtual reality driving simulator (N = 23) suggest that the dynamic world-fixed positioning technique shows increased task performance and lowered error rates as well as faster take-over times. Subjective evaluations show no clear preferences between both conditions. We propose to display text content on the WSD in world-fixed modality but further studies on context- and content-awareness are required.},
	urldate = {2025-03-28},
	booktitle = {Proceedings of the 19th {International} {Conference} on {Mobile} and {Ubiquitous} {Multimedia}},
	publisher = {Association for Computing Machinery},
	author = {Riegler, Andreas and Weigl, Klemens and Riener, Andreas and Holzmann, Clemens},
	month = nov,
	year = {2020},
	keywords = {Started Reading/Skimmed},
	pages = {143--151},
	file = {Full Text PDF:C\:\\Users\\giand\\Zotero\\storage\\SCTYQKFU\\Riegler et al. - 2020 - StickyWSD Investigating Content Positioning on a Windshield Display for Automated Driving.pdf:application/pdf},
}

@inproceedings{riegler_adaptive_2019,
	title = {Adaptive {Dark} {Mode}: {Investigating} {Text} and {Transparency} of {Windshield} {Display} {Content} for {Automated} {Driving}},
	shorttitle = {Adaptive {Dark} {Mode}},
	url = {https://dl.gi.de/handle/20.500.12116/25231},
	abstract = {Windshield displays are a promising technology for automotive application. In combination with the emergence of highly automated vehicles, chances are that work-related activities will become more popular on the daily commute to and from work. While windshield displays can show content relevant for non-driving related activities, little information is available on how potential users would utilize these displays in terms of text and background color as well as transparency usage. In this paper, we present the results of two user studies (pilot study: N = 10, main study: N = 20) addressing this issue. Findings from quantitative measurements and qualitative pre-/post study surveys and interviews suggest a strong preference for the chat window being located on the driver side presented in dark mode with adaptive background transparency levels based on the luminance of the outside environment.},
	language = {en},
	urldate = {2025-03-28},
	publisher = {Gesellschaft für Informatik e.V.},
	author = {Riegler, Andreas and Riener, Andreas and Holzmann, Clemens},
	year = {2019},
	keywords = {Started Reading/Skimmed},
	pages = {10.18420/muc2019},
	file = {Full Text PDF:C\:\\Users\\giand\\Zotero\\storage\\63AI9I55\\Riegler et al. - 2019 - Adaptive Dark Mode Investigating Text and Transparency of Windshield Display Content for Automated.pdf:application/pdf},
}

@book{wigdor_brave_2011,
	address = {Burlington, Mass},
	title = {Brave {NUI} world: designing natural user interfaces for touch and gesture},
	isbn = {978-0-12-382231-4},
	shorttitle = {Brave {NUI} world},
	publisher = {Morgan Kaufmann},
	author = {Wigdor, Daniel and Wixon, Dennis},
	year = {2011},
	keywords = {Read},
}

@book{lipson_driverless_2017,
	address = {Cambridge},
	title = {Driverless: intelligent cars and the road ahead},
	isbn = {978-0-262-53447-5},
	shorttitle = {Driverless},
	abstract = {"Few inventions have changed life as much as the car. These large hunks of steel and horsepower are everywhere, so ubiquitous and deeply intertwined with our lives, jobs and families that we barely pay them any attention. The mundane car, however, is about to become the ultimate mobility device. Thanks to rapid advances in robotics and artificial intelligence, cars are poised to morph into the first mainstream autonomous robots that we will entrust with our lives, creating a cascade of social and economic change. - How do driverless cars work? - Why has it taken nearly 100 years to create a working driverless car? - What are the technological and social barriers? - How do roboticists create artificial perception and what is "Deep Learning"? - How will this technology change our lives, our businesses, and our cities? - What new opportunities lie ahead?"--Provided by publisher},
	language = {eng},
	publisher = {MIT press},
	author = {Lipson, Hod and Kurman, Melba},
	year = {2017},
}

@article{litman_autonomous_2024,
	title = {Autonomous {Vehicle} {Implementation} {Predictions}: {Implications} for {Transport} {Planning}},
	url = {http://www.vtpi.org/avip.pdf},
	abstract = {This report explores the impacts of autonomous (also called self-driving, driverless or robotic) vehicles, and their implications for transportation planning. It investigates how quickly such vehicles are likely to develop and be deployed based on experience with previous vehicle technologies; their likely benefits and costs; how they will affect travel activity; and their impacts on road, parking and public transit planning. This analysis indicates that Level 5 autonomous vehicles, able to operate without a driver, may be commercially available and legal to use in some jurisdictions by the late 2020s, but will initially have high costs and limited performance. Some benefits, such as independent mobility for affluent non-drivers, may begin in the 2030s but most impacts, including reduced traffic and parking congestion, independent mobility for low-income people (and therefore reduced need for public transit), increased safety, energy conservation and pollution reductions, will only be significant when autonomous vehicles become common and affordable, probably in the 2040s to 2060s, and some benefits may require dedicated autonomous vehicle lanes, which raises social equity concerns.},
	language = {en},
	urldate = {2025-04-02},
	author = {Litman, Todd},
	month = oct,
	year = {2024},
	pages = {1--49},
	file = {PDF:C\:\\Users\\giand\\Zotero\\storage\\YP265NBP\\Litman - Autonomous Vehicle Implementation Predictions Implications for Transport Planning.pdf:application/pdf},
}

@inproceedings{desjardins_living_2016,
	address = {New York, NY, USA},
	series = {{CHI} '16},
	title = {Living {In} {A} {Prototype}: {A} {Reconfigured} {Space}},
	isbn = {978-1-4503-3362-7},
	shorttitle = {Living {In} {A} {Prototype}},
	url = {https://dl.acm.org/doi/10.1145/2858036.2858261},
	doi = {10.1145/2858036.2858261},
	abstract = {In this paper, we present a twenty-three months autobiographical design project of converting a Mercedes Sprinter van into a camper van. This project allows us to investigate the complexities and nuances of a case where people engage in a process of making, transforming and adapting a space they live in. This example opens a radically different and productive context for revisiting concepts that are currently at the center of human-computer interaction (HCI) research: ubiquitous computing, home automation, smart homes, and the Internet of Things. We offer six qualities characterizing the evolving relationship between the makers and the lived-in environment: the van. We conclude with a discussion on the two themes of living in a reconfigured home and prototype qualities in a reconfigured space, and a critical reflection around the theme of the invariably unfinished home.},
	urldate = {2025-04-02},
	booktitle = {Proceedings of the 2016 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Desjardins, Audrey and Wakkary, Ron},
	year = {2016},
	pages = {5274--5285},
	file = {Full Text PDF:C\:\\Users\\giand\\Zotero\\storage\\KYRK5Q7P\\Desjardins and Wakkary - 2016 - Living In A Prototype A Reconfigured Space.pdf:application/pdf},
}

@article{parkhurst_heuristic_2019,
	title = {Heuristic {Evaluation} of {A} {Tesla} {Model} 3 {Interface}},
	volume = {63},
	issn = {1071-1813},
	url = {https://doi.org/10.1177/1071181319631336},
	doi = {10.1177/1071181319631336},
	abstract = {Usability research is important in our age of developing technology as it has significant implications for how technology is perceived by users. In 2017 Tesla released the Model 3, their most affordable electric-only vehicle to date. The vehicle is unique in its simplistic inner controls, composed of a single centralized touchscreen and instrumentation on the steering wheel. A heuristic analysis was conducted on the interface system of a Model 3 and several heuristic violations were identified.Suggestions to remedy the usability issues were provided along with considerations for future design of such interfaces.},
	language = {EN},
	number = {1},
	urldate = {2025-04-02},
	journal = {Proceedings of the Human Factors and Ergonomics Society Annual Meeting},
	author = {Parkhurst, Eva L. and Conner, Lindsay B. and Ferraro, James C. and Navarro, Mar E. and Mouloua, Mustapha},
	month = nov,
	year = {2019},
	note = {Publisher: SAGE Publications Inc},
	pages = {1515--1519},
	file = {SAGE PDF Full Text:C\:\\Users\\giand\\Zotero\\storage\\H96GVCG5\\Parkhurst et al. - 2019 - Heuristic Evaluation of A Tesla Model 3 Interface.pdf:application/pdf},
}

@misc{noauthor_tesla_2024,
	title = {Tesla {Model} {Y} secures position as world’s best-selling car in 2023},
	url = {https://www.jato.com/resources/media-and-press-releases/tesla-model-y-worlds-best-selling-car-2023},
	abstract = {Explore the Tesla Model Y's rise to the world's best-selling car of 2023. Learn from JATO Dynamics data about this electric SUV and its impact on the automotive industry.},
	language = {en},
	  note = {Accessed on 02.04.2025},
	journal = {JATO},
	month = jun,
	year = {2024},
	file = {Snapshot:C\:\\Users\\giand\\Zotero\\storage\\WK3TPJSP\\tesla-model-y-worlds-best-selling-car-2023.html:text/html},
}

@misc{noauthor_new_nodate,
	title = {New {Model} {Y}},
	url = {https://www.tesla.com/modely},
	abstract = {New Model Y is a redesigned, fully electric mid-size SUV with expansive storage, a quieter cabin and advanced safety features.},
	language = {en},
	  note = {Accessed on 02.04.2025},
	journal = {Tesla},
	file = {Snapshot:C\:\\Users\\giand\\Zotero\\storage\\U4CL878Z\\modely.html:text/html},
}


@inproceedings{inbar_make_2011,
	address = {New York, NY, USA},
	series = {{CHI} {EA} '11},
	title = {Make a trip an experience: sharing in-car information with passengers},
	isbn = {978-1-4503-0268-5},
	shorttitle = {Make a trip an experience},
	url = {https://dl.acm.org/doi/10.1145/1979742.1979755},
	doi = {10.1145/1979742.1979755},
	abstract = {Current in-vehicle information systems (IVIS) are designed for use by a single entity - the driver. In this paper we propose that the benefits of IVIS can increase if we also consider the needs of passengers and their potential contribution as additional information handlers who buffer the driver from information overload. The benefits these "incidental users" of IVIS can reap from having trip-related information shared with them include reduced boredom, increased trust and a sense of inclusion. Drivers' benefits include less distraction caused by questions previously aimed at them as the exclusive owners of the trip-related information, and reduced information load by allowing passengers to actively control selected in-car systems.},
	urldate = {2025-04-02},
	booktitle = {{CHI} '11 {Extended} {Abstracts} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Inbar, Ohad and Tractinsky, Noam},
	year = {2011},
	pages = {1243--1248},
	file = {Full Text PDF:C\:\\Users\\giand\\Zotero\\storage\\AH4Y9LUC\\Inbar and Tractinsky - 2011 - Make a trip an experience sharing in-car information with passengers.pdf:application/pdf},
}

@inproceedings{wilfinger_are_2011,
	address = {Berlin, Heidelberg},
	title = {Are {We} {There} {Yet}? {A} {Probing} {Study} to {Inform} {Design} for the {Rear} {Seat} of {Family} {Cars}},
	isbn = {978-3-642-23771-3},
	shorttitle = {Are {We} {There} {Yet}?},
	doi = {10.1007/978-3-642-23771-3_48},
	abstract = {When researching interactive systems in the car, the design space can be divided into the following areas: driver, front seat passenger and rear seat. The latter has so far not been sufficiently addressed in HCI research, which results in an absence of implications for interaction designs in that space. This work presents a cultural probing study investigating the activities and the technology usage in the rear seat as social and physical space. The study was conducted with 20 families over a period of four weeks and unveiled aspects relevant for HCI research: aspects of diversion, educational motivation, togetherness, food as activity, physical space, perception of safety, and mobile computing. In relation to these areas, implications for the design and integration of interactive technology in the rear seat area are deduced. We show that cultural probing in the car is a promising and fruitful approach to get insights on passenger behavior and requirements for interactive systems. To improve the rear seat area and to show the potential of probing results to inform design, a design proposal for an interactive rear seat game called RiddleRide is introduced.},
	language = {en},
	booktitle = {Human-{Computer} {Interaction} – {INTERACT} 2011},
	publisher = {Springer},
	author = {Wilfinger, David and Meschtscherjakov, Alexander and Murer, Martin and Osswald, Sebastian and Tscheligi, Manfred},
	editor = {Campos, Pedro and Graham, Nicholas and Jorge, Joaquim and Nunes, Nuno and Palanque, Philippe and Winckler, Marco},
	year = {2011},
	keywords = {car, cultural probing, design, design space, rear seat},
	pages = {657--674},
	file = {Full Text PDF:C\:\\Users\\giand\\Zotero\\storage\\BYFIIAR4\\Wilfinger et al. - 2011 - Are We There Yet A Probing Study to Inform Design for the Rear Seat of Family Cars.pdf:application/pdf},
}

@article{diels_self-driving_2016,
	series = {Transport in the 21st {Century}: {The} {Application} of {Human} {Factors} to {Future} {User} {Needs}},
	title = {Self-driving carsickness},
	volume = {53},
	issn = {0003-6870},
	url = {https://www.sciencedirect.com/science/article/pii/S0003687015300818},
	doi = {10.1016/j.apergo.2015.09.009},
	abstract = {This paper discusses the predicted increase in the occurrence and severity of motion sickness in self-driving cars. Self-driving cars have the potential to lead to significant benefits. From the driver's perspective, the direct benefits of this technology are considered increased comfort and productivity. However, we here show that the envisaged scenarios all lead to an increased risk of motion sickness. As such, the benefits this technology is assumed to bring may not be capitalised on, in particular by those already susceptible to motion sickness. This can negatively affect user acceptance and uptake and, in turn, limit the potential socioeconomic benefits that this emerging technology may provide. Following a discussion on the causes of motion sickness in the context of self-driving cars, we present guidelines to steer the design and development of automated vehicle technologies. The aim is to limit or avoid the impact of motion sickness and ultimately promote the uptake of self-driving cars. Attention is also given to less well known consequences of motion sickness, in particular negative aftereffects such as postural instability, and detrimental effects on task performance and how this may impact the use and design of self-driving cars. We conclude that basic perceptual mechanisms need to be considered in the design process whereby self-driving cars cannot simply be thought of as living rooms, offices, or entertainment venues on wheels.},
	urldate = {2025-04-02},
	journal = {Applied Ergonomics},
	author = {Diels, Cyriel and Bos, Jelte E.},
	month = mar,
	year = {2016},
	keywords = {Important, Motion sickness},
	pages = {374--382},
	file = {Full Text:C\:\\Users\\giand\\Zotero\\storage\\2XURWXWD\\Diels and Bos - 2016 - Self-driving carsickness.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\giand\\Zotero\\storage\\5YTYI643\\S0003687015300818.html:text/html},
}

@inproceedings{ng_evaluation_2017,
	address = {New York, NY, USA},
	series = {{AutomotiveUI} '17},
	title = {An {Evaluation} of {Touch} and {Pressure}-{Based} {Scrolling} and {Haptic} {Feedback} for {In}-{Car} {Touchscreens}},
	isbn = {978-1-4503-5150-8},
	url = {https://dl.acm.org/doi/10.1145/3122986.3122997},
	doi = {10.1145/3122986.3122997},
	abstract = {An in-car study was conducted to examine different input techniques for list-based scrolling tasks and the effectiveness of haptic feedback for in-car touchscreens. The use of physical switchgear on centre consoles is decreasing which allows designers to develop new ways to interact with in-car applications. However, these new methods need to be evaluated to ensure they are usable. Therefore, three input techniques were tested: direct scrolling, pressure-based scrolling and scrolling using onscreen buttons on a touchscreen. The results showed that direct scrolling was less accurate than using onscreen buttons and pressure input, but took almost half the time when compared to the onscreen buttons and was almost three times quicker than pressure input. Vibrotactile feedback did not improve input performance but was preferred by the users. Understanding the speed vs. accuracy trade-off between these input techniques will allow better decisions when designing safer in-car interfaces for scrolling applications.},
	urldate = {2025-04-02},
	booktitle = {Proceedings of the 9th {International} {Conference} on {Automotive} {User} {Interfaces} and {Interactive} {Vehicular} {Applications}},
	publisher = {Association for Computing Machinery},
	author = {Ng, Alexander and Brewster, Stephen},
	month = sep,
	year = {2017},
	pages = {11--20},
	file = {Full Text PDF:C\:\\Users\\giand\\Zotero\\storage\\UKB9VIZ6\\Ng and Brewster - 2017 - An Evaluation of Touch and Pressure-Based Scrolling and Haptic Feedback for In-Car Touchscreens.pdf:application/pdf},
}


@inproceedings{corsten_hapticase_2015,
	address = {New York, NY, USA},
	series = {{CHI} '15},
	title = {{HaptiCase}: {Back}-of-{Device} {Tactile} {Landmarks} for {Eyes}-{Free} {Absolute} {Indirect} {Touch}},
	isbn = {978-1-4503-3145-6},
	shorttitle = {{HaptiCase}},
	url = {https://dl.acm.org/doi/10.1145/2702123.2702277},
	doi = {10.1145/2702123.2702277},
	abstract = {Using a smartphone for touch input to control apps and games mirrored to a distant screen is difficult, as the user cannot see where she is touching while looking at the distant display. We present HaptiCase, an interaction technique that provides back-of-device tactile landmarks that the user senses with her fingers to estimate the location of her finger in relation to the touchscreen. By pinching the thumb resting above the touch- screen to a finger at the back, the finger position is transferred to the front as the thumb touches the screen. In a study, we compared touch performance of different landmark layouts with a regular landmark-free mobile device. Using a land- mark design of dots on a 3x5 grid significantly improves eyes-free tapping accuracy and allows targets to be as small as 17.5 mm---a 14\% reduction in target size---to cover 99\% of all touches. When users can look at the touchscreen, land- marks have no significant effect on performance. HaptiCase is low-cost, requires no electronics, and works with unmodified software.},
	urldate = {2025-04-02},
	booktitle = {Proceedings of the 33rd {Annual} {ACM} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Corsten, Christian and Cherek, Christian and Karrer, Thorsten and Borchers, Jan},
	month = apr,
	year = {2015},
	pages = {2171--2180},
	file = {Full Text PDF:C\:\\Users\\giand\\Zotero\\storage\\7JUZI85D\\Corsten et al. - 2015 - HaptiCase Back-of-Device Tactile Landmarks for Eyes-Free Absolute Indirect Touch.pdf:application/pdf},
}


@misc{noauthor_2025_nodate,
	title = {2025 {BMW} i7 {All}-{Electric} {Luxury} {Sedan} {\textbar} {All} {Models} \& {Pricing}},
	url = {https://www.bmwusa.com/vehicles/all-electric/i7/sedan/overview.html},
	urldate = {2025-04-03},
	journal = {BMW USA},
	file = {2025 BMW i7 All-Electric Luxury Sedan | All Models & Pricing:C\:\\Users\\giand\\Zotero\\storage\\4JF7STRI\\overview.html:text/html},
}


@misc{noauthor_all_nodate,
	title = {All new {Megane} {E}-{Tech} electric - {Renault}},
	url = {https://www.renault.co.uk/electric-vehicles/megane-electric.html},
	  note = {Accessed on 03.04.2025},
	journal = {Renault},
}

@book{on-road_automated_driving_orad_committee_taxonomy_2021,
	title = {Taxonomy and {Definitions} for {Terms} {Related} to {Driving} {Automation} {Systems} for {On}-{Road} {Motor} {Vehicles}},
	url = {https://doi.org/10.4271/J3016_202104},
	abstract = {This document describes [motor] vehicle driving automation systems that perform part or all of the dynamic driving task (DDT) on a sustained basis. It provides a taxonomy with detailed definitions for six levels of driving automation, ranging from no driving automation (Level 0) to full driving automation (Level 5), in the context of [motor] vehicles (hereafter also referred to as “vehicle” or “vehicles”) and their operation on roadways: Level 0: No Driving Automation Level 1: Driver Assistance Level 2: Partial Driving Automation Level 3: Conditional Driving Automation Level 4: High Driving Automation Level 5: Full Driving Automation These level definitions, along with additional supporting terms and definitions provided herein, can be used to describe the full range of driving automation features equipped on [motor] vehicles in a functionally consistent and coherent manner. “On-road” refers to publicly accessible roadways (including parking areas and private campuses that permit public access) that collectively serve all road users, including cyclists, pedestrians, and users of vehicles with and without driving automation features. The levels apply to the driving automation feature(s) that are engaged in any given instance of on-road operation of an equipped vehicle. As such, although a given vehicle may be equipped with a driving automation system that is capable of delivering multiple driving automation features that perform at different levels, the level of driving automation exhibited in any given instance is determined by the feature(s) that are engaged. This document also refers to three primary actors in driving: the (human) user, the driving automation system, and other vehicle systems and components. These other vehicle systems and components (or the vehicle in general terms) do not include the driving automation system in this model, even though as a practical matter a driving automation system may actually share hardware and software components with other vehicle systems, such as a processing module(s) or operating code. The levels of driving automation are defined by reference to the specific role played by each of the three primary actors in performance of the DDT and/or DDT fallback. “Role” in this context refers to the expected role of a given primary actor, based on the design of the driving automation system in question and not necessarily to the actual performance of a given primary actor. For example, a driver who fails to monitor the roadway during engagement of a Level 1 adaptive cruise control (ACC) system still has the role of driver, even while s/he is neglecting it. Active safety systems, such as electronic stability control (ESC) and automatic emergency braking (AEB), and certain types of driver assistance systems, such as lane keeping assistance (LKA), are excluded from the scope of this driving automation taxonomy because they do not perform part or all of the DDT on a sustained basis, but rather provide momentary intervention during potentially hazardous situations. Due to the momentary nature of the actions of active safety systems, their intervention does not change or eliminate the role of the driver in performing part or all of the DDT, and thus are not considered to be driving automation, even though they perform automated functions. In addition, systems that inform, alert, or warn the driver about hazards in the driving environment are also outside the scope of this driving automation taxonomy, as they neither automate part or all of the DDT, nor change the driver’s role in performance of the DDT (see 8.13). It should be noted, however, that crash avoidance features, including intervention-type active safety systems, may be included in vehicles equipped with driving automation systems at any level. For automated driving system (ADS) features (i.e., Levels 3 to 5) that perform the complete DDT, crash mitigation and avoidance capability is part of ADS functionality (see also 8.13).},
	publisher = {SAE International},
	author = {{On-Road Automated Driving (ORAD) Committee}},
	month = apr,
	year = {2021},
	doi = {https://doi.org/10.4271/J3016_202104},
	file = {PDF:C\:\\Users\\giand\\Zotero\\storage\\JLTRAQ4Z\\On-Road Automated Driving (ORAD) Committee - 2021 - Taxonomy and Definitions for Terms Related to Driving Automation Systems for On-Road Motor Vehicles.pdf:application/pdf},
}

@incollection{bubb_regelkreisparadigma_2015,
	title = {Das {Regelkreisparadigma} der {Ergonomie}},
	isbn = {978-3-8348-2297-0},
	url = {https://link.springer.com/chapter/10.1007/978-3-8348-2297-0_2},
	abstract = {Eine wissenschaftlich fundierte ergonomische Gestaltung eines technischen Mittels setzt zun\&\#228;chst die genaue Beschreibung der Aufgabe voraus, die mit ihm erf\&\#252;llt werden soll. Mit der Vorstellung des Regelkreises kann der Informationsfluss beschrieben werden,...},

	urldate = {2025-07-02},
	booktitle = {Automobilergonomie},
	publisher = {Springer Vieweg, Wiesbaden},
	author = {Bubb, Heiner},
	year = {2015},
	doi = {10.1007/978-3-8348-2297-0\_2},
	pages = {27--65},
	file = {Full Text PDF:C\:\\Users\\giand\\Zotero\\storage\\2NCE6TMF\\Bubb - 2015 - Das Regelkreisparadigma der Ergonomie.pdf:application/pdf},
}


@inproceedings{pfleging_non-_2015,
	title = {({Non}-) {Driving}-{Related} {Activities} in the {Car}: {Defining} {Driver} {Activities} for {Manual} and {Automated} {Driving}},
	url = {http://www.hcilab.org/wp-content/uploads/chi15-ws-nondriving-activities.pdf},
	booktitle = {Workshop on {Experiencing} {Autonomous} {Vehicles}: {Crossing} the {Boundaries} between a {Drive} and a {Ride} at {CHI}’15},
	author = {Pfleging, Bastian and Schmidt, Albrecht},
	year = {2015},
	keywords = {2015 simtech2 vis(us) vis-mci visus:pflegibn visus:schmidat},
}

@misc{department_of_transportation_and_national_highway__traffic_safety_administration_visual-manual_2013,
	title = {Visual-{Manual} {NHTSA} {Driver} {Distraction} {Guidelines} for {In}-{Vehicle} {Electronic} {Devices}},
	url = {https://www.federalregister.gov/d/2013-09883},
	abstract = {The National Highway Traffic Safety Administration (NHTSA) is concerned about the effects of distraction on motor vehicle safety due to drivers' use of electronic devices. Consequently, NHTSA is issuing nonbinding, voluntary Driver Distraction Guidelines (NHTSA Guidelines) to promote safety by...},
	language = {en},
	urldate = {2025-07-02},
	journal = {Federal Register},
	author = {{Department of Transportation and National Highway  Traffic Safety Administration}},
	month = apr,
	year = {2013},
	file = {Snapshot:C\:\\Users\\giand\\Zotero\\storage\\G97FYVL4\\visual-manual-nhtsa-driver-distraction-guidelines-for-in-vehicle-electronic-devices.html:text/html},
}

@article{radlmayr_how_2014,
	title = {How {Traffic} {Situations} and {Non}-{Driving} {Related} {Tasks} {Affect} the {Take}-{Over} {Quality} in {Highly} {Automated} {Driving}},
	volume = {58},
	issn = {1071-1813},
	url = {https://doi.org/10.1177/1541931214581434},
	doi = {10.1177/1541931214581434},
	abstract = {Highly automated driving constitutes a temporary transfer of the primary driving task from the driver to the automated vehicle. In case of system limits, drivers take back control of the vehicle. This study investigates the effect of varying traffic situations and non-driving related tasks on the take-over process and quality. The experiment is conducted in a high-fidelity driving simulator. The standardized visual Surrogate Reference Task (SuRT) and the cognitive n-back Task are used to simulate the non-driving related tasks. Participants experience four different traffic situations. Results of this experiment show a strong influence of the traffic situations on the take-over quality in a highway setting, if the traffic density is high. The non-driving related tasks SuRT and the n-back Task show similar effects on the take-over process with a higher total number of collisions by the SuRT in the high density traffic situation.},
	language = {EN},
	number = {1},
	urldate = {2025-07-02},
	journal = {Proceedings of the Human Factors and Ergonomics Society Annual Meeting},
	author = {Radlmayr, Jonas and Gold, Christian and Lorenz, Lutz and Farid, Mehdi and Bengler, Klaus},
	month = sep,
	year = {2014},
	note = {Publisher: SAGE Publications Inc},
	pages = {2063--2067},
}


@techreport{schoettle_survey_2014,
	type = {Technical {Report}},
	title = {A survey of public opinion about autonomous and self-driving vehicles in the {U}.{S}., the {U}.{K}., and {Australia}},
	url = {http://deepblue.lib.umich.edu/handle/2027.42/108384},
	abstract = {This survey examined public opinion regarding self-driving-vehicle technology in three major English-speaking countries—the U.S., the U.K., and Australia.  The survey yielded useable responses from 1,533 persons 18 years and older. The main findings (applicable to each of the three countries) were as follows: 
     The majority of respondents had previously heard of autonomous or self-driving vehicles, had a positive initial opinion of the technology, and had high expectations about the benefits of the technology. 
     However, the majority of respondents expressed high levels of concern about riding in self-driving vehicles, security issues related to self-driving vehicles, and self-driving vehicle not performing as well as actual drivers. 
     Respondents also expressed high levels of concern about vehicles without driver controls; self-driving vehicles moving while unoccupied; and self-driving commercial vehicles, busses, and taxis.      The majority of respondents expressed a desire to have this technology in their vehicle. However, a majority was also unwilling to pay extra for the technology; those who were willing to pay offered similar amounts in each country. 
     Females expressed higher levels of concern with self-driving vehicles than did males.  Similarly, females were more cautious about their expectations concerning benefits from using self-driving vehicles. 
In comparison to the respondents in the U.K. and Australia, respondents in the U.S. expressed greater concern about riding in self-driving vehicles, data privacy, interacting with non-self-driving vehicles, self-driving vehicles not driving as well as human drivers in general, and riding in a self-driving vehicle with no driver controls available. The main implications of these results are that motorists and the general public in the three countries surveyed, while expressing high levels of concern about riding in vehicles equipped with this technology, feel positive about self-driving vehicles, have optimistic expectations of the benefits, and generally desire self-driving-vehicle technology when it becomes available (though a majority is not willing to pay extra for such technology at this time).},
	language = {English},
	urldate = {2025-07-03},
	institution = {University of Michigan, Ann Arbor, Transportation Research Institute},
	author = {Schoettle, Brandon and Sivak, Michael},
	month = jul,
	year = {2014},
	note = {Accepted: 2014-09-08T17:58:46Z},
	file = {Full Text PDF:C\:\\Users\\giand\\Zotero\\storage\\7YSRSNDF\\Schoettle and Sivak - 2014 - A survey of public opinion about autonomous and self-driving vehicles in the U.S., the U.K., and Aus.pdf:application/pdf},
}

@article{kyriakidis_public_2015,
	title = {Public opinion on automated driving: {Results} of an international questionnaire among 5000 respondents},
	volume = {32},
	issn = {13698478},
	shorttitle = {Public opinion on automated driving},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1369847815000777},
	doi = {10.1016/j.trf.2015.04.014},
	language = {en},
	urldate = {2025-07-03},
	journal = {Transportation Research Part F: Traffic Psychology and Behaviour},
	author = {Kyriakidis, M. and Happee, R. and De Winter, J.C.F.},
	month = jul,
	year = {2015},
	pages = {127--140},
	file = {Full Text PDF:C\:\\Users\\giand\\Zotero\\storage\\CS6E5K2Q\\Kyriakidis et al. - 2015 - Public opinion on automated driving Results of an international questionnaire among 5000 respondent.pdf:application/pdf},
}

@article{bansal_assessing_2016,
	title = {Assessing public opinions of and interest in new vehicle technologies: {An} {Austin} perspective},
	volume = {67},
	issn = {0968090X},
	shorttitle = {Assessing public opinions of and interest in new vehicle technologies},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0968090X16000383},
	doi = {10.1016/j.trc.2016.01.019},
	language = {en},
	urldate = {2025-07-03},
	journal = {Transportation Research Part C: Emerging Technologies},
	author = {Bansal, Prateek and Kockelman, Kara M. and Singh, Amit},
	month = jun,
	year = {2016},
	pages = {1--14},
}

@article{wadud_fully_2023,
	title = {Fully automated vehicles: the use of travel time and its association with intention to use},
	volume = {176},
	issn = {0965-092X, 1751-7710},
	shorttitle = {Fully automated vehicles},
	url = {https://www.icevirtuallibrary.com/doi/10.1680/jtran.18.00134},
	doi = {10.1680/jtran.18.00134},
	abstract = {Traditionally, time spent travelling has been seen as a ‘cost’ to the traveller. Autonomous or fully automated vehicles (FAVs) can free the driver of the driving task and allow engagement in other worthwhile activities inside the FAVs, which can transform how people travel. However, there is little understanding about how travel time can be used and how worthwhile this time can be in FAVs; and whether this is related to the intention to use FAVs. This paper addresses these questions through a multi-country questionnaire survey, with a sub-sample of chauffeur-driven car users to mimic time use in FAVs. Responses show that users are likely to engage in other non-driving activities while riding in FAVs, and these differ according to trip purpose and direction. Time spent travelling in FAVs is perceived to be more useful than in current modes of transport. Interest in using FAVs is directly correlated with perceived usefulness of time in autonomous vehicles. There is a strong correlation between intended activities in FAVs and current activities by primary car users in chauffeur-driven cars, providing some validation to the stated intention responses. Results have important implications for policy-making, time use and value-of-time research, as well as vehicle interior design.},
	language = {en},
	number = {3},
	urldate = {2025-07-03},
	journal = {Proceedings of the Institution of Civil Engineers - Transport},
	author = {Wadud, Zia and Huda, Fuad Yasin},
	month = jun,
	year = {2023},
	pages = {127--141},
	file = {Full Text PDF:C\:\\Users\\giand\\Zotero\\storage\\ZWTHNB4B\\Wadud and Huda - 2023 - Fully automated vehicles the use of travel time and its association with intention to use.pdf:application/pdf},
}

@article{kamp_chosen_2011,
	title = {Chosen postures during specific sitting activities},
	volume = {54},
	issn = {0014-0139, 1366-5847},
	url = {https://www.tandfonline.com/doi/full/10.1080/00140139.2011.618230},
	doi = {10.1080/00140139.2011.618230},
	language = {en},
	number = {11},
	urldate = {2025-07-03},
	journal = {Ergonomics},
	author = {Kamp, Irene and Kilincsoy, Ümit and Vink, Peter},
	month = nov,
	year = {2011},
	pages = {1029--1042},
}

@incollection{ahram_non-driving_2020,
	address = {Cham},
	title = {Non-driving {Related} {Activities} in {Automated} {Driving} – {An} {Online} {Survey} {Investigating} {User} {Needs}},
	volume = {1026},
	isbn = {978-3-030-27927-1 978-3-030-27928-8},
	url = {http://link.springer.com/10.1007/978-3-030-27928-8_28},
	language = {en},
	urldate = {2025-07-03},
	booktitle = {Human {Systems} {Engineering} and {Design} {II}},
	publisher = {Springer International Publishing},
	author = {Hecht, Tobias and Darlagiannis, Emilia and Bengler, Klaus},
	editor = {Ahram, Tareq and Karwowski, Waldemar and Pickl, Stefan and Taiar, Redha},
	year = {2020},
	doi = {10.1007/978-3-030-27928-8\_28},
	note = {Series Title: Advances in Intelligent Systems and Computing},
	pages = {182--188},
}

@article{gripsrud_working_2012,
	title = {Working on the train: from ‘dead time’ to productive and vital time},
	volume = {39},
	copyright = {http://www.springer.com/tdm},
	issn = {0049-4488, 1572-9435},
	shorttitle = {Working on the train},
	url = {http://link.springer.com/10.1007/s11116-012-9396-7},
	doi = {10.1007/s11116-012-9396-7},
	language = {en},
	number = {5},
	urldate = {2025-07-03},
	journal = {Transportation},
	author = {Gripsrud, Mattias and Hjorthol, Randi},
	month = sep,
	year = {2012},
	pages = {941--956},
}

@article{lyons_use_2007,
	title = {The use of travel time by rail passengers in {Great} {Britain}},
	volume = {41},
	copyright = {https://www.elsevier.com/tdm/userlicense/1.0/},
	issn = {09658564},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0965856406000644},
	doi = {10.1016/j.tra.2006.05.012},
	language = {en},
	number = {1},
	urldate = {2025-07-03},
	journal = {Transportation Research Part A: Policy and Practice},
	author = {Lyons, Glenn and Jain, Juliet and Holley, David},
	month = jan,
	year = {2007},
	pages = {107--120},
}

@incollection{ahram_what_2020,
	address = {Cham},
	title = {What {Do} {You} {Do}? {An} {Analysis} of {Non}-driving {Related} {Activities} {During} a 60 {Minutes} {Conditionally} {Automated} {Highway} {Drive}},
	volume = {1018},
	isbn = {978-3-030-25628-9 978-3-030-25629-6},
	shorttitle = {What {Do} {You} {Do}?},
	url = {http://link.springer.com/10.1007/978-3-030-25629-6_5},
	language = {en},
	urldate = {2025-07-03},
	booktitle = {Human {Interaction} and {Emerging} {Technologies}},
	publisher = {Springer International Publishing},
	author = {Hecht, Tobias and Feldhütter, Anna and Draeger, Kathrin and Bengler, Klaus},
	editor = {Ahram, Tareq and Taiar, Redha and Colson, Serge and Choplin, Arnaud},
	year = {2020},
	doi = {10.1007/978-3-030-25629-6\_5},
	note = {Series Title: Advances in Intelligent Systems and Computing},
	pages = {28--34},
}

@article{large_design_2017,
	title = {Design {Implications} of {Drivers}’ {Engagement} with {Secondary} {Activities} {During} {Highly}-{Automated} {Driving} – {A} {Longitudinal} {Simulator} {Study}},
	url = {https://nottingham-repository.worktribe.com/output/1214099},
	abstract = {Highly-automated vehicles will provide the freedom for drivers to engage in secondary activities while the vehicle is in control. However, little is known regarding the nature of activities that drivers will undertake, and how these may impact drivers’ ability to resume manual control. In a novel, long-term, qualitative simulator study, six experienced drivers completed the same 30-minute motorway journey (portrayed as their commute to work) at the same time on five consecutive weekdays in a highly-automated car; a system ‘health-bar’ indicated the overall status of the automated system during each drive. Participants were invited to bring with them any objects or devices that they would expect to use in their own (automated) vehicle during such a journey, and use these freely during the drives. Inclement weather (heavy fog) on the penultimate day of testing presented an unexpected, emergency 5.0-second take-over request (indicated by an urgent auditory alarm and a flashing visual icon replacing the ‘health-bar’). Video analysis with thematic coding shows that participants were quickly absorbed by a variety of secondary activities/devices, which typically demanded high levels of visual, manual and cognitive attention, and postural adaptation (e.g. moving/reclining the driver’s seat). The steering wheel was routinely used as a support for secondary objects/devices. Drivers were required to rapidly discharge secondary devices/activities and re-establish driving position/posture following the unexpected, emergency hand-over request on day four. This resulted in notable changes in participants’ subjective ratings of trust on the final day of testing, with some participants apparently more sceptical of the system following the emergency hand-over event, whereas others were more trusting than before. Qualitative results are presented and discussed in the context of the re-design of vehicles to enable the safe and comfortable execution of secondary activities during high-automation, while enabling effective transfer of control.},
	language = {en},
	urldate = {2025-07-03},
	author = {Large, David R. and Burnett, Gary E. and Morris, Andrew and Muthumani, Arun and Matthias, Rebecca},
	month = oct,
	year = {2017},
	file = {Full Text PDF:C\:\\Users\\giand\\Zotero\\storage\\2TVI74RK\\Large et al. - 2017 - Design Implications of Drivers’ Engagement with Secondary Activities During Highly-Automated Driving.pdf:application/pdf},
}


@inproceedings{cyganski_travel-time_2015,
	title = {Travel-time valuation for automated driving: {A} use-case-driven study},
	booktitle = {Proceedings of the 94th {Annual} {Meeting} of the {TRB}},
	author = {Cyganski, Rita and Fraedrich, Eva and Lenz, Barbara},
	year = {2015},
}


@article{cunningham_public_2019,
	title = {Public opinion about automated vehicles in {Australia}: {Results} from a large-scale national survey},
	volume = {129},
	issn = {0965-8564},
	shorttitle = {Public opinion about automated vehicles in {Australia}},
	url = {https://www.sciencedirect.com/science/article/pii/S0965856419302745},
	doi = {10.1016/j.tra.2019.08.002},
	abstract = {Public acceptability, and ultimately acceptance, of automated vehicles (AVs) is critical in order to ensure that drivers utilise them and thus realise their predicted safety and other benefits. The aim of this study was to gauge public acceptability and opinions of AVs within an Australian context, for which there is currently a scarcity of empirical research. The study employed a national sample of 5089 respondents who responded to a large online survey (including 45 items specifically targeting aspects of AV acceptability). Survey items gauged demographic and other sample characteristics, and probed responses to questions on key issues including (a) the perceived benefits of AVs, (b) sources, and degree, of concerns regarding AV-related issues, and (c) willingness to pay for AV technology. Overall, it was found that, even though Australian respondents tended to agree with many of the potential benefits of AVs probed in the survey, they have considerable concerns regarding many AV-related issues. Furthermore, a majority of Australians are currently not willing to pay any more for a fully autonomous vehicle than for a manually operated vehicle. Results also showed that a number of sample demographic and characteristic variables (e.g., gender, self-classification as an early vs. late adopter of technology) have unique associations with aspects of AV acceptability. Important theoretical and practical implications of these findings are discussed.},
	urldate = {2025-07-03},
	journal = {Transportation Research Part A: Policy and Practice},
	author = {Cunningham, Mitchell L. and Regan, Michael A. and Horberry, Timothy and Weeratunga, Kamal and Dixit, Vinayak},
	month = nov,
	year = {2019},
	keywords = {Acceptability, Acceptance, Automated vehicles, Autonomous vehicles, Public opinion, Self-driving vehicles},
	pages = {1--18},
	file = {ScienceDirect Snapshot:C\:\\Users\\giand\\Zotero\\storage\\TI8H3D56\\S0965856419302745.html:text/html},
}


@inproceedings{stampf_deriving_2024,
	address = {New York, NY, USA},
	series = {{MuC} '24},
	title = {Deriving {Non}-{Driving}-{Related} {Activities} in {Highly} {Automated} {Driving} via an {Autoethnographic} {Approach} by {Traveling} {Canada} in a {Recreational} {Vehicle}},
	isbn = {979-8-4007-0998-2},
	url = {https://dl.acm.org/doi/10.1145/3670653.3670663},
	doi = {10.1145/3670653.3670663},
	abstract = {Automated vehicles will alter traffic fundamentally. Users can engage in various activities, such as working, reading, or sleeping. However, based on these activities, there are challenges and opportunities to adapt the vehicle, possibly transforming these into “tiny houses”. Some activities will most likely be conducted, especially those already undertaken, such as making phone calls or listening to music. However, there are limited possibilities to derive activities occurring in longer trips or with a high level of automation. Therefore, we propose to derive non-driving-related activities based on a 12-day trip in a camper as a surrogate for prolonged exposure to automated driving. We report the autoethnographic results of our experiences and deduce relevant future research questions. We highlight the possibility of employing Vanlife as a method to study these upcoming challenges.},
	urldate = {2025-07-02},
	booktitle = {Proceedings of {Mensch} und {Computer} 2024},
	publisher = {Association for Computing Machinery},
	author = {Stampf, Annika and Colley, Mark},
	month = sep,
	year = {2024},
	keywords = {To Read},
	pages = {279--287},
	file = {Full Text PDF:C\:\\Users\\giand\\Zotero\\storage\\GUTNUY4H\\Stampf and Colley - 2024 - Deriving Non-Driving-Related Activities in Highly Automated Driving via an Autoethnographic Approach.pdf:application/pdf},
}


@techreport{riener_automotive_2016,
	title = {Automotive {User} {Interfaces} in the {Age} of {Automation} ({Dagstuhl} {Seminar} 16262)},
	copyright = {Creative Commons Attribution 3.0 Unported license, info:eu-repo/semantics/openAccess},
	url = {https://drops.dagstuhl.de/entities/document/10.4230/DagRep.6.6.111},
	abstract = {The next big change in the automotive domain will be the move towards automated and semi-automated driving. We can expect an increasing level of autonomous driving in the coming years, resulting in new opportunities for the car as an infotainment platform when standard driving tasks will be automated. This change also comes with a number of challenges to automotive user interfaces. Core challenges for the assistance system and the user interface will be distributing tasks between the assistance system and the driver, the re-engagement of drivers in semi-automated driving back to the driving task, and collaborative driving in which cars collectively work together (e.g., platoons). Overall, in the coming years we will need to design interfaces and applications that make driving safe while enabling communication, work, and play in human-operated vehicles. This Dagstuhl seminar brought together researchers from human computer interaction, cognitive psychology, human factors psychology and also from automotive industry and OEMs to discuss the new interface paradigms for (semi-)automated driving.},
	language = {en},
	urldate = {2025-07-04},
	institution = {Schloss Dagstuhl – Leibniz-Zentrum für Informatik},
	author = {Riener, Andreas and Boll, Susanne and Kun, Andrew L.},
	year = {2016},
	doi = {10.4230/DAGREP.6.6.111},
	note = {Artwork Size: 47 pages, 2111978 bytes
ISSN: 2192-5283
Issue: 6
Medium: application/pdf
Publication Title: Dagstuhl Reports (DagRep)
Volume: 6},
	keywords = {Automotive UIs; Driver-vehicle interaction services; UX in driving; Customization of vehicles/UIs; (Over)trust; Ethical issues},
	pages = {111--157},
}


@inproceedings{janssen_exploring_2019,
	address = {Utrecht Netherlands},
	title = {Exploring the concept of the (future) mobile office},
	isbn = {978-1-4503-6920-6},
	url = {https://dl.acm.org/doi/10.1145/3349263.3349600},
	doi = {10.1145/3349263.3349600},
	language = {en},
	urldate = {2025-07-04},
	booktitle = {Proceedings of the 11th {International} {Conference} on {Automotive} {User} {Interfaces} and {Interactive} {Vehicular} {Applications}: {Adjunct} {Proceedings}},
	publisher = {ACM},
	author = {Janssen, Christian P. and Kun, Andrew L. and Brewster, Stephen and Boyle, Linda Ng and Brumby, Duncan P. and Chuang, Lewis L.},
	month = sep,
	year = {2019},
	pages = {465--467},
	file = {Full Text:C\:\\Users\\giand\\Zotero\\storage\\JJXD3XCQ\\Janssen et al. - 2019 - Exploring the concept of the (future) mobile office.pdf:application/pdf},
}


@inproceedings{wu_defining_2018,
	address = {New York, NY, USA},
	series = {{AutomotiveUI} '18},
	title = {Defining {Ritualistic} {Driver} and {Passenger} {Behaviour} to {Inform} {In}-{Vehicle} {Experiences}},
	isbn = {978-1-4503-5947-4},
	url = {https://dl.acm.org/doi/10.1145/3239092.3265944},
	doi = {10.1145/3239092.3265944},
	abstract = {By discovering unconscious ritualistic actions in everyday driving such as preparing for the morning commute, we seek design opportunities to help people achieve critical emotional transitions such as moving from an anxious state to relief. We have gathered and analysed data from workshops and phone interviews from a variety of vehicle and public transport users to capture these key ritualistic scenarios and map their emotional transitions. Design ideation is used to generate concepts for improving the in-vehicle user experience through redesign of vehicle layout, environment and analogue and digital interfaces. We report a set of human-centred design approaches that allow us to study the details of action, objects, people, emotions and meaning for typical car users which are indispensable for designing driving experiences and are often overlooked by the car design process.},
	urldate = {2025-07-04},
	booktitle = {Adjunct {Proceedings} of the 10th {International} {Conference} on {Automotive} {User} {Interfaces} and {Interactive} {Vehicular} {Applications}},
	publisher = {Association for Computing Machinery},
	author = {Wu, Jiayu and Johnson, Samuel and Hesseldahl, Katrine and Quinlan, Daniel and Zileli, Selin and Harrow, Professor Dale},
	month = sep,
	year = {2018},
	pages = {72--76},
	file = {Full Text PDF:C\:\\Users\\giand\\Zotero\\storage\\Q8KZE23A\\Wu et al. - 2018 - Defining Ritualistic Driver and Passenger Behaviour to Inform In-Vehicle Experiences.pdf:application/pdf},
}


@article{sheldon_what_2001,
	title = {What is satisfying about satisfying events? {Testing} 10 candidate psychological needs},
	volume = {80},
	issn = {1939-1315},
	shorttitle = {What is satisfying about satisfying events?},
	doi = {10.1037/0022-3514.80.2.325},
	abstract = {Three studies compared 10 candidate psychological needs in an attempt to determine which are truly most fundamental for humans. Participants described "most satisfying events" within their lives and then rated the salience of each of the 10 candidate needs within these events. Supporting self-determination theory postulates (Ryan \& Deci, 2000)—autonomy, competence, and relatedness, were consistently among the top 4 needs, in terms of both their salience and their association with event-related affect. Self-esteem was also important, whereas self-actualization or meaning, physical thriving, popularity or influence, and money–luxury were less important. This basic pattern emerged within three different time frames and within both U.S. and South Korean samples and also within a final study that asked, "What's unsatisfying about unsatisfying events?" Implications for hierarchical theories of needs are discussed. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
	number = {2},
	journal = {Journal of Personality and Social Psychology},
	author = {Sheldon, Kennon M. and Elliot, Andrew J. and Kim, Youngmee and Kasser, Tim},
	year = {2001},
	note = {Place: US
Publisher: American Psychological Association},
	keywords = {Competence, Cross Cultural Differences, Independence (Personality), Life Experiences, Life Satisfaction, Personality, Psychological Needs, Satisfaction, Self-Concept, Self-Determination, Self-Esteem},
	pages = {325--339},
	file = {Submitted Version:C\:\\Users\\giand\\Zotero\\storage\\WJ2H6YCW\\Sheldon et al. - 2001 - What is satisfying about satisfying events Testing 10 candidate psychological needs.pdf:application/pdf},
}


@article{eastwood_unengaged_2012,
	title = {The {Unengaged} {Mind}: {Defining} {Boredom} in {Terms} of {Attention}},
	volume = {7},
	issn = {1745-6916, 1745-6924},
	shorttitle = {The {Unengaged} {Mind}},
	url = {https://journals.sagepub.com/doi/10.1177/1745691612456044},
	doi = {10.1177/1745691612456044},
	abstract = {Our central goal is to provide a definition of boredom in terms of the underlying mental processes that occur during an instance of boredom. Through the synthesis of psychodynamic, existential, arousal, and cognitive theories of boredom, we argue that boredom is universally conceptualized as “the aversive experience of wanting, but being unable, to engage in satisfying activity.” We propose to map this conceptualization onto underlying mental processes. Specifically, we propose that boredom be defined in terms of attention. That is, boredom is the aversive state that occurs when we (a) are not able to successfully engage attention with internal (e.g., thoughts or feelings) or external (e.g., environmental stimuli) information required for participating in satisfying activity, (b) are focused on the fact that we are not able to engage attention and participate in satisfying activity, and (c) attribute the cause of our aversive state to the environment. We believe that our definition of boredom fully accounts for the phenomenal experience of boredom, brings existing theories of boredom into dialogue with one another, and suggests specific directions for future research on boredom and attention.},
	language = {en},
	number = {5},
	urldate = {2025-07-04},
	journal = {Perspectives on Psychological Science},
	author = {Eastwood, John D. and Frischen, Alexandra and Fenske, Mark J. and Smilek, Daniel},
	month = sep,
	year = {2012},
	pages = {482--495},
	file = {PDF:C\:\\Users\\giand\\Zotero\\storage\\9TYANJKH\\Eastwood et al. - 2012 - The Unengaged Mind Defining Boredom in Terms of Attention.pdf:application/pdf},
}


@inproceedings{rodel_towards_2014,
	address = {New York, NY, USA},
	series = {{AutomotiveUI} '14},
	title = {Towards {Autonomous} {Cars}: {The} {Effect} of {Autonomy} {Levels} on {Acceptance} and {User} {Experience}},
	isbn = {978-1-4503-3212-5},
	shorttitle = {Towards {Autonomous} {Cars}},
	url = {https://dl.acm.org/doi/10.1145/2667317.2667330},
	doi = {10.1145/2667317.2667330},
	abstract = {Surveys [8] show that people generally have a positive attitude towards autonomous cars. However, these studies neglect that cars have different levels of autonomy and that User Acceptance (UA) and User Experience (UX) with autonomous systems differ with regard to the degree of system autonomy. The National Highway Traffic Safety Administration (NHTSA) defines five degrees of car autonomy which vary in the penetration of cars with Advanced Driver Assistance Systems (ADAS) and the extent to which a car is taken over by autonomous systems. Based on these levels, we conducted an online-questionnaire study (N = 336), in which we investigated how UA and UX factors, such as Perceived Ease of Use, Attitude Towards using the system, Perceived Behavioral Control, Behavioral Intention to use a system, Trust and Fun, differ with regard to the degree of autonomy in cars. We show that UA and UX are highest in levels of autonomy that already have been deployed in modern cars. More specifically, perceived control and fun decrease continuously with higher autonomy. Furthermore, our results indicate that pre-experience with ADAS and demographics, such as age and gender, have an influence on UA and UX.},
	urldate = {2025-07-04},
	booktitle = {Proceedings of the 6th {International} {Conference} on {Automotive} {User} {Interfaces} and {Interactive} {Vehicular} {Applications}},
	publisher = {Association for Computing Machinery},
	author = {Rödel, Christina and Stadler, Susanne and Meschtscherjakov, Alexander and Tscheligi, Manfred},
	month = sep,
	year = {2014},
	pages = {1--8},
	file = {Full Text PDF:C\:\\Users\\giand\\Zotero\\storage\\JN4UU4HW\\Rödel et al. - 2014 - Towards Autonomous Cars The Effect of Autonomy Levels on Acceptance and User Experience.pdf:application/pdf},
}

@inproceedings{van_huysduynen_why_2018,
	address = {New York, NY, USA},
	series = {{AutomotiveUI} '18},
	title = {Why {Disable} the {Autopilot}?},
	isbn = {978-1-4503-5946-7},
	url = {https://dl.acm.org/doi/10.1145/3239060.3239063},
	doi = {10.1145/3239060.3239063},
	abstract = {The number of systems in commercially available vehicles that assist or automate driving tasks is rapidly increasing. At least for the next decade, using such systems remains up to the discretion of the user. In this paper, different reasons why drivers may disengage the autopilot are investigated. This was done through a simulator study in which the system could drive fully automated, but where participants could also disengage the system. Qualitative data were collected about why participants disengaged the autopilot. The analysis of the data revealed six themes covering the reasons why participants disabled the autopilot: The speed maintained by the autopilot, the behavior of the autopilot in relation to overtaking other vehicles, onset of boredom, onset of sleepiness, lack of trust in the autopilot, and enjoyment of manual driving. On the basis of the results, design opportunities are proposed to counteract the tendency to not use automated driving systems.},
	urldate = {2025-07-04},
	booktitle = {Proceedings of the 10th {International} {Conference} on {Automotive} {User} {Interfaces} and {Interactive} {Vehicular} {Applications}},
	publisher = {Association for Computing Machinery},
	author = {van Huysduynen, Hanneke Hooft and Terken, Jacques and Eggen, Berry},
	month = sep,
	year = {2018},
	pages = {247--257},
	file = {Full Text PDF:C\:\\Users\\giand\\Zotero\\storage\\8RE4GCSI\\van Huysduynen et al. - 2018 - Why Disable the Autopilot.pdf:application/pdf},
}


@book{desmet_positive_2013,
	title = {Positive {Design}: {An} {Introduction} to {Design} for {Subjective} {Well}-{Being}},
	url = {https://www.ijdesign.org/index.php/IJDesign/article/view/1666%C3%A2%E2%82%AC%C5%93},
	abstract = {This paper addresses the question of how design can contribute to the happiness of individuals–to their subjective well-being. A framework for positive design is introduced that includes three main components of subjective well-being: pleasure, personal significance and virtue. Each component represents an ingredient of design for happiness, and we propose that design that expressly includes all three ingredients is design that promotes human flourishing. People who flourish are developing as individuals, live their lives to their fullest potential, and act in the best interests of society. The intention to support human flourishing is the explicit, central design objective of positive design. Five characteristics of positive design are proposed, all of which are of relevance to organizing design processes that intend to result in designs that stimulate human flourishing. In addition, some contemporary design approaches are discussed that focus on quality of life, including nudge, capability approach, and experience design. Four important research challenges are outlined to indicate directions for a research agenda. Together with the framework, these research directions are intended to offer inspiration for designers and design researchers to join forces in their endeavours to design for subjective well-being.},
	author = {Desmet, Pieter M. A. and Pohlmeyer, Anna E.},
	year = {2013},
	note = {Publication Title: 2013
Type: Design for Subjective Well-Being, Happiness, Flourishing, Design Framework, Positive Design},
	keywords = {Design for Subjective Well-Being, Happiness, Flourishing, Design Framework, Positive Design},
}

@article{riva_positive_2012,
	title = {Positive {Technology}: {Using} {Interactive} {Technologies} to {Promote} {Positive} {Functioning}},
	volume = {15},
	issn = {2152-2715},
	shorttitle = {Positive {Technology}},
	url = {https://www.liebertpub.com/doi/abs/10.1089/cyber.2011.0139},
	doi = {10.1089/cyber.2011.0139},
	abstract = {It is generally assumed that technology assists individuals in improving the quality of their lives. However, the impact of new technologies and media on well-being and positive functioning is still somewhat controversial. In this paper, we contend that the quality of experience should become the guiding principle in the design and development of new technologies, as well as a primary metric for the evaluation of their applications. The emerging discipline of Positive Psychology provides a useful framework to address this challenge. Positive Psychology is the scientific study of optimal human functioning and flourishing. Instead of drawing on a “disease model” of human behavior, it focuses on factors that enable individuals and communities to thrive and build the best in life. In this paper, we propose the “Positive Technology” approach—the scientific and applied approach to the use of technology for improving the quality of our personal experience through its structuring, augmentation, and/or replacement—as a way of framing a suitable object of study in the field of cyberpsychology and human–computer interaction. Specifically, we suggest that it is possible to use technology to influence three specific features of our experience—affective quality, engagement/actualization, and connectedness—that serve to promote adaptive behaviors and positive functioning. In this framework, positive technologies are classified according to their effects on a specific feature of personal experience. Moreover, for each level, we have identified critical variables that can be manipulated to guide the design and development of positive technologies.},
	number = {2},
	urldate = {2025-07-04},
	journal = {Cyberpsychology, Behavior, and Social Networking},
	author = {Riva, Giuseppe and Baños, Rosa M. and Botella, Cristina and Wiederhold, Brenda K. and Gaggioli, Andrea},
	month = feb,
	year = {2012},
	note = {Publisher: Mary Ann Liebert, Inc., publishers},
	pages = {69--77},
}

@book{calvo_positive_2014,
	title = {Positive {Computing}: {Technology} for {Wellbeing} and {Human} {Potential}},
	isbn = {978-0-262-32568-4},
	shorttitle = {Positive {Computing}},
	url = {https://direct.mit.edu/books/monograph/4026/Positive-ComputingTechnology-for-Wellbeing-and},
	abstract = {A case for building a digital environment that can make us happier and healthier, not just more productive, and a theoretical framework for doing so.On the},
	language = {en},
	urldate = {2025-07-04},
	publisher = {The MIT Press},
	author = {Calvo, Rafael A. and Peters, Dorian},
	month = nov,
	year = {2014},
	doi = {10.7551/mitpress/9764.001.0001},
	file = {Full Text PDF:C\:\\Users\\giand\\Zotero\\storage\\WC2BQMG8\\Calvo and Peters - 2014 - Positive Computing Technology for Wellbeing and Human Potential.pdf:application/pdf},
}

@article{pawlowski_positive_2015,
	title = {Positive {Computing}},
	volume = {57},
	copyright = {2015 Springer Fachmedien Wiesbaden},
	issn = {1867-0202},
	url = {https://link.springer.com/article/10.1007/s12599-015-0406-0},
	doi = {10.1007/s12599-015-0406-0},
	language = {en},
	number = {6},
	urldate = {2025-07-04},
	journal = {Business \& Information Systems Engineering},
	author = {Pawlowski, Jan M. and Eimler, Sabrina C. and Jansen, Marc and Stoffregen, Julia and Geisler, Stefan and Koch, Oliver and Müller, Gordon and Handmann, Uwe},
	month = dec,
	year = {2015},
	note = {Company: Springer
Distributor: Springer
Institution: Springer
Label: Springer
Number: 6
Publisher: Springer Fachmedien Wiesbaden},
	pages = {405--408},
	file = {Full Text PDF:C\:\\Users\\giand\\Zotero\\storage\\785XXYRE\\Pawlowski et al. - 2015 - Positive Computing.pdf:application/pdf},
}


@inproceedings{frison_why_2019,
	address = {New York, NY, USA},
	series = {{IUI} '19},
	title = {Why do you like to drive automated? a context-dependent analysis of highly automated driving to elaborate requirements for intelligent user interfaces},
	isbn = {978-1-4503-6272-6},
	shorttitle = {Why do you like to drive automated?},
	url = {https://dl.acm.org/doi/10.1145/3301275.3302331},
	doi = {10.1145/3301275.3302331},
	abstract = {Technology acceptance is a critical factor influencing the adoption of automated vehicles. Consequently, manufacturers feel obliged to design automated driving systems in a way to account for negative effects of automation on user experience. Recent publications confirm that full automation will potentially lack in the satisfaction of important user needs. To counteract, the adoption of Intelligent User Interfaces (IUIs) could play an important role. In this work, we focus on the evaluation of the impact of scenario type (represented by variations of road type and traffic volume) on the fulfillment of psychological needs. Results of a qualitative study (N=30) show that the scenario has a high impact on how users perceive the automation. Based on this, we discuss the potential of adaptive IUIs in the context of automated driving. In detail, we look at the aspects trust, acceptance, and user experience and its impact on IUIs in different driving situations.},
	urldate = {2025-07-04},
	booktitle = {Proceedings of the 24th {International} {Conference} on {Intelligent} {User} {Interfaces}},
	publisher = {Association for Computing Machinery},
	author = {Frison, Anna-Katharina and Wintersberger, Philipp and Liu, Tianjia and Riener, Andreas},
	year = {2019},
	pages = {528--537},
	file = {Full Text PDF:C\:\\Users\\giand\\Zotero\\storage\\DTGILL5J\\Frison et al. - 2019 - Why do you like to drive automated a context-dependent analysis of highly automated driving to elab.pdf:application/pdf},
}


@inproceedings{terken_unwinding_2013,
	address = {New York, NY, USA},
	series = {{AutomotiveUI} '13},
	title = {Unwinding after work: an in-car mood induction system for semi-autonomous driving},
	isbn = {978-1-4503-2478-6},
	shorttitle = {Unwinding after work},
	url = {https://dl.acm.org/doi/10.1145/2516540.2516571},
	doi = {10.1145/2516540.2516571},
	abstract = {We present a concept for an in-car system to support unwinding after work. It consists of a mood sensing steering wheel, an interactive in-car environment and a tangible input device. The in-car environment incorporates a basic state that uses color to relax or energize the driver, and an exploratory state that intends to immerse the user into a simulated environment. In the exploratory state, the user plays with a tangible input device allowing the simulated environment to appear. This environment includes images and sounds related to a certain theme. Our preliminary research findings reveal that users felt significantly calmer and marginally significantly better after interacting with the simulated environment. Results from the semi-structured interviews demonstrated that the majority of people appreciated the system and thought it might be effective to support unwinding. These outcomes demonstrate potential in the concept, but testing in a more realistic setting is necessary.},
	urldate = {2025-07-04},
	booktitle = {Proceedings of the 5th {International} {Conference} on {Automotive} {User} {Interfaces} and {Interactive} {Vehicular} {Applications}},
	publisher = {Association for Computing Machinery},
	author = {Terken, Zoë and Haex, Roy and Beursgens, Luuk and Arslanova, Elvira and Vrachni, Maria and Terken, Jacques and Szostak, Dalila},
	year = {2013},
	pages = {246--249},
	file = {Full Text PDF:C\:\\Users\\giand\\Zotero\\storage\\8GJL6V67\\Terken et al. - 2013 - Unwinding after work an in-car mood induction system for semi-autonomous driving.pdf:application/pdf},
}


@article{madigan_acceptance_2016,
	series = {Transport {Research} {Arena} {TRA2016}},
	title = {Acceptance of {Automated} {Road} {Transport} {Systems} ({ARTS}): {An} {Adaptation} of the {UTAUT} {Model}},
	volume = {14},
	issn = {2352-1465},
	shorttitle = {Acceptance of {Automated} {Road} {Transport} {Systems} ({ARTS})},
	url = {https://www.sciencedirect.com/science/article/pii/S2352146516302435},
	doi = {10.1016/j.trpro.2016.05.237},
	abstract = {As research into innovative forms of automated transportation systems gains momentum, it is important that we develop an understanding of the factors that will impact the adoption of these systems. In an effort to address this issue, the European project CityMobil2 is collecting data around large-scale demonstrations of Automated Road Transport Systems (ARTS) in a number of cities across Europe. For these systems to be successful, user acceptance is vital. The current study used the Unified Theory of Acceptance and Use of Technology (UTAUT) to investigate the factors which might influence acceptance of ARTS vehicles, which were operational in two locations in Europe. The results indicate that the UTAUT constructs of performance expectancy, effort expectancy and social influence were all useful predictors of behavioural intentions to use ARTS, with performance expectancy having the strongest impact. However, it would appear that other factors are also needed in order for the model to strongly predict behavioural intentions in an automated transport context. Based on these findings, a number of implications for developers and ideas for future research are suggested.},
	urldate = {2025-07-04},
	journal = {Transportation Research Procedia},
	author = {Madigan, Ruth and Louw, Tyron and Dziennus, Marc and Graindorge, Tatiana and Ortega, Erik and Graindorge, Matthieu and Merat, Natasha},
	month = jan,
	year = {2016},
	keywords = {automation, autonomous vehicles, intelligent transport systems, UTAUT},
	pages = {2217--2226},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\giand\\Zotero\\storage\\JDN8JDRG\\Madigan et al. - 2016 - Acceptance of Automated Road Transport Systems (ARTS) An Adaptation of the UTAUT Model.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\giand\\Zotero\\storage\\AW6KZJAK\\S2352146516302435.html:text/html},
}

@incollection{fraedrich_societal_2016,
	title = {Societal and {Individual} {Acceptance} of {Autonomous} {Driving}},
	isbn = {978-3-662-48847-8},
	url = {https://link.springer.com/chapter/10.1007/978-3-662-48847-8_29},
	abstract = {What attitudes and expectations do (potential) future users, and the public at large, bring to the new technology of autonomous driving? Alongside the technical and legal areas of research, this question is moving into ever-greater focus. The emerging debates assume...},
	language = {en},
	urldate = {2025-07-04},
	booktitle = {Autonomous {Driving}},
	publisher = {Springer, Berlin, Heidelberg},
	author = {Fraedrich, Eva and Lenz, Barbara},
	year = {2016},
	doi = {10.1007/978-3-662-48847-8\_29},
	pages = {621--640},
	file = {Full Text PDF:C\:\\Users\\giand\\Zotero\\storage\\LASBFMIA\\Fraedrich and Lenz - 2016 - Societal and Individual Acceptance of Autonomous Driving.pdf:application/pdf},
}

@article{hoff_trust_2015,
	title = {Trust in {Automation}: {Integrating} {Empirical} {Evidence} on {Factors} {That} {Influence} {Trust}},
	volume = {57},
	issn = {0018-7208},
	shorttitle = {Trust in {Automation}},
	url = {https://doi.org/10.1177/0018720814547570},
	doi = {10.1177/0018720814547570},
	abstract = {Objective:We systematically review recent empirical research on factors that influence trust in automation to present a three-layered trust model that synthesizes existing knowledge.Background:Much of the existing research on factors that guide human-automation interaction is centered around trust, a variable that often determines the willingness of human operators to rely on automation. Studies have utilized a variety of different automated systems in diverse experimental paradigms to identify factors that impact operators’ trust.Method:We performed a systematic review of empirical research on trust in automation from January 2002 to June 2013. Papers were deemed eligible only if they reported the results of a human-subjects experiment in which humans interacted with an automated system in order to achieve a goal. Additionally, a relationship between trust (or a trust-related behavior) and another variable had to be measured. All together, 101 total papers, containing 127 eligible studies, were included in the review.Results:Our analysis revealed three layers of variability in human–automation trust (dispositional trust, situational trust, and learned trust), which we organize into a model. We propose design recommendations for creating trustworthy automation and identify environmental conditions that can affect the strength of the relationship between trust and reliance. Future research directions are also discussed for each layer of trust.Conclusion:Our three-layered trust model provides a new lens for conceptualizing the variability of trust in automation. Its structure can be applied to help guide future research and develop training interventions and design procedures that encourage appropriate trust.},
	language = {EN},
	number = {3},
	urldate = {2025-07-04},
	journal = {Human Factors},
	author = {Hoff, Kevin Anthony and Bashir, Masooda},
	month = may,
	year = {2015},
	note = {Publisher: SAGE Publications Inc},
	pages = {407--434},
	file = {SAGE PDF Full Text:C\:\\Users\\giand\\Zotero\\storage\\BGTLVGSY\\Hoff and Bashir - 2015 - Trust in Automation Integrating Empirical Evidence on Factors That Influence Trust.pdf:application/pdf},
}

@article{schlosmacher_audi_nodate,
	title = {Audi {Aicon} concept car – autonomous on course for the future},
	url = {https://preview.thenewsmarket.com/Previews/GAUD/DocumentAssets/484532.pdf},
	language = {en},
	author = {Schloßmacher, Josef},
	file = {PDF:C\:\\Users\\giand\\Zotero\\storage\\F3XL6LEJ\\Schloßmacher - Audi Aicon concept car – autonomous on course for the future.pdf:application/pdf},
        note = {Accessed on 07.05.2025},
}

@misc{mercedes-benz_deutschland_zukunftsweisend_2015,
	title = {Zukunftsweisend und modern – {Fahren} mit dem {F} 015},
	url = {https://www.youtube.com/watch?v=cgOZgo8f_eI},
	abstract = {Futuristisches Design trifft auf durchdachte Technologie. In San Francisco gab das Entwicklerteam rund um den Mercedes-Benz F 015 Luxury in Motion einen exklusiven Einblick in die Technologie. Mehr Informationen zum F 015 Luxury in Motion unter http://mb4.me/6ekooXrX},
	note = {Accessed on 07.05.2025},
	author = {{Mercedes-Benz Deutschland}},
	month = apr,
	year = {2015},
}

@misc{mercedes-benz_australia_mercedes-benz_nodate,
	title = {Mercedes-{Benz} {F} 015 {Luxury} in {Motion}},
	url = {https://www.mercedes-benz.com.au/passengercars/campaigns/mercedes-benz-f-015.html},
	abstract = {With its immersive user experience, the Mercedes-Benz F 015 Luxury in Motion concept car provides an innovative perspective into the future of mobility. This autonomously driving luxury saloon elevates the car from a mere means of transport into a private place of retreat.},
	language = {en-AU},
	note = {Accessed on 07.05.2025},
	journal = {Mercedes-Benz},
	author = {{Mercedes-Benz Australia}},
}

@article{schlott_fahrzeuginnenraume_2016,
	title = {Fahrzeuginnenräume für automatisierte {Mobilitätsstrategien}},
	volume = {118},
	copyright = {2016 Springer Fachmedien Wiesbaden},
	issn = {2192-8800},
	url = {https://link.springer.com/article/10.1007/s35148-015-0184-5},
	doi = {10.1007/s35148-015-0184-5},
	
	number = {3},
	urldate = {2025-07-05},
	journal = {ATZ - Automobiltechnische Zeitschrift},
	author = {Schlott, Stefan},
	month = mar,
	year = {2016},
	note = {Company: Springer
Distributor: Springer
Institution: Springer
Label: Springer
Number: 3
Publisher: Springer Fachmedien Wiesbaden},
	pages = {8--13},
	file = {Full Text PDF:C\:\\Users\\giand\\Zotero\\storage\\LAEGFGVH\\Schlott - 2016 - Fahrzeuginnenräume für automatisierte Mobilitätsstrategien.pdf:application/pdf},
}

@misc{mercedes-benz_f_2015,
	title = {The {F} 015 {Luxury} in {Motion} {Future} {City} - {Mercedes}-{Benz} original},
	url = {https://www.youtube.com/watch?v=SlfpZmCCZ_U},
	abstract = {The autonomously driving research car F 015 Luxury in Motion demonstrates in this animated video several scenarios of the future. For instance, the F 015 is able to park itself autonomously or to project a virtual crosswalk onto the road surface which lets the pedestrian know the road},
	note = {Accessed on 07.05.2025},
	author = {{Mercedes-Benz}},
	month = mar,
	year = {2015},
}

@misc{nissan_2015_2015,
	title = {2015 {Nissan} {IDS} {Concept} - {Together} {We} {Ride}},
	url = {https://www.youtube.com/watch?v=pgXdpDJJaA0},
	note = {Accessed on 07.05.2025},
	author = {{Nissan}},
	month = oct,
	year = {2015},
}

@misc{nissan_nissan_2015,
	title = {Nissan {IDS} {Concept}: {Eine} {Vision} über {EV} der {Zukunft} und autonomes {Fahren}},
	shorttitle = {Nissan {IDS} {Concept}},
	url = {https://germany.nissannews.com/de-DE/releases/nissan-ids-concept-eine-vision-ber-ev-der-zukunft-und-autonomes-fahren},
	abstract = {Mit der Premiere des IDS Concept präsentiert Nissan auf der Tokyo Motor Show 2015 seine Zukunftsvision für das emissionsfreie und autonome Fahren mit batterieelektrischen Fahrzeugen.},
	language = {de-DE},
	note = {Accessed on 07.05.2025},
	journal = {Offizielles Presseportal {\textbar} Nissan Deutschland},
	author = {{Nissan}},
	month = oct,
	year = {2015},
	file = {Snapshot:C\:\\Users\\giand\\Zotero\\storage\\KL9FSE8E\\nissan-ids-concept-eine-vision-ber-ev-der-zukunft-und-autonomes-fahren.html:text/html},
}

@misc{motor1_rinspeed_2014,
	title = {Rinspeed {XchangE} interior raw footage},
	url = {https://www.youtube.com/watch?v=Bdi-FnkHZm8},
	abstract = {Creative Commons-Lizenz mit Quellenangabe (Wiederverwendung erlaubt)},
	note = {Accessed on 07.05.2025},
	author = {{Motor1}},
	month = feb,
	year = {2014},
}

@misc{rolls-royce_motor_cars_future_nodate,
	title = {The future in the making: {Rolls}‑{Royce} {103EX}: {Vision} {Next} 100},
	shorttitle = {The future in the making},
	url = {https://www.rolls-roycemotorcars.com/en_GB/inspiring-greatness/vision/103ex.html},
	abstract = {Introducing the visionary Rolls-Royce 103EX. Journey into the future of luxury travel, with our first ever autonomous motor car.},
	language = {en-GB},
	  note = {Accessed on 07.05.2025},
	journal = {Rolls-Royce Motor Cars},
	author = {{Rolls-Royce Motor Cars}},
}

@misc{form_trends_italdesign_2016,
	title = {Italdesign {Gira} {Concept} – {Autonomous} {Car} {Interior}},
	url = {https://www.youtube.com/watch?v=Uf4iiYTsBwA},
	abstract = {Volkswagen Group Research, in collaboration with designers and engineers at Italdesign, has devised a futuristic vehicle interior study called ‘Gira’ http://www.formtrends.com/volkswagen-...},
	note = {Accessed on 07.05.2025},
	author = {{Form Trends}},
	month = nov,
	year = {2016},
}

@misc{volvo_cars_volvo_2016,
	title = {Volvo {Cars}: {The} {Future} {Of} {Excellence}},
	shorttitle = {Volvo {Cars}},
	url = {https://www.youtube.com/watch?v=LZX4485Rqb8},
	abstract = {We believe in doing things differently. Introducing the S90 Excellence Concept.},
	note = {Accessed on 07.05.2025},
	author = {{Volvo Cars}},
	month = apr,
	year = {2016},
}

@misc{volvo_volvo_nodate,
	title = {Volvo {S90} {Excellence}: {Interieurkonzept} als {Kunstwerk}},
	shorttitle = {Volvo {S90} {Excellence}},
	url = {https://www.media.volvocars.com/at/de-at/media/pressreleases/189929/volvo-s90-excellence-interieurkonzept-als-kunstwerk},
	abstract = {Ein realitätsnahes Kunstwerk präsentiert Volvo auf der Auto China 2016 in Peking (25. April bis 4. Mai): Die Skulptur basiert auf dem Innenraum des neuen Volvo S90 Excellence, dem künftigen Topmodell der Premium-Limousine. Mit dem Konzept gibt der schwedische Hersteller einen Ausblick auf die weiterentwickelte „Lounge Console“ und demonstriert sein Verständnis von progressivem Luxus. Das Unternehmen hatte im vergangenen Jahr im Volvo XC90 Excellence erstmals das „Lounge Console“ Konzept vorgestellt, wo ein variables Modul den Beifahrersitz ersetzt und dadurch ein höchst wandlungsfähiger Innenraum entsteht.},
	language = {de-at},
	note = {Accessed on 07.05.2025},
	journal = {Volvo Cars Media},
	author = {{Volvo}},
	file = {Snapshot:C\:\\Users\\giand\\Zotero\\storage\\7ARI295E\\volvo-s90-excellence-interieurkonzept-als-kunstwerk.html:text/html},
}

@misc{the_wheel_network_volvo_2018,
	title = {Volvo 360c {Autonomous} {Concept} - {Exterior} \& {Interior}},
	url = {https://www.youtube.com/watch?v=X0cG5lDkrK4},
	abstract = {With its new 360c autonomous concept, Volvo Cars tackles one of the main challenges around the introduction of autonomous technology and calls for a new, global standard in how autonomous vehicles can safely communicate with all other road users.},
	note = {Accessed on 07.05.2025},
	author = {{The Wheel Network}},
	month = sep,
	year = {2018},
}

@misc{renault_group_renault_2017,
	title = {Renault {SYMBIOZ}: concept and vision for mobility {\textbar} {Renault}},
	shorttitle = {Renault {SYMBIOZ}},
	url = {https://www.youtube.com/watch?v=wWofSIB4osY},
	abstract = {Renault today took the wraps off SYMBIOZ, an integrated house and car that work together in harmony. SYMBIOZ extends the vision of autonomous, electric and connected cars to a time when vehicles fully interact with connected homes, cities, other vehicles and road infrastructure and become even more personal in the travel, energy and entertainment preferences of people who use them.},
	note = {Accessed on 07.05.2025},
	author = {{Renault Group}},
	month = sep,
	year = {2017},
}

@misc{carfection_audi_2019,
	title = {Audi {AI}:{ME} {Concept}: {Like} {It} {Or} {Not}, {This} {Might} {Be} {The} {Future} {\textbar} {Carfection}},
	shorttitle = {Audi {AI}},
	url = {https://www.youtube.com/watch?v=6RYnfncBCz8},
	abstract = {It might not be what we want to hear but Audi sees the future as one where we don't own cars but rather subscribe to a mobility service that involves cars like AiMe that autonomously drive to you and give you a relaxing experience on your way to your destination in the mega cities of tomorrow. 
Subscribe for more Carfection videos: http://bit.ly/1V1yFYX},
	note = {Accessed on 07.05.2025},
	author = {{Carfection}},
	month = apr,
	year = {2019},
}

@misc{completecarie_is_2022,
	title = {Is the {Volkswagen} {Group}'s {Gen}.{Travel} the future of autonomous driving?},
	url = {https://www.youtube.com/watch?v=igEnyaQZUIY},
	abstract = {The Volkswagen Group is presenting its vision of the future of mobility in the fully autonomous age with a design concept called Gen.Travel, an efficient and fully electric vehicle that could replace short-haul flights. The concept is the work of the Volkswagen Group rather than any one particular brand within the conglomerate and is part of the 'New Auto' strategy that, Volkswagen says, will define mobility "for generations to come".},
	note = {Accessed on 07.05.2025},
	author = {{CompleteCar.ie}},
	month = oct,
	year = {2022},
}

@misc{volkswagen_group_pressemitteilungen_innovative_2022,
	title = {Die innovative {Art} zu {Reisen}: {Designstudie} {GEN}.{TRAVEL} feiert {Weltpremiere}},
	shorttitle = {Die innovative {Art} zu {Reisen}},
	url = {https://www.volkswagen-group.com/de/pressemitteilungen/die-innovative-art-zu-reisen-designstudie-gentravel-feiert-weltpremiere-16447},
	abstract = {Im Rahmen der Chantilly Arts \& Elegance bei Paris präsentiert der Volkswagen Konzern am 24. September eine innovative Designstudie, die die zukünftige Langstreckenmobilität neu definiert. Das vollelektrisch angetriebene Innovation Experience Vehicle (IEV) ist ein realer Prototyp, fährt autonom (Level 5) und gibt einen realistischen Ausblick auf die Mobilität im nächsten Jahrzehnt. Aufgrund seines modularen Interieur-Konzepts stellt das Fahrzeug eine flexible und nachhaltige Mobility-as-a-Service Alternative zu Kurzstreckenflügen dar. Als Forschungsfahrzeug dient der Gen.Travel dazu, das Konzept und neue Funktionalitäten auf seine Resonanz bei Kunden und Kundinnen zu testen. Auf Basis der Ergebnisse solcher Studien werden einzelne Features später in Serienfahrzeuge übertragen.},
	
	note = {Accessed on 07.05.2025},
	journal = {Volkswagen Group},
	author = {{Volkswagen Group Pressemitteilungen}},
	month = sep,
	year = {2022},
}

@misc{hyundaiworldwide_mobility_2017,
	title = {Mobility {Vision}},
	url = {https://www.youtube.com/watch?v=0P2ga4wQ0PQ},
	abstract = {Hyundai Motor’s Mobility Vision concept: the evolution from mobility to a living space},
	note = {Accessed on 07.05.2025},
	author = {{HyundaiWorldwide}},
	month = jan,
	year = {2017},
}

@misc{lincoln_live_2022,
	title = {Live {Action} {\textbar} {The} {Lincoln} {Model} {L100} {Concept} {Vehicle} {\textbar} {Lincoln}},
	url = {https://www.youtube.com/watch?v=aJEiKz1VtwE},
	abstract = {Reimagining the future of personal mobility. The Model L100 Concept pays homage to Lincoln's first luxury vehicle, the 1922 Model L. The L100 Concept features sleek, aero-influenced styling and a futuristic design that evolves Lincoln's Quiet Flight DNA.},
	note = {Accessed on 07.05.2025},
	author = {{Lincoln}},
	month = sep,
	year = {2022},
}

@misc{lincoln_ford_motor_company_lincoln_nodate,
	title = {Lincoln {Model} {L100} {Concept} {Signals} the {Brand}’s {Future} {Vision}; {Explores} {Reimagined} {Space} for {Personal} {Mobility} {\textbar} {Lincoln} {Media} {Center}},
	url = {https://media.lincoln.com/content/lincolnmedia/lna/us/en/news/2022/08/18/lincoln-model-l100-concept-reveal.html},
	note = {Accessed on 07.05.2025},
	author = {{Lincoln (Ford Motor Company)}},
	file = {Lincoln Model L100 Concept Signals the Brand’s Future Vision\; Explores Reimagined Space for Personal Mobility | Lincoln Media Center:C\:\\Users\\giand\\Zotero\\storage\\QM2MHHRW\\lincoln-model-l100-concept-reveal.html:text/html},
}

@misc{peugeot_peugeot_nodate,
	title = {Peugeot {Inception} {Concept}: next-generation of electric cars},
	shorttitle = {Peugeot {Inception} {Concept}},
	url = {https://www.peugeot.co.uk/about-us/innovation/concept-cars/peugeot-inception-concept.html},
	abstract = {Discover our vision for the next generation of electric vehicles with the Peugeot Inception Concept car, showcasing the new Peugeot i-Cockpit.},
	language = {en},
	note = {Accessed on 07.05.2025},
	author = {{Peugeot}},
}

@misc{citroen_citroen_nodate,
	title = {{CITROËN} 19\_19 {CONCEPT}, {LE} {VOYAGE} {IN} Ë-{COMFORT} {MODE}},
	url = {https://www.media.stellantis.com/em-en/citroen/press/citroen-19-19-concept-le-voyage-in-e-comfort-mode},
	abstract = {Following Ami One Concept revealed last February and embodying the urban electric mobility, Citroën is presenting 19\_19 Concept, expressing Citroën’s vision of ultra-comfort and extended mobility to escape from the cities. Two electric concept cars responding to all the needs of the customers willing to be free to move, in a world asking for “always more”. A true Brand manifesto, 19\_19 Concept is an unconventional expression lying outside traditional automotive cues; a technological aerodynamic object with exceptional proportions and a spectacular, suspended and transparent capsule design inspired by the world of aviation. The new concept car illustrates ultra-comfort at the service of tomorrow’s mobility, Through its design: a cabin designed as a true living room in its architecture and materials, plunging each occupant into a cocoon in which each seat is a unique experience of absolute comfort; Through its technologies: a full-electric concept car with a range of 800 km, a true magic carpet ride with a suspended cabin equipped with suspension with Progressive Hydraulic Cushions® combined with smart active control, and featuring autonomous driving technologies and a proactive personal assistant that interacts unprompted with the passengers, bringing each one a whole new experience of car travel. 19\_19 Concept will be revealed as a World Premiere at VivaTech in Paris the 16 May 2019.},
	language = {en},
	note = {Accessed on 07.05.2025},
	journal = {Media Stellantis},
	author = {{Citroën}},
}

@misc{sony_honda_mobility_of_america_inc_afeela_nodate,
	title = {{AFEELA} - {EV} {\textbar} {Sony} {Honda} {Mobility}},
	url = {https://www.shm-afeela.com/en/},
	abstract = {AFEELA: A new generation of mobility pulsing with intelligence. Inviting you to be part of the future of mobility. Reserve yours now.},
	language = {en},
	note = {Accessed on 07.05.2025},
	journal = {AFEELA},
	author = {{Sony Honda Mobility of America Inc}},
}

@misc{hyundaiworldwide_ioniq_2021,
	title = {{IONIQ} {Concept} '{SEVEN}' {\textbar} {Live} in {SEVEN} – {Main} {Film}},
	url = {https://www.youtube.com/watch?v=7UXyfPLElhY},
	abstract = {Introducing the IONIQ Concept 'SEVEN' that will change our lives. 
SEVEN Concept represents our commitment to a human-centered approach to redefine everyday experiences as an innovative living space on wheels.},
	note = {Accessed on 07.05.2025},
	author = {{HyundaiWorldwide}},
	month = nov,
	year = {2021},
}

@misc{hyundai_worldwide_ioniq_nodate,
	title = {{IONIQ} {Concept} '{SEVEN}' - {Hyundai} {Worldwide}},
	url = {https://www.hyundai.com/worldwide/en/brand-journal/ioniq/introducing-the-seven-concept},
	abstract = {Check out the third part in our series about EVs. Join Britta Reineke to find out more about driving an EV and why the IONIQ 5 offers a new experience.},
	language = {en},
	note = {Accessed on 07.05.2025},
	journal = {HYUNDAI MOTORS},
	author = {{Hyundai Worldwide}},
}

@misc{lg_electronics_if_nodate,
	title = {{iF} {Design} - {LG} {Vision} {OMNIPOD}},
	url = {https://ifdesign.com/en/winner-ranking/project/lg-vision-omnipod/566300},
	abstract = {OMNIPOD is the futuristic car cabin solution that is a spatial extension of the home.
Users subscribe to the additional space for their purpose, which breaks down the boundaries between home and vehicle by supporting work office, music studio, personal gym area, outdoor restaurant, and more.
The overall spatial experience is made by adjusting linked services, the modular screen and home appliances. It provides not only the changing spatial layout, but a Metaverse experience linked to professional services with a Meta environment display inside, 6 types of upgradable modular home appliances, and the virtual human AI Concierge.},
	language = {en},
	note = {Accessed on 07.05.2025},
	author = {{LG Electronics}},
}

@misc{cnet_highlights_lg_2023,
	title = {{LG} {Reveals} {Omnipod} {Mobile} {Cabin} {Concept} ({IAA} {Mobility} 2023)},
	url = {https://www.youtube.com/watch?v=PzcQtqbcl8w},
	abstract = {At IAA Mobility 2023, LG unveiled its vision for a futuristic mobile cabin vehicle, dubbed the Omnipod.},
	note = {Accessed on 07.05.2025},
	author = {{CNET Highlights}},
	month = sep,
	year = {2023},
}

@misc{pininfarina_teorema_nodate,
	title = {Teorema},
	url = {https://pininfarina.it/projects/teorema},
	abstract = {Pininfarina's first visual concept car},
	language = {en-US},
	note = {Accessed on 07.05.2025},
        year = {2021},
	journal = {Pininfarina Projects},
	author = {{Pininfarina}},
}

@misc{bmw_group_bmw_nodate,
	title = {{BMW} {Vision} {iNEXT}},
	url = {https://www.bmwgroup.com/en/innovation/concept-cars-and-design/bmw-vision-i-next.html},
	abstract = {The BMW Vision iNEXT challenges conventional automotive design and creates a space that becomes your favorite place. Discover it now!},
	language = {en},
	  note = {Accessed on 07.05.2025},
	journal = {BMW},
	author = {{BMW Group}},
}

@misc{bmw_group_bmw_2018,
	title = {The {BMW} {Vision} {iNEXT}. {Creating} {A} {Space} {That} {Never} {Existed} {Before}.},
	url = {https://www.youtube.com/watch?v=dfbBru6JCSI},
	abstract = {We asked ourselves, "How will we be moving around in future?”. Meet the future of mobility today. 

The \#BMW \#VisioniNEXT symbolizes the dawn of a new era of driving pleasure. Highly automated, emission-free and fully networked, it integrates the strategic fields of i},
	  note = {Accessed on 07.05.2025},
	author = {{BMW Group}},
	month = sep,
	year = {2018},
}

@misc{bmw_group_bmw_nodate-1,
	title = {{BMW} i {Vision} {Dee}: {All} highlights {\textbar} {BMW}.{UK}},
	shorttitle = {{BMW} i {Vision} {Dee}},
	url = {https://www.bmw.co.uk/en/topics/discover/concept-cars/bmw-vision-ivisiondee-2023.html},
	abstract = {All highlights of the BMW i Vision Dee: Concept, design and digital technologies. Discover now.},
	language = {en-GB},
	  note = {Accessed on 07.05.2025},
	journal = {BMW UK},
	author = {{BMW Group}},
	file = {Snapshot:C\:\\Users\\giand\\Zotero\\storage\\2Z7PS3DB\\bmw-vision-ivisiondee-2023.html:text/html},
}

@misc{nissan_motor_corporation_nissan_2015,
	title = {Nissan {IDS} {Concept}: {Nissan}'s vision for the future of {EVs} and autonomous driving},
	shorttitle = {Nissan {IDS} {Concept}},
	url = {https://usa.nissannews.com/en-US/releases/nissan-ids-concept-nissan-s-vision-for-the-future-of-evs-and-autonomous-driving},
	abstract = {Today at the Tokyo Motor Show 2015, Nissan Motor Co., Ltd. unveiled a concept vehicle that embodies Nissan's vision of the future of autonomous driving and zero emission EVs: the Nissan IDS Concept.},
	language = {en-US},
	  note = {Accessed on 07.05.2025},
	journal = {Official U.S. Newsroom},
	author = {{Nissan Motor Corporation}},
	month = oct,
	year = {2015},
	file = {Snapshot:C\:\\Users\\giand\\Zotero\\storage\\B85VHEZG\\nissan-ids-concept-nissan-s-vision-for-the-future-of-evs-and-autonomous-driving.html:text/html},
}


@misc{gallina_volkswagen_2016,
	title = {Volkswagen {Italdesign} {Gira} {Shows} {Group}'s {Autonomous} {Interior} {Vision}},
	url = {https://www.formtrends.com/volkswagen-italdesign-gira-interior-concept/},
	abstract = {Volkswagen Group Research, in collaboration with designers and engineers at Italdesign, has devised a futuristic vehicle interior study called ‘Gira’, an abbreviation of a German phrase that roughly translates to ‘the relaxing way to drive’. The interior concept, accessed via wide gullwing doors that fold open to form a canopy above the passengers, depicts what it could be like to travel in a future semi-autonomous vehicle. The concept’s four gray seats can be adjusted to suit an array of different […]},
	language = {en-US},
	  note = {Accessed on 07.05.2025},
	journal = {Form Trends},
	author = {Gallina, Eric},
	month = nov,
	year = {2016},
	file = {Snapshot:C\:\\Users\\giand\\Zotero\\storage\\XQRHNXB4\\volkswagen-italdesign-gira-interior-concept.html:text/html},
}


@misc{volvo_cars_volvo_2018,
	title = {Volvo {Cars}’ new 360c autonomous concept: reimagining the work-life balance and the future of cities},
	shorttitle = {Volvo {Cars}’ new 360c autonomous concept},
	url = {https://www.media.volvocars.com/global/en-gb/media/pressreleases/237020/volvo-cars-new-360c-autonomous-concept-reimagining-the-work-life-balance-and-the-future-of-cities},
	abstract = {Where would you live if you could commute each workday in an autonomous driving, fully-functional, connected, comfortable, mobile office space? What if the service was provided via an on demand subscription basis? Or what if it was provided by one employer yet not another – which company would you work for?},
	language = {en-gb},
	note = {Accessed on 07.05.2025},
	journal = {Volvo Cars Global Newsroom},
	author = {{Volvo Cars}},
	month = sep,
	year = {2018},
	file = {Snapshot:C\:\\Users\\giand\\Zotero\\storage\\I3NX9FB6\\volvo-cars-new-360c-autonomous-concept-reimagining-the-work-life-balance-and-the-future-of-citi.html:text/html},
}

@article{eid_affective_2016,
	title = {Affective {Haptics}: {Current} {Research} and {Future} {Directions}},
	volume = {4},
	issn = {2169-3536},
	shorttitle = {Affective {Haptics}},
	url = {https://ieeexplore.ieee.org/document/7320966},
	doi = {10.1109/ACCESS.2015.2497316},
	abstract = {Touch plays a prominent role in communicating emotions and intensifying interpersonal communication. Affective haptics is an emerging field, which focuses on the analysis, design, and evaluation of systems that can capture, process, or display emotions through the sense of touch. The objective of this paper is to present an overview of the recent achievements in affective haptics and to discuss how the sense of touch can elicit or influence human emotions. We first introduce a definition to the term affective haptics and describe its multidisciplinary nature-as a field that integrates ideas from affective computing, haptic technology, and user experience. Second, we provide a thorough discussion about the effectiveness of using the haptic channel to communicate affective information through direct and mediated means. Third, we present a variety of applications in the area ranging from interhuman social interaction systems to human robot interaction applications. Finally, we discuss some of the key findings discerned from the various surveyed papers, and present some of the challenges and trends in this field. We extract the following conclusions pertaining to affective haptics: 1) haptic stimulation can be successfully used to achieve a higher level of emotional immersion during media consumption or emotional telepresence; 2) existing research has demonstrated that haptics is effective in communicating valence and arousal, and the emotions of happiness, sadness, anger and fear, and less focus have been given to the communication of disgust and surprise; 3) the haptic-based affect detection remains an understudied topic, whereas the haptic-based affect display is a well-established subject; and 4) the interpretation of the haptic stimulation by human beings is highly contextual.},
	urldate = {2025-07-06},
	journal = {IEEE Access},
	author = {Eid, Mohamad A. and Al Osman, Hussein},
	year = {2016},
	keywords = {Affective computing, Emotion recognition, Force feedback, haptic interfaces, Haptic interfaces, human computer interaction, Human computer interaction, Psychology, social computing, social computing,, tactile sensors, Tactile sensors},
	pages = {26--40},
	file = {Full Text PDF:C\:\\Users\\giand\\Zotero\\storage\\TYPEZIPW\\Eid and Al Osman - 2016 - Affective Haptics Current Research and Future Directions.pdf:application/pdf},
}

@article{sathyan_study_2020,
	title = {A {Study} and {Analysis} of {Touch} {Screen} {Technologies}},
	issn = {2456-3307},
	url = {http://ijsrcseit.com/paper/CSEIT2063184.pdf},
	doi = {10.32628/CSEIT2063184},
	abstract = {The use of touch screen in our day-to-day life is always there. People without touch screen are only a few. Touch screen were built for ease of work and for saving time. It is an assistive technology. This interface can be beneficial to those that have difficulty in using other input devices such as a mouse or keyboard. When used in conjunction with software such as on-screen keyboards, or other assistive technology, they can make computing resources more available to people that have difficulty in using computers. Touch Screen is widely used and emerging technology that is sensitive to human touch, allowing a user to interact with the computer by touching pictures or words on the screen. It provides a very good user interface with applications that normally require a mouse. The touch screen interface is going to revolutionize the electronic interactive devices in a big way. The purpose of this study is to analyse the various technologies used to build the touch screen and it's also helpful for the future gen those who make a study on it.},
	language = {en},
	urldate = {2025-07-06},
	journal = {International Journal of Scientific Research in Computer Science, Engineering and Information Technology},
	author = {Sathyan, Anu and Manikandan, L C},
	month = jul,
	year = {2020},
	pages = {737--744},
	file = {Full Text:C\:\\Users\\giand\\Zotero\\storage\\388C3PGS\\Sathyan and Manikandan - 2020 - A Study and Analysis of Touch Screen Technologies.pdf:application/pdf},
}

@inproceedings{hansberger_dispelling_2017,
	title = {Dispelling the {Gorilla} {Arm} {Syndrome}: {The} {Viability} of {Prolonged} {Gesture} {Interactions}},
	isbn = {978-3-319-57987-0},
	shorttitle = {Dispelling the {Gorilla} {Arm} {Syndrome}},
	url = {https://link.springer.com/chapter/10.1007/978-3-319-57987-0_41},
	doi = {10.1007/978-3-319-57987-0_41},
	abstract = {The use of gestures as a way to interact with computer systems has shown promise as a natural way to interact and manipulate digital information. However, users performing mid-air gestures for even moderate periods of time experience arm fatigue and discomfort,...},
	language = {en},
	urldate = {2025-07-06},
	booktitle = {Virtual, {Augmented} and {Mixed} {Reality}},
	publisher = {Springer, Cham},
	author = {Hansberger, Jeffrey T. and Peng, Chao and Mathis, Shannon L. and Areyur Shanthakumar, Vaidyanath and Meacham, Sarah C. and Cao, Lizhou and Blakely, Victoria R.},
	year = {2017},
	note = {ISSN: 1611-3349},
	pages = {505--520},
	file = {Full Text PDF:C\:\\Users\\giand\\Zotero\\storage\\AE45LGIG\\Hansberger et al. - 2017 - Dispelling the Gorilla Arm Syndrome The Viability of Prolonged Gesture Interactions.pdf:application/pdf},
}

@inproceedings{hermann_pixels_2022,
	title = {Pixels {On} {The} {Road} - {Where} {Are} {They} {Headed}?},
	url = {https://ieeexplore.ieee.org/abstract/document/9851374},
	doi = {10.23919/AM-FPD54920.2022.9851374},
	abstract = {This paper describes how “pixels on the road” have grown by the numbers over the past decade and provides a personal outlook on where they are headed in the coming years.},
	urldate = {2025-07-06},
	booktitle = {2022 29th {International} {Workshop} on {Active}-{Matrix} {Flatpanel} {Displays} and {Devices} ({AM}-{FPD})},
	author = {Hermann, David S.},
	month = jul,
	year = {2022},
	keywords = {Drives, Force, Head-up displays, Market research, Roads, Technological innovation, User experience},
	pages = {37--44},
	file = {Full Text PDF:C\:\\Users\\giand\\Zotero\\storage\\SAEV7X9A\\Hermann - 2022 - Pixels On The Road - Where Are They Headed.pdf:application/pdf},
}

@inproceedings{hermann_user_2020,
	title = {User {Experience} and {HMI} {Technologies} for the {Future}},
	url = {https://ieeexplore.ieee.org/abstract/document/9224505},
	doi = {10.23919/AM-FPD49417.2020.9224505},
	abstract = {The nature of the automotive industry is changing as Connectivity, Autonomous Drive, Shared Mobility concepts and Electrification take center stage in this new decade. This transformation will drive some unique needs and present some interesting challenges in the years ahead. In this paper we will explore how the User Experience, and the HMI technologies that enable it, will define how we perceive the future of mobility.},
	urldate = {2025-07-06},
	booktitle = {2020 27th {International} {Workshop} on {Active}-{Matrix} {Flatpanel} {Displays} and {Devices} ({AM}-{FPD})},
	author = {Hermann, David S. and Singh, Sandhya},
	month = sep,
	year = {2020},
	keywords = {Active matrix technology, Automotive engineering, Autonomous vehicles, Conferences, Industries, User experience},
	pages = {39--44},
	file = {Full Text PDF:C\:\\Users\\giand\\Zotero\\storage\\EBAQGHPW\\Hermann and Singh - 2020 - User Experience and HMI Technologies for the Future.pdf:application/pdf},
}

@inproceedings{mathis_towards_2021,
	title = {Towards {Future} {Interior} {Concepts}: {User} {Perception} and {Requirements} for the {Use} {Case} {Working} in the {Autonomous} {Car}},
	isbn = {978-3-030-80012-3},
	shorttitle = {Towards {Future} {Interior} {Concepts}},
	url = {https://link.springer.com/chapter/10.1007/978-3-030-80012-3_37},
	doi = {10.1007/978-3-030-80012-3_37},
	abstract = {Working and being productive while commuting and travelling is a promising use case for automated and autonomous vehicles. Whereas different concepts have already been proposed how future interior concepts can support in-car work, user requirements for this use case...},
	language = {en},
	urldate = {2025-07-06},
	booktitle = {Advances in {Human} {Aspects} of {Transportation}},
	publisher = {Springer, Cham},
	author = {Mathis, Lesley-Ann and Widlroither, Harald and Traub, Nico},
	year = {2021},
	note = {ISSN: 2367-3389},
	pages = {315--322},
	file = {Full Text PDF:C\:\\Users\\giand\\Zotero\\storage\\GSTMGNEM\\Mathis et al. - 2021 - Towards Future Interior Concepts User Perception and Requirements for the Use Case Working in the A.pdf:application/pdf},
}

@inproceedings{beruscha_evaluation_2017,
	title = {An evaluation of the influence of haptic feedback on gaze behavior during in-car interaction with touch screens},
	url = {https://ieeexplore.ieee.org/abstract/document/7989901},
	doi = {10.1109/WHC.2017.7989901},
	abstract = {A major motivation for the introduction of haptic feedback in in-vehicle touch screens is the reduction of the eyes-off-road time. This paper presents a study which compares different feedback conditions for touch screen interaction: (1) visual feedback, (2) combined visual-haptic feedback, and (3) haptic feedback only. Subjects had to select target buttons on a touch screen during simulated driving. Our results show that haptic feedback significantly reduces the eyes-off-road time and the subjectively perceived workload. When visual content is available, gazes on the touch screen are more frequent than necessary. And even in the absence of visual content, complete eyes-free interaction was only occasionally spotted, and subjects still looked at the screen initially. We assume that this is due to the necessity of an initial reference position.},
	urldate = {2025-07-06},
	booktitle = {2017 {IEEE} {World} {Haptics} {Conference} ({WHC})},
	author = {Beruscha, Frank and Krautter, Wolfgang and Lahmer, Anja and Pauly, Markus},
	month = jun,
	year = {2017},
	keywords = {Automobiles, Haptic interfaces, Roads, Thumb, Touch sensitive screens, Visualization},
	pages = {201--206},
	file = {Full Text PDF:C\:\\Users\\giand\\Zotero\\storage\\GM8CFQ3D\\Beruscha et al. - 2017 - An evaluation of the influence of haptic feedback on gaze behavior during in-car interaction with to.pdf:application/pdf},
}

@inproceedings{patel_inspection_2022,
	title = {Inspection of {In}-{Vehicle} {Touchscreen} {Infotainment} {Display} for {Different} {Screen} {Locations}, {Menu} {Types}, and {Positions}},
	isbn = {978-3-031-04987-3},
	url = {https://link.springer.com/chapter/10.1007/978-3-031-04987-3_18},
	doi = {10.1007/978-3-031-04987-3_18},
	abstract = {There has been a rapid increase in \&\#8216;In-vehicle touchscreens\&\#8217; usage over the last decade, particularly for information and entertainment functions. And because of the dynamic interface functionality, the touchscreen becomes a major attraction for the...},
	language = {en},
	urldate = {2025-07-06},
	booktitle = {{HCI} in {Mobility}, {Transport}, and {Automotive} {Systems}},
	publisher = {Springer, Cham},
	author = {Patel, Saumil and Liu, Yi and Zhao, Ruobing and Liu, Xinyu and Li, Yueqing},
	year = {2022},
	note = {ISSN: 1611-3349},
	pages = {258--279},
	file = {Full Text PDF:C\:\\Users\\giand\\Zotero\\storage\\CE5EVJEX\\Patel et al. - 2022 - Inspection of In-Vehicle Touchscreen Infotainment Display for Different Screen Locations, Menu Types.pdf:application/pdf},
}

@inproceedings{mayer_effect_2018,
	address = {New York, NY, USA},
	series = {{AutomotiveUI} '18},
	title = {The {Effect} of {Road} {Bumps} on {Touch} {Interaction} in {Cars}},
	isbn = {978-1-4503-5946-7},
	url = {https://dl.acm.org/doi/10.1145/3239060.3239071},
	doi = {10.1145/3239060.3239071},
	abstract = {Touchscreens are a common fixture in current vehicles. With autonomous driving, we can expect touch interaction with such in-vehicle media systems to exponentially increase. In spite of vehicle suspension systems, road perturbations will continue to exert forces that can render in-vehicle touch interaction challenging. Using a motion simulator, we investigate how different vehicle speeds interact with road features (i.e., speed bumps) to influence touch interaction. We determine their effect on pointing accuracy and task completion time. We show that road bumps have a significant effect on touch input and can decrease accuracy by 19\%. In light of this, we developed a Random Forest (RF) model that improves touch accuracy by 32.0\% on our test set and by 22.5\% on our validation set. As the lightweight model uses only features that can easily be determined through inertial measurement units, this model could be easily deployed in current automobiles.},
	urldate = {2025-07-06},
	booktitle = {Proceedings of the 10th {International} {Conference} on {Automotive} {User} {Interfaces} and {Interactive} {Vehicular} {Applications}},
	publisher = {Association for Computing Machinery},
	author = {Mayer, Sven and Le, Huy Viet and Nesti, Alessandro and Henze, Niels and Bülthoff, Heinrich H. and Chuang, Lewis L.},
	month = sep,
	year = {2018},
	pages = {85--93},
	file = {Full Text PDF:C\:\\Users\\giand\\Zotero\\storage\\W3SQLZSI\\Mayer et al. - 2018 - The Effect of Road Bumps on Touch Interaction in Cars.pdf:application/pdf},
}

@inproceedings{ahmad_touchscreen_2015,
	address = {New York, NY, USA},
	series = {{AutomotiveUI} '15},
	title = {Touchscreen usability and input performance in vehicles under different road conditions: an evaluative study},
	isbn = {978-1-4503-3736-6},
	shorttitle = {Touchscreen usability and input performance in vehicles under different road conditions},
	url = {https://dl.acm.org/doi/10.1145/2799250.2799284},
	doi = {10.1145/2799250.2799284},
	abstract = {With the proliferation of the touchscreen technology, interactive displays are becoming an integrated part of the modern vehicle environment. However, due to road and driving conditions, the user input on such displays can be perturbed resulting in erroneous selections. This paper describes an evaluative study of the usability and input performance of in-vehicle touchscreens. The analysis is based on data collected in instrumented cars driven under various road/driving conditions. We assess the frequency of failed selection attempts, distances by which users miss the intended on-screen target and the durations of undertaken free hand pointing gestures to accomplish the selection tasks. It is shown that the road/driving conditions can notably undermine the usability of an interactive display when the user input is perturbed, e.g. due to the experienced vibrations and lateral accelerations in the vehicle. The distance between the location of an erroneous on-screen selection and the intended endpoint on the display, is closely related to the level of present in-vehicle noise. The conducted study can advise graphical user interfaces design for the vehicle environment where the user free hand pointing gestures can be subject to varying levels of perturbations.},
	urldate = {2025-07-06},
	booktitle = {Proceedings of the 7th {International} {Conference} on {Automotive} {User} {Interfaces} and {Interactive} {Vehicular} {Applications}},
	publisher = {Association for Computing Machinery},
	author = {Ahmad, Bashar I. and Langdon, Patrick M. and Godsill, Simon J. and Hardy, Robert and Skrypchuk, Lee and Donkor, Richard},
	month = sep,
	year = {2015},
	pages = {47--54},
	file = {Full Text PDF:C\:\\Users\\giand\\Zotero\\storage\\52TDJENC\\Ahmad et al. - 2015 - Touchscreen usability and input performance in vehicles under different road conditions an evaluati.pdf:application/pdf},
}

@article{pitts_evaluating_2012,
	title = {Evaluating {User} {Response} to {In}-{Car} {Haptic} {Feedback} {Touchscreens} {Using} the {Lane} {Change} {Test}},
	volume = {2012},
	copyright = {Copyright © 2012 Matthew J. Pitts et al.},
	issn = {1687-5907},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1155/2012/598739},
	doi = {10.1155/2012/598739},
	abstract = {Touchscreen interfaces are widely used in modern technology, from mobile devices to in-car infotainment systems. However, touchscreens impose significant visual workload demands on the user which have safety implications for use in cars. Previous studies indicate that the application of haptic feedback can improve both performance of and affective response to user interfaces. This paper reports on and extends the findings of a 2009 study conducted to evaluate the effects of different combinations of touchscreen visual, audible, and haptic feedback on driving and task performance, affective response, and subjective workload; the initial findings of which were originally published in (M. J. Pitts et al., 2009). A total of 48 non-expert users completed the study. A dual-task approach was applied, using the Lane Change Test as the driving task and realistic automotive use case touchscreen tasks. Results indicated that, while feedback type had no effect on driving or task performance, preference was expressed for multimodal feedback over visual alone. Issues relating to workload and cross-modal interaction were also identified.},
	language = {en},
	number = {1},
	urldate = {2025-07-06},
	journal = {Advances in Human-Computer Interaction},
	author = {Pitts, Matthew J. and Skrypchuk, Lee and Wellings, Tom and Attridge, Alex and Williams, Mark A.},
	year = {2012},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1155/2012/598739},
	pages = {598739},
	file = {Full Text PDF:C\:\\Users\\giand\\Zotero\\storage\\ZH7KVHRJ\\Pitts et al. - 2012 - Evaluating User Response to In-Car Haptic Feedback Touchscreens Using the Lane Change Test.pdf:application/pdf;Snapshot:C\:\\Users\\giand\\Zotero\\storage\\E8CDWP22\\598739.html:text/html},
}

@article{huo_influence_2024,
	title = {The influence of tactile feedback in {In}-vehicle central control interfaces on driver emotions: {A} comparative study of touchscreens and physical buttons},
	volume = {101},
	issn = {0169-8141},
	shorttitle = {The influence of tactile feedback in {In}-vehicle central control interfaces on driver emotions},
	url = {https://www.sciencedirect.com/science/article/pii/S0169814124000428},
	doi = {10.1016/j.ergon.2024.103586},
	abstract = {Touchscreen in-vehicle central control interfaces are rapidly replacing traditional physical buttons. However, the differences in the effects of tactile feedback between touchscreens and physical buttons on driver emotions are unclear. This study used a simulated driving experiment to investigate the effects of tactile feedback mode and intensity on driver emotion using the Self-Assessment Manikin (SAM). The results showed that tactile feedback mode, intensity, and difficulty of non-driving-related tasks (NDRTs) significantly affected drivers' emotional states. Touchscreen tactile feedback elicited a more positive emotional state than physical button tactile feedback. The intensity of touchscreen tactile feedback is positively correlated with driver emotional valence. However, higher-intensity physical button feedback decreases driver emotional valence, particularly when drivers are engaged in complex NDRTs, and the difference due to feedback intensity is insignificant. The study's results could help automakers intervene by designing tactile feedback to enhance the emotional experience of the driver's in-vehicle interaction interface.},
	urldate = {2025-07-06},
	journal = {International Journal of Industrial Ergonomics},
	author = {Huo, Faren and Wang, Tai and Fang, Fei and Sun, Cong},
	month = may,
	year = {2024},
	keywords = {Driving, Emotion, In-vehicle central control interface, Physical button, Tactile feedback, Touchscreen},
	pages = {103586},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\giand\\Zotero\\storage\\HGI9WPH9\\Huo et al. - 2024 - The influence of tactile feedback in In-vehicle central control interfaces on driver emotions A com.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\giand\\Zotero\\storage\\H2SCM9G3\\S0169814124000428.html:text/html},
}

@article{breitschaft_wheres_2022,
	title = {Where's {My} {Button}? {Evaluating} the {User} {Experience} of {Surface} {Haptics} in {Featureless} {Automotive} {User} {Interfaces}},
	volume = {15},
	issn = {2329-4051},
	shorttitle = {Where's {My} {Button}?},
	url = {https://ieeexplore.ieee.org/abstract/document/9627777},
	doi = {10.1109/TOH.2021.3131058},
	abstract = {Advancements in user interface technologies and demands of design engineering led to increasing implementation of large and mostly flat interactive surfaces in automotive. Recent discussions in the context of in-vehicle usage of touchscreens advocate for the use of haptic feedback to restore the explore- and feel-qualities typically experienced in traditional physical button interfaces that contribute to intuitive, eyes-free, and tactually rich interactions. Haptic technologies that include a friction modulation approach seem especially promising to convey a high-quality feeling. This research reports an experience-oriented evaluation of an electrostatic friction haptic display in an in-vehicle direct touch interaction context. The evaluation was based on an automotive multitask setting (primary driving-task and secondary target-selection-task) with a 2 × 2 feedback modality design (factors haptic/audio with levels absent/present). The objective variables (response time, errors, and performance on the primary task) did not differ between feedback modalities. Any additional feedback to a visual baseline enhanced the user experience, with the multimodal feedback being preferred by most participants. Surface haptics was perceived as a novel yet unexpected type of haptic feedback. We discuss the implications for the haptic design of programmable friction displays and provide an initial set of guidelines for this innovative technology.},
	number = {2},
	urldate = {2025-07-06},
	journal = {IEEE Transactions on Haptics},
	author = {Breitschaft, Stefan Josef and Pastukhov, Alexander and Carbon, Claus-Christian},
	month = apr,
	year = {2022},
	keywords = {automotive, Automotive engineering, electrostatic friction modulation., Electrostatics, Friction, Haptic design, haptic experience, haptic feedback, Haptic interfaces, Modulation, surface haptics, Task analysis, user interface, Visualization},
	pages = {292--303},
	file = {Full Text PDF:C\:\\Users\\giand\\Zotero\\storage\\R32CSCH2\\Breitschaft et al. - 2022 - Where's My Button Evaluating the User Experience of Surface Haptics in Featureless Automotive User.pdf:application/pdf},
}

@misc{audi_mobility_2019,
	title = {Mobility for megacities: {The} {Audi} {AI}:{ME} {\textbar} {Releases} {\textbar} {Official} {Media} {Site} {NEWSROOM}},
	url = {https://press.audi.co.uk/releases/733},
	  note = {Accessed on 06.07.2025},
	journal = {Audi Newsroom},
	author = {{Audi}},
	month = apr,
	year = {2019},
	file = {Mobility for megacities\: The Audi AI\:ME | Releases | Official Media Site NEWSROOM:C\:\\Users\\giand\\Zotero\\storage\\3B5GTIIG\\733.html:text/html},
}

@article{ammari_music_2019,
	title = {Music, {Search}, and {IoT}: {How} {People} ({Really}) {Use} {Voice} {Assistants}},
	volume = {26},
	issn = {1073-0516},
	shorttitle = {Music, {Search}, and {IoT}},
	url = {https://dl.acm.org/doi/10.1145/3311956},
	doi = {10.1145/3311956},
	abstract = {Voice has become a widespread and commercially viable interaction mechanism with the introduction of voice assistants (VAs), such as Amazon’s Alexa, Apple’s Siri, Google Assistant, and Microsoft’s Cortana. Despite their prevalence, we do not have a detailed understanding of how these technologies are used in domestic spaces. To understand how people use VAs, we conducted interviews with 19 users, and analyzed the log files of 82 Amazon Alexa devices, totaling 193,665 commands, and 88 Google Home Devices, totaling 65,499 commands. In our analysis, we identified music, search, and IoT usage as the command categories most used by VA users. We explored how VAs are used in the home, investigated the role of VAs as scaffolding for Internet of Things device control, and characterized emergent issues of privacy for VA users. We conclude with implications for the design of VAs and for future research studies of VAs.},
	number = {3},
	urldate = {2025-07-06},
	journal = {ACM Trans. Comput.-Hum. Interact.},
	author = {Ammari, Tawfiq and Kaye, Jofish and Tsai, Janice Y. and Bentley, Frank},
	month = apr,
	year = {2019},
	pages = {17:1--17:28},
	file = {Full Text PDF:C\:\\Users\\giand\\Zotero\\storage\\AMZTK3ZB\\Ammari et al. - 2019 - Music, Search, and IoT How People (Really) Use Voice Assistants.pdf:application/pdf},
}

@inproceedings{meng_voice_2020,
	title = {Voice {User}-{Interface} ({VUI}) in {Automobiles}: {Exploring} {Design} {Opportunities} for {Using} {VUI} {Through} the {Observational} {Study}},
	isbn = {978-3-030-50537-0},
	shorttitle = {Voice {User}-{Interface} ({VUI}) in {Automobiles}},
	url = {https://link.springer.com/chapter/10.1007/978-3-030-50537-0_4},
	doi = {10.1007/978-3-030-50537-0_4},
	abstract = {The integration of voice interaction in automobiles has become a trend for current automobile development. This study aims to explore the design opportunities of using voice interaction in automobiles. To achieve this goal, we conducted an observational study to...},
	language = {en},
	urldate = {2025-07-06},
	booktitle = {{HCI} in {Mobility}, {Transport}, and {Automotive} {Systems}. {Driving} {Behavior}, {Urban} and {Smart} {Mobility}},
	publisher = {Springer, Cham},
	author = {Meng, Fangang and Cheng, Peiyao and Wang, Yiran},
	year = {2020},
	note = {ISSN: 1611-3349},
	pages = {40--50},
	file = {Full Text PDF:C\:\\Users\\giand\\Zotero\\storage\\UVI2XR8Z\\Meng et al. - 2020 - Voice User-Interface (VUI) in Automobiles Exploring Design Opportunities for Using VUI Through the.pdf:application/pdf},
}

@inproceedings{kim_why_2019,
	address = {New York, NY, USA},
	series = {{AutomotiveUI} '19},
	title = {"{Why} did this voice agent not understand me?": error recovery strategy for in-vehicle voice user interface},
	isbn = {978-1-4503-6920-6},
	shorttitle = {"{Why} did this voice agent not understand me?},
	url = {https://dl.acm.org/doi/10.1145/3349263.3351513},
	doi = {10.1145/3349263.3351513},
	abstract = {We aimed at investigating the effects of error recovery strategy that could enable the drivers to recover from the non-understanding error when interacting with the in-vehicle voice user interface (VUI). An experiment using a driving simulator was conducted with forty-seven participants who performed driving tasks with the VUI. One of three different error recovery strategies (ask repeat, re-prompt, and you can say) was suggested to recover from the non-understanding errors. A subjective questionnaire and semi-structured interviews were used to collect the participants' workload, perceived reasons for errors, and preference. Results showed participants felt that 'you can say' was more difficult than the 're-prompt' condition. However, preferences of 'ask repeat' and 'you can say' were significantly higher than 're-prompt' because the perceived reason for the non-understanding was 'input error' when the system used the 're-prompt' method. These findings provide insights into the design of the VUI in the context of driving.},
	urldate = {2025-07-06},
	booktitle = {Proceedings of the 11th {International} {Conference} on {Automotive} {User} {Interfaces} and {Interactive} {Vehicular} {Applications}: {Adjunct} {Proceedings}},
	publisher = {Association for Computing Machinery},
	author = {Kim, Jihyun and Jeong, Meuel and Lee, Seul Chan},
	month = sep,
	year = {2019},
	pages = {146--150},
	file = {Full Text PDF:C\:\\Users\\giand\\Zotero\\storage\\YTT2FAM2\\Kim et al. - 2019 - Why did this voice agent not understand me error recovery strategy for in-vehicle voice user int.pdf:application/pdf},
}

@article{liu_comparison_2004,
	title = {Comparison of head-up display ({HUD}) vs. head-down display ({HDD}): driving performance of commercial vehicle operators in {Taiwan}},
	volume = {61},
	issn = {1071-5819},
	shorttitle = {Comparison of head-up display ({HUD}) vs. head-down display ({HDD})},
	url = {https://www.sciencedirect.com/science/article/pii/S1071581904000497},
	doi = {10.1016/j.ijhcs.2004.06.002},
	abstract = {This study investigates the effects of two different display modes—head-up display (HUD) vs. head-down display (HDD) on the driving performance and psychological workload ratings of drivers operating commercial vehicles in Taiwan. Twelve commercial lorry drivers participated in a 2 (high/low driving load road)×2 (head-up/head-down display)×2 (different arrangements of display sequences used) mixed-factor driving simulation experiment. Participants were divided into two groups according to the level of driving load conditions within each driving load group; the participants were further divided into another 2 subgroups based on two arrangements of display sequences used. For each driving load condition, there were two 20-min driving simulation experiments, separated by a display sequence using head-up first and then head-down or vice versa. The subjects were asked to perform four tasks: “commercial goods delivery”, “navigation”, “speed detection and maintenance” and “response to an urgent event”. Results indicated that for the first task, commercial goods delivery, the two display types showed no significant performance difference in terms of average accuracy rate. However, in terms of response time to an urgent event, it was faster with the HUD (with a low driving load—head-up vs. head-down: 1.0073 vs. 1.8684s; with a high driving load—head-up vs. head-down: 1.3235 vs. 2.3274s) and speed control was more consistent (having low speed variations) than with the HDD. In addition, using the HUD caused less mental stress for the drivers than the HDD and was easier for first-time users to become familiar with; with a high driving load, however, the difference between the two displays was not significant.},
	number = {5},
	urldate = {2025-07-06},
	journal = {International Journal of Human-Computer Studies},
	author = {Liu, Yung-Ching and Wen, Ming-Hui},
	month = nov,
	year = {2004},
	pages = {679--697},
	file = {ScienceDirect Snapshot:C\:\\Users\\giand\\Zotero\\storage\\A87UKQV3\\S1071581904000497.html:text/html},
}

@misc{wyman_turbulent_2018,
	title = {Turbulent {Times} {Ahead} for {Global} {Automotive} {Industry} {According} to {New} {Oliver} {Wyman} {Report}},
	url = {https://www.oliverwyman.com/media-center/2018/june/turbulent-times-ahead-for-global-automotive-industry-according-t.html},
	language = {en},
	urldate = {2025-07-07},
	journal = {Oliver Wyman Media-Center},
	author = {Wyman, Oliver},
	month = jun,
	year = {2018},
	file = {Snapshot:C\:\\Users\\giand\\Zotero\\storage\\E5CAL7Q7\\turbulent-times-ahead-for-global-automotive-industry-according-t.html:text/html},
}

@inproceedings{weihrauch_first_1989,
	address = {400 Commonwealth Drive, Warrendale, PA, United States},
	title = {The {First} {Head} {Up} {Display} {Introduced} by {General} {Motors}},
	url = {https://www.sae.org/content/890288/},
	doi = {10.4271/890288},
	urldate = {2025-07-07},
	booktitle = {{SAE} {Technical} {Paper} {Series}},
	publisher = {SAE International},
	author = {Weihrauch, M. and Meloeny, G. G. and Goesch, T. C.},
	month = feb,
	year = {1989},
	note = {ISSN: 0148-7191},
}

@article{skirnewskaja_automotive_2022,
	title = {Automotive {Holographic} {Head}‐{Up} {Displays}},
	volume = {34},
	copyright = {http://creativecommons.org/licenses/by/4.0/},
	issn = {0935-9648, 1521-4095},
	url = {https://advanced.onlinelibrary.wiley.com/doi/10.1002/adma.202110463},
	doi = {10.1002/adma.202110463},
	abstract = {AbstractDriver's access to information about navigation and vehicle data through in‐car displays and personal devices distract the driver from safe vehicle management. The discrepancy between road safety and infotainment must be addressed to develop safely operated modern vehicles. Head‐up displays (HUDs) aim to introduce a seamless uptake of visual information for the driver while securely operating a vehicle. HUDs projected on the windshield provide the driver with visual navigation and vehicle data within the comfort of the driver's personal eye box through a customizable extended display space. Windshield HUDs do not require the driver to shift the gaze away from the road to attain road information. This article presents a review of technological advances and future perspectives in holographic HUDs by analyzing the optoelectronics devices and the user experience of the driver. The review elucidates holographic displays and full augmented reality in 3D with depth perception when projecting the visual information on the road within the driver's gaze. Design factors, functionality, and the integration of personalized machine learning technologies into holographic HUDs are discussed. Application examples of the display technologies regarding road safety and security are presented. An outlook is provided to reflect on display trends and autonomous driving.},
	language = {en},
	number = {19},
	urldate = {2025-07-07},
	journal = {Advanced Materials},
	author = {Skirnewskaja, Jana and Wilkinson, Timothy D.},
	month = may,
	year = {2022},
	note = {Publisher: Wiley},
	file = {Full Text:C\:\\Users\\giand\\Zotero\\storage\\9NMFKGXP\\Skirnewskaja and Wilkinson - 2022 - Automotive Holographic Head‐Up Displays.pdf:application/pdf},
}

@inproceedings{hauslschmid_augmenting_2015,
	address = {New York, NY, USA},
	series = {{IUI} '15},
	title = {Augmenting the {Driver}'s {View} with {Peripheral} {Information} on a {Windshield} {Display}},
	isbn = {978-1-4503-3306-1},
	url = {https://dl.acm.org/doi/10.1145/2678025.2701393},
	doi = {10.1145/2678025.2701393},
	abstract = {Windshield displays (WSDs) are information displays covering the entire windshield. Current WSD test setups place information at different distances, but always within the driver's foveal field of view. We built two WSD test setups, which present information not only at various distances within the driver's visual focus, but also in the peripheral field of view. Then we evaluated the display of information in the periphery on both WSD setups in a user study. While making sure the participants would look at the peripheral information, we measured the display's impact on driving performance. Subjects were also asked about their driving experience with the windshield displays and their preference among the two setups.},
	urldate = {2025-07-07},
	booktitle = {Proceedings of the 20th {International} {Conference} on {Intelligent} {User} {Interfaces}},
	publisher = {Association for Computing Machinery},
	author = {Häuslschmid, Renate and Osterwald, Sven and Lang, Marcus and Butz, Andreas},
	year = {2015},
	pages = {311--321},
	file = {Full Text PDF:C\:\\Users\\giand\\Zotero\\storage\\N3W4U6Y7\\Häuslschmid et al. - 2015 - Augmenting the Driver's View with Peripheral Information on a Windshield Display.pdf:application/pdf},
}

@inproceedings{haeuslschmid_first_2016,
	address = {New York, NY, USA},
	series = {Automotive'{UI} 16},
	title = {First {Steps} towards a {View} {Management} {Concept} for {Large}-sized {Head}-up {Displays} with {Continuous} {Depth}},
	isbn = {978-1-4503-4533-0},
	url = {https://dl.acm.org/doi/10.1145/3003715.3005418},
	doi = {10.1145/3003715.3005418},
	abstract = {Windshield displays (WSDs) are the big siblings of Head-up displays (HUDs). They are assumed to cover the entire windshield and to allow displaying content at continuous depth, eventually. This creates a large and unstructured 3D space for information display -- raising the question what to display where. To address this question, we developed a view management concept for WSDs in left hand drive cars which proposes zones and areas for specific information. As driving is a safety-critical task, we designed the initial concept with the driver's perceptual abilities in mind. Subsequently, we gathered insights into the driver's needs and desires from a formative study. We asked participants where they would place different types of information after inspiring their imagination by a 3D driving scene and WSD information on a Google Cardboard. The improved concept respects both the drivers' needs and desires and their perceptual abilities and can serve as a basis for view management concepts of future WSD.},
	urldate = {2025-07-07},
	booktitle = {Proceedings of the 8th {International} {Conference} on {Automotive} {User} {Interfaces} and {Interactive} {Vehicular} {Applications}},
	publisher = {Association for Computing Machinery},
	author = {Haeuslschmid, Renate and Shou, Yixin and O'Donovan, John and Burnett, Gary and Butz, Andreas},
	year = {2016},
	pages = {1--8},
	file = {Full Text PDF:C\:\\Users\\giand\\Zotero\\storage\\4NCD4R5X\\Haeuslschmid et al. - 2016 - First Steps towards a View Management Concept for Large-sized Head-up Displays with Continuous Depth.pdf:application/pdf},
}

@article{riener_gestural_2012,
	title = {Gestural {Interaction} in {Vehicular} {Applications}},
	volume = {45},
	issn = {1558-0814},
	url = {https://ieeexplore.ieee.org/abstract/document/6165247},
	doi = {10.1109/MC.2012.108},
	abstract = {In-vehicle gestural interfaces are easy to use and increase safety by reducing visual demand on the driver. Prototype capacitive proximity sensing and depth-camera-based systems demonstrate that current technologies can recognize finger and hand gestures of varying complexity.},
	number = {4},
	urldate = {2025-07-07},
	journal = {Computer},
	author = {Riener, Andreas},
	month = apr,
	year = {2012},
	keywords = {Computers, driver-vehicle interfaces, gestural interaction, Gesture recognition, human-computer interaction, implicit sensing, intuitive gestures, participatory design, Safety, Sensors, User interfaces, Vehicles, Visualization},
	pages = {42--47},
	file = {Full Text PDF:C\:\\Users\\giand\\Zotero\\storage\\NTQUYFW9\\Riener - 2012 - Gestural Interaction in Vehicular Applications.pdf:application/pdf},
}

@article{gabbard_behind_2014,
	title = {Behind the {Glass}: {Driver} {Challenges} and {Opportunities} for {AR} {Automotive} {Applications}},
	volume = {102},
	copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
	issn = {0018-9219, 1558-2256},
	shorttitle = {Behind the {Glass}},
	url = {http://ieeexplore.ieee.org/document/6704805/},
	doi = {10.1109/jproc.2013.2294642},
	number = {2},
	urldate = {2025-07-07},
	journal = {Proceedings of the IEEE},
	author = {Gabbard, Joseph L. and Fitch, Gregory M. and Kim, Hyungil},
	month = feb,
	year = {2014},
	note = {Publisher: Institute of Electrical and Electronics Engineers (IEEE)},
	pages = {124--136},
}

@inproceedings{berger_designing_2021,
	title = {Designing for a {Convenient} {In}-{Car} {Passenger} {Experience}: {A} {Repertory} {Grid} {Study}},
	isbn = {978-3-030-85616-8},
	shorttitle = {Designing for a {Convenient} {In}-{Car} {Passenger} {Experience}},
	url = {https://link.springer.com/chapter/10.1007/978-3-030-85616-8_9},
	doi = {10.1007/978-3-030-85616-8_9},
	abstract = {The driving experience has become one of the central decision factors when buying a car. In current manually driven cars, this experience is to a large extent influenced by driver-based infotainment functionalities. With the advent of rear-seat infotainment systems,...},
	language = {en},
	urldate = {2025-07-09},
	booktitle = {Human-{Computer} {Interaction} – {INTERACT} 2021},
	publisher = {Springer, Cham},
	author = {Berger, Melanie and Pfleging, Bastian and Bernhaupt, Regina},
	year = {2021},
	note = {ISSN: 1611-3349},
	pages = {117--139},
	file = {Full Text PDF:C\:\\Users\\giand\\Zotero\\storage\\G2IYJMGW\\Berger et al. - 2021 - Designing for a Convenient In-Car Passenger Experience A Repertory Grid Study.pdf:application/pdf},
}

@inproceedings{wintersberger_traffic_2017,
	address = {New York, NY, USA},
	series = {{CHItaly} '17},
	title = {Traffic {Augmentation} as a {Means} to {Increase} {Trust} in {Automated} {Driving} {Systems}},
	isbn = {978-1-4503-5237-6},
	url = {https://dl.acm.org/doi/10.1145/3125571.3125600},
	doi = {10.1145/3125571.3125600},
	abstract = {Many human factor issues regarding automated driving systems are still unresolved. For instance, it is not fully clear if, and to what extent, drivers will accept and trust this novel technology. Trust in technology is of utmost importance to avoid both disuse and misuse. Possibilities for increasing user trust in automated driving systems include proper feedback aiming to build a shared mental model so that system intentions are visible to the driver. A potential approach could be to augment traffic and other relevant objects in the environment. Technical advancements in display technology would allow the use of windshield displays in the near future. To investigate the effect of augmented reality aids (presented as augmentations of traffic objects) in potentially ambiguous situations, we conducted a user study (n=26) and assessed qualitative (trust scale TS, technology acceptance model TAM) and quantitative (HRV) factors. Initial results indicate that augmenting sensor data in the driver's line of sight can lead to increased trust and acceptance.},
	urldate = {2025-07-09},
	booktitle = {Proceedings of the 12th {Biannual} {Conference} on {Italian} {SIGCHI} {Chapter}},
	publisher = {Association for Computing Machinery},
	author = {Wintersberger, Philipp and von Sawitzky, Tamara and Frison, Anna-Katharina and Riener, Andreas},
	month = sep,
	year = {2017},
	pages = {1--7},
	file = {Full Text PDF:C\:\\Users\\giand\\Zotero\\storage\\667PLJ7W\\Wintersberger et al. - 2017 - Traffic Augmentation as a Means to Increase Trust in Automated Driving Systems.pdf:application/pdf},
}

@inproceedings{kun_arv_2017,
	address = {New York, NY, USA},
	series = {{AutomotiveUI} '17},
	title = {{ARV} 2017: {Workshop} on {Augmented} {Reality} for {Intelligent} {Vehicles}},
	isbn = {978-1-4503-5151-5},
	shorttitle = {{ARV} 2017},
	url = {https://dl.acm.org/doi/10.1145/3131726.3131735},
	doi = {10.1145/3131726.3131735},
	abstract = {It is forecast that augmented reality (AR automotive applications will increase road safety, bring intuitive activities to driving, and finally enhance driving experience. AR technology may also help on the transition towards automated driving. However, many technological challenges need to be addressed before AR applications will hit the mainstream market. In this workshop, we will discuss the potential and constraints as well as impact, role, and adequacy of AR in driving applications. The overarching goal is to define a research agenda for the general use of AR in intelligent vehicles within the next 3 to5 years.},
	urldate = {2025-07-09},
	booktitle = {Proceedings of the 9th {International} {Conference} on {Automotive} {User} {Interfaces} and {Interactive} {Vehicular} {Applications} {Adjunct}},
	publisher = {Association for Computing Machinery},
	author = {Kun, Andrew L. and Tscheligi, Manfred and Riener, Andreas and van der Meulen, Hidde},
	month = sep,
	year = {2017},
	pages = {47--51},
	file = {Full Text PDF:C\:\\Users\\giand\\Zotero\\storage\\PZI4LS55\\Kun et al. - 2017 - ARV 2017 Workshop on Augmented Reality for Intelligent Vehicles.pdf:application/pdf},
}

@article{riener_automotive_2016,
	title = {Automotive {User} {Interfaces} in the {Age} of {Automation} ({Dagstuhl} {Seminar} 16262)},
	volume = {6},
	issn = {2192-5283},
	url = {https://drops.dagstuhl.de/entities/document/10.4230/DagRep.6.6.111},
	doi = {10.4230/DagRep.6.6.111},
	number = {6},
	urldate = {2025-07-09},
	journal = {Dagstuhl Reports},
	author = {Riener, Andreas and Boll, Susanne and Kun, Andrew L.},
	editor = {Riener, Andreas and Boll, Susanne and Kun, Andrew L.},
	year = {2016},
	note = {Place: Dagstuhl, Germany
Publisher: Schloss Dagstuhl – Leibniz-Zentrum für Informatik},
	keywords = {Automotive UIs; Driver-vehicle interaction services; UX in driving; Customization of vehicles/UIs; (Over)trust; Ethical issues},
	pages = {111--157},
	file = {PDF:C\:\\Users\\giand\\Zotero\\storage\\38KS5N5E\\Riener et al. - 2016 - Automotive User Interfaces in the Age of Automation (Dagstuhl Seminar 16262).pdf:application/pdf},
}

@inproceedings{kim_exploring_2016,
	address = {Seoul, KOR},
	series = {{HCIK} '16},
	title = {Exploring the {User} {Experience} for {Autonomous} {Vehicle} and the {Role} of {Windshield} {Display}: {Based} on {Framework} {Approach}},
	isbn = {978-89-6848-791-0},
	shorttitle = {Exploring the {User} {Experience} for {Autonomous} {Vehicle} and the {Role} of {Windshield} {Display}},
	url = {https://dl.acm.org/doi/10.17210/hcik.2016.01.321},
	doi = {10.17210/hcik.2016.01.321},
	abstract = {Autonomous vehicle will change the user behavior completely, so there are needs for exploring the user's future experience in the autonomous environment. Windshield display was neglected in normal driving condition for out of safety concerns. However, as autonomous vehicles comes to reality, windshield get a chance to be utilized as an in-vehicle display. We conducted Focus Group Interview (FGI) to provide deep understanding of what user is willing to experience through the windshield. We used the framework approach as analysis tool for the qualitative data from the FGI. This paper describes the insights which could be used for the basic study of designing the windshield in future vehicle.},
	urldate = {2025-07-09},
	booktitle = {Proceedings of {HCI} {Korea}},
	publisher = {Hanbit Media, Inc.},
	author = {Kim, Meen Jong and Yoon, Sol Hee and Ji, Yong Gu},
	month = jan,
	year = {2016},
	pages = {321--326},
	file = {Full Text PDF:C\:\\Users\\giand\\Zotero\\storage\\AKIX3HTF\\Kim et al. - 2016 - Exploring the User Experience for Autonomous Vehicle and the Role of Windshield Display Based on Fr.pdf:application/pdf},
}

@article{lindemann_catch_2018,
	title = {Catch {My} {Drift}: {Elevating} {Situation} {Awareness} for {Highly} {Automated} {Driving} with an {Explanatory} {Windshield} {Display} {User} {Interface}},
	volume = {2},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2414-4088},
	shorttitle = {Catch {My} {Drift}},
	url = {https://www.mdpi.com/2414-4088/2/4/71},
	doi = {10.3390/mti2040071},
	abstract = {Broad access to automated cars (ACs) that can reliably and unconditionally drive in all environments is still some years away. Urban areas pose a particular challenge to ACs, since even perfectly reliable systems may be forced to execute sudden reactive driving maneuvers in hard-to-predict hazardous situations. This may negatively surprise the driver, possibly causing discomfort, anxiety or loss of trust, which might be a risk for the acceptance of the technology in general. To counter this, we suggest an explanatory windshield display interface with augmented reality (AR) elements to support driver situation awareness (SA). It provides the driver with information about the car’s perceptive capabilities and driving decisions. We created a prototype in a human-centered approach and implemented the interface in a mixed-reality driving simulation. We conducted a user study to assess its influence on driver SA. We collected objective SA scores and self-ratings, both of which yielded a significant improvement with our interface in good (medium effect) and in bad (large effect) visibility conditions. We conclude that explanatory AR interfaces could be a viable measure against unwarranted driver discomfort and loss of trust in critical urban situations by elevating SA.},
	language = {en},
	number = {4},
	urldate = {2025-07-09},
	journal = {Multimodal Technologies and Interaction},
	author = {Lindemann, Patrick and Lee, Tae-Young and Rigoll, Gerhard},
	month = dec,
	year = {2018},
	note = {Number: 4
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {augmented reality, autonomous driving, head-up display, human-centered design, mixed reality, situation awareness, technology acceptance, user interface, windshield display},
	pages = {71},
	file = {Full Text PDF:C\:\\Users\\giand\\Zotero\\storage\\Q9JZTXX2\\Lindemann et al. - 2018 - Catch My Drift Elevating Situation Awareness for Highly Automated Driving with an Explanatory Winds.pdf:application/pdf},
}

@article{dandekar_how_2022,
	title = {How to {Display} {Vehicle} {Information} to {Users} of {Automated} {Vehicles} {When} {Conducting} {Non}-{Driving}-{Related} {Activities}},
	volume = {6},
	url = {https://dl.acm.org/doi/10.1145/3546741},
	doi = {10.1145/3546741},
	abstract = {Automated vehicles (AVs) are expected to enable users to engage in non-driving-related activities (NDRAs). However, users do not easily trust an automated vehicle which poses new challenges for automotive human-machine interfaces (HMIs). Over-presenting vehicle information can distract users from NDRAs, and under-presentation can impact trust and user experience (UX) negatively. To investigate how to best present vehicle information to foster users' trust and UX while performing NDRAs, we designed two in-vehicle HMI concepts: 1) A colored and animated light bar display around the windshield and 2) a windshield display interface presenting pictograms and numbers. Results from a simulator study (\$N=18\$) indicate that both concepts contribute to a high trust level and UX while not affecting the NDRA performance compared to the baseline of not showing vehicle information. In addition, the light bar provides better UX than the windshield display and is also preferred by users. With our findings, we contribute to the effective design of presenting vehicle information in automated vehicles.},
	number = {MHCI},
	urldate = {2025-07-09},
	journal = {Proc. ACM Hum.-Comput. Interact.},
	author = {Dandekar, Aditya and Mathis, Lesley-Ann and Berger, Melanie and Pfleging, Bastian},
	month = sep,
	year = {2022},
	pages = {206:1--206:22},
	file = {Full Text PDF:C\:\\Users\\giand\\Zotero\\storage\\MYEY7VMA\\Dandekar et al. - 2022 - How to Display Vehicle Information to Users of Automated Vehicles When Conducting Non-Driving-Relate.pdf:application/pdf},
}

@article{matsumura_active_2018,
	title = {On {Active} {Passengering}: {Supporting} {In}-{Car} {Experiences}},
	volume = {1},
	shorttitle = {On {Active} {Passengering}},
	url = {https://dl.acm.org/doi/10.1145/3161176},
	doi = {10.1145/3161176},
	abstract = {We describe the development of an interactive car window system designed to support passengers in engaging with the external environment during a journey. Through advances in embedded digital technologies, cars increasingly have a potential to become interactive spaces, in which passengers will find it possible to interact with the external environment through in-car interfaces. However the utility and benefit of such interactive systems for passengers has not been well studied. There is a need therefore, to study the design and use of these technologies, as they are emerging. We thus investigated how digital technology might support passengers' interactions with the external environment. Through a focus group (n=6) and interviews (n=5) we investigated passengers' attitudes towards, and practices during, ordinary car journeys. From this scoping study we formulated five design considerations for designing/implementing a prototype interactive car-window system. This system was then evaluated through an in-lab user study (n=8). Qualitative thematic analysis of interviews during the user study suggested a variety of orientations towards ‘passengering’, the act of being a passenger, on a journey. Herein we critically examine the role of our interactive technology in supporting desired experiences of ‘active passengering’.},
	number = {4},
	urldate = {2025-07-09},
	journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
	author = {Matsumura, Kohei and Kirk, David S.},
	month = jan,
	year = {2018},
	pages = {154:1--154:23},
	file = {Full Text PDF:C\:\\Users\\giand\\Zotero\\storage\\BK3NX2RQ\\Matsumura and Kirk - 2018 - On Active Passengering Supporting In-Car Experiences.pdf:application/pdf},
}

@misc{pagura_window_2011,
	title = {Window {To} {The} {World} - {Kansei} {Design} {Toyota} - {CIID} (2011)},
	url = {https://www.martinapagura.com/work/window-to-the-world},
	language = {English},
	urldate = {2025-07-09},
	journal = {Window To The World},
	author = {Pagura, Matrina},
	year = {2011},
	file = {Snapshot:C\:\\Users\\giand\\Zotero\\storage\\YF9P8DX8\\window-to-the-world.html:text/html},
}
@inproceedings{togwell_-car_2022,
	address = {New York, NY, USA},
	series = {{CHI} {EA} '22},
	title = {In-{cAR} {Gaming}: {Exploring} the use of {AR} headsets to {Leverage} {Passenger} {Travel} {Environments} for {Mixed} {Reality} {Gameplay}},
	isbn = {978-1-4503-9156-6},
	shorttitle = {In-{cAR} {Gaming}},
	url = {https://dl.acm.org/doi/10.1145/3491101.3519741},
	doi = {10.1145/3491101.3519741},
	abstract = {Autonomous cars offer passengers a rich platform for Augmented Reality entertainment, with complex sensing that can drive passenger experiences by tracking, appropriating and altering elements of reality. This paper forms an early exploration of in-car AR games, starting with how existing game genres might work within an AR vehicle context, appropriating elements of reality (e.g. other cars) into gameplay, and altering the appearance of reality in relation to game events (e.g. augmented cracks in car windows). We discuss results from focus groups exploring an initial AR game prototype, and an informal in-car evaluation of a follow-up prototype inspired by the focus groups. Broadly, we found that participants enjoyed using AR gaming in-car, noted the immersive impact of appropriating real-world elements into gameplay, and felt that it improved their experience of the journey. We reflect on the ways in which future AR passenger experiences might take advantage of the available sensing and environment to create engaging reality-based gameplay.},
	urldate = {2025-07-09},
	booktitle = {Extended {Abstracts} of the 2022 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Togwell, Henry and McGill, Mark and Wilson, Graham and Medeiros, Daniel and Brewster, Stephen Anthony},
	month = apr,
	year = {2022},
	pages = {1--7},
	file = {Full Text PDF:C\:\\Users\\giand\\Zotero\\storage\\ANRXBU6P\\Togwell et al. - 2022 - In-cAR Gaming Exploring the use of AR headsets to Leverage Passenger Travel Environments for Mixed.pdf:application/pdf},
}

@inproceedings{wu_project_2021,
	address = {New York, NY, USA},
	series = {{CHI} '21},
	title = {Project {Tasca}: {Enabling} {Touch} and {Contextual} {Interactions} with a {Pocket}-based {Textile} {Sensor}},
	isbn = {978-1-4503-8096-6},
	shorttitle = {Project {Tasca}},
	url = {https://dl.acm.org/doi/10.1145/3411764.3445712},
	doi = {10.1145/3411764.3445712},
	abstract = {We present Project Tasca, a pocket-based textile sensor that detects user input and recognizes everyday objects that a user carries in the pockets of a pair of pants (e.g., keys, coins, electronic devices, or plastic items). By creating a new fabric-based sensor capable of detecting in-pocket touch and pressure, and recognizing metallic, non-metallic, and tagged objects inside the pocket, we enable a rich variety of subtle, eyes-free, and always-available input, as well as context-driven interactions in wearable scenarios. We developed our prototype by integrating four distinct types of sensing methods, namely: inductive sensing, capacitive sensing, resistive sensing, and NFC in a multi-layer fabric structure into the form factor of a jeans pocket. Through a ten-participant study, we evaluated the performance of our prototype across 11 common objects including hands, 8 force gestures, and 30 NFC tag placements. We yielded a 92.3\% personal cross-validation accuracy for object recognition, 96.4\% accuracy for gesture recognition, and a 100\% accuracy for detecting NFC tags at close distance . We conclude by demonstrating the interactions enabled by our pocket-based sensor in several applications.},
	urldate = {2025-07-09},
	booktitle = {Proceedings of the 2021 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Wu, Te-Yen and Xu, Zheer and Yang, Xing-Dong and Hodges, Steve and Seyed, Teddy},
	year = {2021},
	pages = {1--13},
	file = {Full Text PDF:C\:\\Users\\giand\\Zotero\\storage\\FFTRUKYF\\Wu et al. - 2021 - Project Tasca Enabling Touch and Contextual Interactions with a Pocket-based Textile Sensor.pdf:application/pdf},
}

@inproceedings{wu_zebrasense_2020,
	address = {New York, NY, USA},
	series = {{UIST} '20},
	title = {{ZebraSense}: {A} {Double}-sided {Textile} {Touch} {Sensor} for {Smart} {Clothing}},
	isbn = {978-1-4503-7514-6},
	shorttitle = {{ZebraSense}},
	url = {https://dl.acm.org/doi/10.1145/3379337.3415886},
	doi = {10.1145/3379337.3415886},
	abstract = {ZebraSense is a novel dual-sided woven touch sensor that can recognize and differentiate interactions on the top and bottom surfaces of the sensor. ZebraSense is based on an industrial multi-layer textile weaving technique, yet it enables a novel capacitive sensing paradigm, where each sensing element contributes to touch detection on both surfaces of the sensor simultaneously. Unlike the common "sensor sandwich" approach used in previous work, ZebraSense inherently minimizes the number of sensing elements, which drastically simplifies both sensor construction and its integration into soft goods, while preserving maximum sensor resolution. The experimental evaluation confirmed the validity of our approach and demonstrated that ZebraSense is a reliable, efficient, and accurate solution for detecting user gestures in various dual-sided interaction scenarios, allowing for new use cases in smart apparel, home decoration, toys, and other textile objects.},
	urldate = {2025-07-09},
	booktitle = {Proceedings of the 33rd {Annual} {ACM} {Symposium} on {User} {Interface} {Software} and {Technology}},
	publisher = {Association for Computing Machinery},
	author = {Wu, Tony and Fukuhara, Shiho and Gillian, Nicholas and Sundara-Rajan, Kishore and Poupyrev, Ivan},
	year = {2020},
	pages = {662--674},
	file = {Full Text PDF:C\:\\Users\\giand\\Zotero\\storage\\7ECDC5X7\\Wu et al. - 2020 - ZebraSense A Double-sided Textile Touch Sensor for Smart Clothing.pdf:application/pdf},
}

@inproceedings{schneegass_gesturesleeve_2016,
	address = {New York, NY, USA},
	series = {{ISWC} '16},
	title = {{GestureSleeve}: using touch sensitive fabrics for gestural input on the forearm for controlling smartwatches},
	isbn = {978-1-4503-4460-9},
	shorttitle = {{GestureSleeve}},
	url = {https://dl.acm.org/doi/10.1145/2971763.2971797},
	doi = {10.1145/2971763.2971797},
	abstract = {Smartwatches provide quick and easy access to information. Due to their wearable nature, users can perceive the information while being stationary or on the go. The main drawback of smartwatches, however, is the limited input possibility. They use similar input methods as smartphones but thereby suffer from a smaller form factor. To extend the input space of smartwatches, we present GestureSleeve, a sleeve made out of touch enabled textile. It is capable of detecting different gestures such as stroke based gestures or taps. With these gestures, the user can control various smartwatch applications. Exploring the performance of the GestureSleeve approach, we conducted a user study with a running application as use case. In this study, we show that input using the GestureSleeve outperforms touch input on the smartwatch. In the future the GestureSleeve can be integrated into regular clothing and be used for controlling various smart devices.},
	urldate = {2025-07-09},
	booktitle = {Proceedings of the 2016 {ACM} {International} {Symposium} on {Wearable} {Computers}},
	publisher = {Association for Computing Machinery},
	author = {Schneegass, Stefan and Voit, Alexandra},
	month = sep,
	year = {2016},
	pages = {108--115},
	file = {Full Text PDF:C\:\\Users\\giand\\Zotero\\storage\\VQ5SXACZ\\Schneegass and Voit - 2016 - GestureSleeve using touch sensitive fabrics for gestural input on the forearm for controlling smart.pdf:application/pdf},
}

@inproceedings{poupyrev_project_2016,
	address = {New York, NY, USA},
	series = {{CHI} '16},
	title = {Project {Jacquard}: {Interactive} {Digital} {Textiles} at {Scale}},
	isbn = {978-1-4503-3362-7},
	shorttitle = {Project {Jacquard}},
	url = {https://dl.acm.org/doi/10.1145/2858036.2858176},
	doi = {10.1145/2858036.2858176},
	abstract = {Project Jacquard presents manufacturing technologies that enable deploying invisible ubiquitous interactivity at scale. We propose novel interactive textile materials that can be manufactured inexpensively using existing textile weaving technology and equipment.The development of touch-sensitive textiles begins with the design and engineering of a new highly conductive yarn. The yarns and textiles can be produced by standard textile manufacturing processes and can be dyed to any color, made with a number of materials, and designed to a variety of thicknesses and textures to be consistent with garment designers' needs.We describe the development of yarn, textiles, garments, and user interactivity; we present the opportunities and challenges of creating a manufacturable interactive textile for wearable computing.},
	urldate = {2025-07-09},
	booktitle = {Proceedings of the 2016 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Poupyrev, Ivan and Gong, Nan-Wei and Fukuhara, Shiho and Karagozler, Mustafa Emre and Schwesig, Carsten and Robinson, Karen E.},
	year = {2016},
	pages = {4216--4227},
	file = {Full Text PDF:C\:\\Users\\giand\\Zotero\\storage\\8FDC5FUH\\Poupyrev et al. - 2016 - Project Jacquard Interactive Digital Textiles at Scale.pdf:application/pdf},
}

@inproceedings{parzer_resi_2018,
	address = {New York, NY, USA},
	series = {{UIST} '18},
	title = {{RESi}: {A} {Highly} {Flexible}, {Pressure}-{Sensitive}, {Imperceptible} {Textile} {Interface} {Based} on {Resistive} {Yarns}},
	isbn = {978-1-4503-5948-1},
	shorttitle = {{RESi}},
	url = {https://dl.acm.org/doi/10.1145/3242587.3242664},
	doi = {10.1145/3242587.3242664},
	abstract = {We present RESi (Resistive tExtile Sensor Interfaces), a novel sensing approach enabling a new kind of yarn-based, resistive pressure sensing. The core of RESi builds on a newly designed yarn, which features conductive and resistive properties. We run a technical study to characterize the behaviour of the yarn and to determine the sensing principle. We demonstrate how the yarn can be used as a pressure sensor and discuss how specific issues, such as connecting the soft textile sensor with the rigid electronics can be solved. In addition, we present a platform-independent API that allows rapid prototyping. To show its versatility, we present applications developed with different textile manufacturing techniques, including hand sewing, machine sewing, and weaving. RESi is a novel technology, enabling textile pressure sensing to augment everyday objects with interactive capabilities.},
	urldate = {2025-07-09},
	booktitle = {Proceedings of the 31st {Annual} {ACM} {Symposium} on {User} {Interface} {Software} and {Technology}},
	publisher = {Association for Computing Machinery},
	author = {Parzer, Patrick and Perteneder, Florian and Probst, Kathrin and Rendl, Christian and Leong, Joanne and Schuetz, Sarah and Vogl, Anita and Schwoediauer, Reinhard and Kaltenbrunner, Martin and Bauer, Siegfried and Haller, Michael},
	year = {2018},
	pages = {745--756},
	file = {Full Text PDF:C\:\\Users\\giand\\Zotero\\storage\\JHG83963\\Parzer et al. - 2018 - RESi A Highly Flexible, Pressure-Sensitive, Imperceptible Textile Interface Based on Resistive Yarn.pdf:application/pdf},
}

@inproceedings{holleis_evaluating_2008,
	address = {New York, NY, USA},
	series = {{MobileHCI} '08},
	title = {Evaluating capacitive touch input on clothes},
	isbn = {978-1-59593-952-4},
	url = {https://dl.acm.org/doi/10.1145/1409240.1409250},
	doi = {10.1145/1409240.1409250},
	abstract = {Wearable computing and smart clothing have attracted a lot of attention in the last years. For a variety of applications, it can be seen as potential future direction of mobile user interfaces. In this paper, we concentrate on usability and applicability issues concerned with capacitive touch input on clothing. To be able to perform user studies, we built a generic platform for attaching, e.g., capacitive sensors of different types. On top of that, several prototypes of wearable accessories and clothing and implemented various application scenarios. We report on two studies we undertook with these implementations with a user group randomly sampled at a shopping mall. We provide a significant set of guidelines and lessons learned that emerged from our experiences and those studies. Thus, developers of similar projects have to put major efforts into minimizing the delay between button activation and feedback and to make location and identification of controls and their function as simple and quick as possible. Issues that have to be treated in all designs include the requirement of one-handed interaction and that, even for minimal functionality, to find a general solution with regard to layout and button-to-function mapping is hardly possible. Additionally, in order to generate a satisfactory user experience good usability must be combined with aesthetical factors.},
	urldate = {2025-07-09},
	booktitle = {Proceedings of the 10th international conference on {Human} computer interaction with mobile devices and services},
	publisher = {Association for Computing Machinery},
	author = {Holleis, Paul and Schmidt, Albrecht and Paasovaara, Susanna and Puikkonen, Arto and Häkkilä, Jonna},
	month = sep,
	year = {2008},
	pages = {81--90},
	file = {Full Text PDF:C\:\\Users\\giand\\Zotero\\storage\\VWZVNY7E\\Holleis et al. - 2008 - Evaluating capacitive touch input on clothes.pdf:application/pdf},
}

@inproceedings{goveia_da_rocha_crafting_2020,
	address = {New York, NY, USA},
	series = {{DIS} '20},
	title = {Crafting {Research} {Products} through {Digital} {Machine} {Embroidery}},
	isbn = {978-1-4503-6974-9},
	url = {https://dl.acm.org/doi/10.1145/3357236.3395443},
	doi = {10.1145/3357236.3395443},
	abstract = {Wearables combine practical and conceptual challenges related to electronics, clothing and interaction design. Research through design in this area is commonly done iteratively through prototypes of increasing levels of fidelity, often relying on manual fabrication. However, manual fabrication presents challenges when comparing prototypes due to their varying levels of realization and the inaccuracy of reproductions. We discuss how using digital machine embroidery, combined with chemical embroidery technique, supports fabricating consistent high-fidelity prototypes for soft wearables in the form of research products. Our approach involves creating the textile substrate together with integrating and embedding electronic components through a unified process whilst keeping high control over alterations between prototypes. We illustrate this approach through the design process of the Smart Sock, a sensorized sock for rehabilitation. We detail the challenges behind our process and reflect on the opportunities emerging from using digital machine and chemical embroidery techniques combined to craft research products.},
	urldate = {2025-07-09},
	booktitle = {Proceedings of the 2020 {ACM} {Designing} {Interactive} {Systems} {Conference}},
	publisher = {Association for Computing Machinery},
	author = {Goveia da Rocha, Bruna and Tomico, Oscar and Markopoulos, Panos and Tetteroo, Daniel},
	month = jul,
	year = {2020},
	pages = {341--350},
	file = {Full Text PDF:C\:\\Users\\giand\\Zotero\\storage\\GRYGYDWV\\Goveia da Rocha et al. - 2020 - Crafting Research Products through Digital Machine Embroidery.pdf:application/pdf},
}

@inproceedings{hamdan_sketchstitch_2018,
	address = {New York, NY, USA},
	series = {{CHI} '18},
	title = {Sketch\&{Stitch}: {Interactive} {Embroidery} for {E}-textiles},
	isbn = {978-1-4503-5620-6},
	shorttitle = {Sketch\&{Stitch}},
	url = {https://dl.acm.org/doi/10.1145/3173574.3173656},
	doi = {10.1145/3173574.3173656},
	abstract = {E-Textiles are fabrics that integrate electronic circuits and components. Makers use them to create interactive clothing, furniture, and toys. However, this requires significant manual labor and skills, and using technology-centric design tools. We introduce Sketch\&amp;Stitch, an interactive embroidery system to create e-textiles using a traditional crafting approach: Users draw their art and circuit directly on fabric using colored pens. The system takes a picture of the sketch, converts it to embroidery patterns, and sends them to an embroidery machine. Alternating between sketching and stitching, users build and test their design incrementally. Sketch\&amp;Stitch features Circuitry Stickers representing circuit boards, components, and custom stitch patterns for wire crossings to insulate, and various textile touch sensors such as pushbuttons, sliders, and 2D touchpads. Circuitry Stickers serve as placeholders during design. Using computer vision, they are recognized and replaced later in the appropriate embroidery phases. We close with technical considerations and application examples.},
	urldate = {2025-07-09},
	booktitle = {Proceedings of the 2018 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Hamdan, Nur Al-huda and Voelker, Simon and Borchers, Jan},
	month = apr,
	year = {2018},
	pages = {1--13},
	file = {Full Text PDF:C\:\\Users\\giand\\Zotero\\storage\\3NAD8368\\Hamdan et al. - 2018 - Sketch&Stitch Interactive Embroidery for E-textiles.pdf:application/pdf},
}

@article{castano_smart_2014,
	title = {Smart fabric sensors and e-textile technologies: a review},
	volume = {23},
	issn = {0964-1726},
	shorttitle = {Smart fabric sensors and e-textile technologies},
	url = {https://dx.doi.org/10.1088/0964-1726/23/5/053001},
	doi = {10.1088/0964-1726/23/5/053001},
	abstract = {This paper provides a review of recent developments in the rapidly changing and advancing field of smart fabric sensor and electronic textile technologies. It summarizes the basic principles and approaches employed when building fabric sensors as well as the most commonly used materials and techniques used in electronic textiles. This paper shows that sensing functionality can be created by intrinsic and extrinsic modifications to textile substrates depending on the level of integration into the fabric platform. The current work demonstrates that fabric sensors can be tailored to measure force, pressure, chemicals, humidity and temperature variations. Materials, connectors, fabric circuits, interconnects, encapsulation and fabrication methods associated with fabric technologies prove to be customizable and versatile but less robust than their conventional electronics counterparts. The findings of this survey suggest that a complete smart fabric system is possible through the integration of the different types of textile based functional elements. This work intends to be a starting point for standardization of smart fabric sensing techniques and e-textile fabrication methods.},
	language = {en},
	number = {5},
	urldate = {2025-07-09},
	journal = {Smart Materials and Structures},
	author = {Castano, Lina M and Flatau, Alison B},
	month = apr,
	year = {2014},
	note = {Publisher: IOP Publishing},
	pages = {053001},
}

@inproceedings{posch_integrating_2018,
	address = {New York, NY, USA},
	series = {{TEI} '18},
	title = {Integrating {Textile} {Materials} with {Electronic} {Making}: {Creating} {New} {Tools} and {Practices}},
	isbn = {978-1-4503-5568-1},
	shorttitle = {Integrating {Textile} {Materials} with {Electronic} {Making}},
	url = {https://dl.acm.org/doi/10.1145/3173225.3173255},
	doi = {10.1145/3173225.3173255},
	abstract = {We introduce and discuss the design and use of new tools for electronic textile making. Electronic textiles, or eTextiles, are increasingly produced and used in experimental interfaces, wearables, interior design, as well as in the education and maker cultures. However, the field relies on tools specific to either the textile or the electronic domain, neglecting the distinct requirements, and potentials, of their intersection. To address this gap, we explored the design of new tools, targeted at specific needs and use cases of electronic textile making and the materials used. Three resulting prototypes have been evaluated through use in both our own practice and among a group of experts in the field. Our findings show the importance of specialized tools for routines essential to the field eTextiles, their role for the emergence of new practices, as well as for the understanding of the discipline.},
	urldate = {2025-07-09},
	booktitle = {Proceedings of the {Twelfth} {International} {Conference} on {Tangible}, {Embedded}, and {Embodied} {Interaction}},
	publisher = {Association for Computing Machinery},
	author = {Posch, Irene and Fitzpatrick, Geraldine},
	year = {2018},
	pages = {158--165},
	file = {Full Text PDF:C\:\\Users\\giand\\Zotero\\storage\\3DPTSNFE\\Posch and Fitzpatrick - 2018 - Integrating Textile Materials with Electronic Making Creating New Tools and Practices.pdf:application/pdf},
}

@article{essick_psychophysical_1999,
	title = {Psychophysical assessment of the affective components of non-painful touch},
	volume = {10},
	issn = {0959-4965},
	url = {https://journals.lww.com/neuroreport/abstract/1999/07130/psychophysical_assessment_of_the_affective.17.aspx},
	abstract = {A novel psychophysical procedure for the evaluation of the affective components of touch was developed. A fabric material was stroked across the test site at a controlled direction and velocity, after which the subject provided a numerical estimate of pleasantness. Significant differences were detected for the sites tested (FACE vs ARM), the fabric materials used (VELVET, COTTON and PLASTIC MESH), and the velocity of motion (0.5, 5 and 50 cm/s). Attesting to their validity, estimates of pleasantness correlated negatively with estimates of unpleasantness obtained for the same stimuli. Moreover, subjects were reasonably consistent in their ratings upon stimulus replication. These findings demonstrate that the hedonic qualities of touch can be psychophysically evaluated, and that valid and reliable estimates are obtained.},
	language = {en-US},
	number = {10},
	urldate = {2025-07-09},
	journal = {NeuroReport},
	author = {Essick, Greg K. and James, Anuj and McGlone, Francis P.},
	month = jul,
	year = {1999},
	pages = {2083},
	file = {Snapshot:C\:\\Users\\giand\\Zotero\\storage\\399XSSFR\\psychophysical_assessment_of_the_affective.17.html:text/html},
}

@inproceedings{komor_is_2009,
	title = {Is {It} {Gropable}? – {Assessing} the {Impact} of {Mobility} on {Textile} {Interfaces}},
	shorttitle = {Is {It} {Gropable}?},
	url = {https://ieeexplore.ieee.org/abstract/document/5254651},
	doi = {10.1109/ISWC.2009.21},
	abstract = {In a mobile environment, the visual attention a person can devote to a computer is often limited. In such situations, a manual interface should be ldquogropable,rdquo that is, the user should be able to access and use the interface with little to no visual attention. We compare stationary and mobile input on two embroidered textile interfaces; a single touch three button interface and a multitouch four button interface that is activated by pressing two buttons at the same time. Sixteen participants completed 480 trials while walking a path and sitting. While multitouch increases the expressiveness of gestures that can be performed, our user study only shows a slight, not statistically significant, increase in accuracy and an understandable decrease in speed for simple selection tasks.},
	urldate = {2025-07-09},
	booktitle = {2009 {International} {Symposium} on {Wearable} {Computers}},
	author = {Komor, Nicholas and Gilliland, Scott and Clawson, James and Bhardwaj, Manish and Garg, Mayank and Zeagler, Clint and Starner, Thad},
	month = sep,
	year = {2009},
	note = {ISSN: 2376-8541},
	keywords = {Textiles},
	pages = {71--74},
	file = {Full Text PDF:C\:\\Users\\giand\\Zotero\\storage\\5U52UGLE\\Komor et al. - 2009 - Is It Gropable – Assessing the Impact of Mobility on Textile Interfaces.pdf:application/pdf},
}

@inproceedings{post_smart_1997,
	title = {Smart fabric, or "wearable clothing"},
	url = {https://ieeexplore.ieee.org/abstract/document/629937},
	doi = {10.1109/ISWC.1997.629937},
	abstract = {Wearable computers can now merge seamlessly into ordinary clothing. Using various conductive textiles, data and power distribution as well as sensing circuitry can be incorporated directly into wash-and-wear clothing. This paper describes some of the techniques used to build circuits from commercially available fabrics, yarns, fasteners, and components.},
	urldate = {2025-07-09},
	booktitle = {Digest of {Papers}. {First} {International} {Symposium} on {Wearable} {Computers}},
	author = {Post, E.R. and Orth, M.},
	month = oct,
	year = {1997},
	keywords = {Circuits, Clothing, Conducting materials, Fabrics, Keyboards, Laboratories, Optical fiber cables, Textiles, Wearable computers, Yarn},
	pages = {167--168},
	file = {Full Text PDF:C\:\\Users\\giand\\Zotero\\storage\\FIJWWQ95\\Post and Orth - 1997 - Smart fabric, or wearable clothing.pdf:application/pdf},
}

@article{post_e-broidery_2000,
	title = {E-broidery: {Design} and fabrication of textile-based computing},
	volume = {39},
	issn = {0018-8670},
	shorttitle = {E-broidery},
	url = {https://ieeexplore.ieee.org/abstract/document/5387040},
	doi = {10.1147/sj.393.0840},
	abstract = {Highly durable, flexible, and even washable multilayer electronic circuitry can be constructed on textile substrates, using conductive yarns and suitably packaged components. In this paper we describe the development of e-broidery (electronic embroidery, i.e., the patterning of conductive textiles by numerically controlled sewing or weaving processes) as a means of creating computationally active textiles. We compare textiles to existing flexible circuit substrates with regard to durability, conformability, and wearability. We also report on: some unique applications enabled by our work; the construction of sensors and user interface elements in textiles; and a complete process for creating flexible multilayer circuits on fabric substrates. This process maintains close compatibility with existing electronic components and design tools, while optimizing design techniques and component packages for use in textiles.},
	number = {3.4},
	urldate = {2025-07-09},
	journal = {IBM Systems Journal},
	author = {Post, E. R. and Orth, M. and Russo, P. R. and Gershenfeld, N.},
	year = {2000},
	pages = {840--860},
	file = {Snapshot:C\:\\Users\\giand\\Zotero\\storage\\WNA3AGNM\\5387040.html:text/html},
}

@inproceedings{pouta_woven_2022,
	address = {New York, NY, USA},
	series = {{DIS} '22},
	title = {Woven {eTextiles} in {HCI} — a {Literature} {Review}},
	isbn = {978-1-4503-9358-4},
	url = {https://dl.acm.org/doi/10.1145/3532106.3533566},
	doi = {10.1145/3532106.3533566},
	abstract = {Advances to functional materials and flexible electronics have yielded new means of integrating electrical properties into textile materials, which invite researchers in various fields to apply woven-textile construction methods in eTextile development. However, common ground for woven eTextiles’ prototyping is still taking shape. This calls for greater understanding of how the knowledge now scattered across diverse research fields can benefit the textiles’ development for HCI. To investigate how eTextile research has employed weaving and extract insight for HCI purposes, the authors reviewed and categorised applications of woven structures and electrical functions, then identified specifically HCI-relevant qualities and means of creating them via weaving. The paper outlines those woven structures useful for HCI and advocates consistent weaving-related terminology, to improve knowledge transfer across disciplines. In addition, the results point to research opportunities involving haptic qualities, the ability to weave multiple layers, functionality integration, and tools and methods.},
	urldate = {2025-07-09},
	booktitle = {Proceedings of the 2022 {ACM} {Designing} {Interactive} {Systems} {Conference}},
	publisher = {Association for Computing Machinery},
	author = {Pouta, Emmi and Mikkonen, Jussi Ville},
	month = jun,
	year = {2022},
	pages = {1099--1118},
	file = {Full Text PDF:C\:\\Users\\giand\\Zotero\\storage\\BXZNZUWW\\Pouta and Mikkonen - 2022 - Woven eTextiles in HCI — a Literature Review.pdf:application/pdf},
}

@inproceedings{chen_design_2020,
	address = {New York, NY, USA},
	series = {{TEI} '20},
	title = {The {Design} and {Creation} of {Tactile} {Knitted} {E}-textiles for {Interactive} {Applications}},
	isbn = {978-1-4503-6107-1},
	url = {https://dl.acm.org/doi/10.1145/3374920.3374959},
	doi = {10.1145/3374920.3374959},
	abstract = {E-textiles have the potential to be utilised for their tactile qualities, particularly in sensory stimulation applications. However, tactility and aesthetics are seldomly a focus of e-textiles research, as e-textiles research often concentrates on the functional aspects. While there is research in textiles and e-textiles for sensory stimulation, the research rarely takes advantage of textiles production technologies, frequently using handcraft to produce the sensory tools. While these techniques are accessible, they lack scalability, making creating e-textiles for interactive applications less practical. My work focuses on the design of tactile e-textiles, leveraging the benefits of knit technologies in the production of e-textiles. The work aims to produce a range of knitted textile-based e-textiles which balance design aesthetics, functionality and ease of production. This paper outlines the research that has already been conducted, as well as the planned future work as part of this PhD research.},
	urldate = {2025-07-09},
	booktitle = {Proceedings of the {Fourteenth} {International} {Conference} on {Tangible}, {Embedded}, and {Embodied} {Interaction}},
	publisher = {Association for Computing Machinery},
	author = {Chen, Amy},
	month = feb,
	year = {2020},
	pages = {905--909},
	file = {Full Text PDF:C\:\\Users\\giand\\Zotero\\storage\\UVBYF2RK\\Chen - 2020 - The Design and Creation of Tactile Knitted E-textiles for Interactive Applications.pdf:application/pdf},
}

@article{lee_conductive_2015,
	title = {Conductive {Fiber}‐{Based} {Ultrasensitive} {Textile} {Pressure} {Sensor} for {Wearable} {Electronics}},
	volume = {27},
	copyright = {http://onlinelibrary.wiley.com/termsAndConditions\#vor},
	issn = {0935-9648, 1521-4095},
	url = {https://onlinelibrary.wiley.com/doi/10.1002/adma.201500009},
	doi = {10.1002/adma.201500009},
	language = {en},
	number = {15},
	urldate = {2025-07-09},
	journal = {Advanced Materials},
	author = {Lee, Jaehong and Kwon, Hyukho and Seo, Jungmok and Shin, Sera and Koo, Ja Hoon and Pang, Changhyun and Son, Seungbae and Kim, Jae Hyung and Jang, Yong Hoon and Kim, Dae Eun and Lee, Taeyoon},
	month = apr,
	year = {2015},
	note = {Publisher: Wiley},
	pages = {2433--2439},
}

@inproceedings{honnet_polysense_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {{PolySense}: {Augmenting} {Textiles} with {Electrical} {Functionality} using {In}-{Situ} {Polymerization}},
	isbn = {978-1-4503-6708-0},
	shorttitle = {{PolySense}},
	url = {https://dl.acm.org/doi/10.1145/3313831.3376841},
	doi = {10.1145/3313831.3376841},
	abstract = {We present a method for enabling arbitrary textiles to sense pressure and deformation: In-situ polymerization supports integration of piezoresistive properties at the material level, preserving a textile's haptic and mechanical characteristics. We demonstrate how to enhance a wide set of fabrics and yarns using only readily available tools. To further support customisation by the designer, we present methods for patterning, as needed to create circuits and sensors, and demonstrate how to combine areas of different conductance in one material. Technical evaluation results demonstrate the performance of sensors created using our method is comparable to off-the-shelf piezoresistive textiles. As application examples, we demonstrate rapid manufacturing of on-body interfaces, tie-dyed motion-capture clothing, and zippers that act as potentiometers.},
	urldate = {2025-07-09},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Honnet, Cedric and Perner-Wilson, Hannah and Teyssier, Marc and Fruchard, Bruno and Steimle, Jürgen and Baptista, Ana C. and Strohmeier, Paul},
	month = apr,
	year = {2020},
	pages = {1--13},
	file = {Full Text PDF:C\:\\Users\\giand\\Zotero\\storage\\PT9MMRY5\\Honnet et al. - 2020 - PolySense Augmenting Textiles with Electrical Functionality using In-Situ Polymerization.pdf:application/pdf},
}

@article{goncalves_wearable_2018,
	title = {Wearable {E}-{Textile} {Technologies}: {A} {Review} on {Sensors}, {Actuators} and {Control} {Elements}},
	volume = {3},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2411-5134},
	shorttitle = {Wearable {E}-{Textile} {Technologies}},
	url = {https://www.mdpi.com/2411-5134/3/1/14},
	doi = {10.3390/inventions3010014},
	abstract = {Wearable e-textiles are able to perform electronic functions and are perceived as a way to add features into common wearable textiles, building competitive market advantages. The e-textile production has become not only a research effort but also an industrial production challenge. It is important to know how to use existing industrial processes or to develop new ones that are able to scale up production, ensuring the behavior and performance of prototypes. Despite the technical challenges, there are already some examples of wearable e-textiles where sensors, actuators, and production techniques were used to seamlessly embed electronic features into traditional wearable textiles, which allow for daily use without a bionic stigma.},
	language = {en},
	number = {1},
	urldate = {2025-07-09},
	journal = {Inventions},
	author = {Gonçalves, Carlos and Ferreira da Silva, Alexandre and Gomes, João and Simoes, Ricardo},
	month = mar,
	year = {2018},
	note = {Number: 1
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {conductive yarns, digital textiles, e-textiles, heat regulating textiles, smart textiles},
	pages = {14},
	file = {Full Text PDF:C\:\\Users\\giand\\Zotero\\storage\\MR3SF93T\\Gonçalves et al. - 2018 - Wearable E-Textile Technologies A Review on Sensors, Actuators and Control Elements.pdf:application/pdf},
}

@inproceedings{zeagler_textile_2012,
	title = {Textile {Interfaces}: {Embroidered} {Jog}-{Wheel}, {Beaded} {Tilt} {Sensor}, {Twisted} {Pair} {Ribbon}, and {Sound} {Sequins}},
	shorttitle = {Textile {Interfaces}},
	url = {https://ieeexplore.ieee.org/abstract/document/6246143},
	doi = {10.1109/ISWC.2012.29},
	abstract = {Electronic textiles (or e-textiles) attempt to integrate electronics and computing into fabric. In our efforts to create new e-textile interfaces and construction techniques for our Electronic Textile Interface Swatch Book (an e-textile toolkit), we have created a multi-use jog wheel using multilayer embroidery, sound sequins from PVDF film and a tilt sensor using a hanging bead, embroidery and capacitive sensing. In order to make capacitive sensing over long leads possible on the body, we have constructed twisted pair ribbon and demonstrated its effectiveness over more typical sensing techniques. We detail construction techniques and lessons learned from this technology exploration.},
	urldate = {2025-07-09},
	booktitle = {2012 16th {International} {Symposium} on {Wearable} {Computers}},
	author = {Zeagler, Clint and Gilliland, Scott and Profita, Halley and Starner, Thad},
	month = jun,
	year = {2012},
	note = {ISSN: 2376-8541},
	keywords = {Beaded Tilt Sensor, Capacitance, Embroidered Jog-Wheel, Fabrics, Films, Sensors, Sound Sequins, Textile Interfaces, Twisted Pair Ribbon, Wheels, Yarn},
	pages = {60--63},
	file = {Full Text PDF:C\:\\Users\\giand\\Zotero\\storage\\JF35BNW3\\Zeagler et al. - 2012 - Textile Interfaces Embroidered Jog-Wheel, Beaded Tilt Sensor, Twisted Pair Ribbon, and Sound Sequin.pdf:application/pdf},
}

@inproceedings{zeagler_can_2013,
	address = {New York, NY, USA},
	series = {{ISWC} '13},
	title = {Can i wash it? the effect of washing conductive materials usedin making textile based wearable electronic interfaces.},
	isbn = {978-1-4503-2127-3},
	shorttitle = {Can i wash it?},
	url = {https://dl.acm.org/doi/10.1145/2493988.2494344},
	doi = {10.1145/2493988.2494344},
	abstract = {We explore the wash-ability of conductive materials used in creating traces and touch sensors in wearable electronic textiles. We perform a wash test measuring change in resistivity after each of 10 cycles of washing for conductive traces constructed using two types of conductive thread, conductive ink, and combinations of thread and ink.},
	urldate = {2025-07-09},
	booktitle = {Proceedings of the 2013 {International} {Symposium} on {Wearable} {Computers}},
	publisher = {Association for Computing Machinery},
	author = {Zeagler, Clint and Gilliland, Scott and Audy, Stephen and Starner, Thad},
	month = sep,
	year = {2013},
	pages = {143--144},
	file = {Full Text PDF:C\:\\Users\\giand\\Zotero\\storage\\9SX88Z9B\\Zeagler et al. - 2013 - Can i wash it the effect of washing conductive materials usedin making textile based wearable elect.pdf:application/pdf},
}

@inproceedings{leong_procover_2016,
	address = {New York, NY, USA},
	series = {{UIST} '16},
	title = {{proCover}: {Sensory} {Augmentation} of {Prosthetic} {Limbs} {Using} {Smart} {Textile} {Covers}},
	isbn = {978-1-4503-4189-9},
	shorttitle = {{proCover}},
	url = {https://dl.acm.org/doi/10.1145/2984511.2984572},
	doi = {10.1145/2984511.2984572},
	abstract = {Today's commercially available prosthetic limbs lack tactile sensation and feedback. Recent research in this domain focuses on sensor technologies designed to be directly embedded into future prostheses. We present a novel concept and prototype of a prosthetic-sensing wearable that offers a non-invasive, self-applicable and customizable approach for the sensory augmentation of present-day and future low to mid-range priced lower-limb prosthetics. From consultation with eight lower-limb amputees, we investigated the design space for prosthetic sensing wearables and developed novel interaction methods for dynamic, user-driven creation and mapping of sensing regions on the foot to wearable haptic feedback actuators. Based on a pilot-study with amputees, we assessed the utility of our design in scenarios brought up by the amputees and we summarize our findings to establish future directions for research into using smart textiles for the sensory enhancement of prosthetic limbs.},
	urldate = {2025-07-09},
	booktitle = {Proceedings of the 29th {Annual} {Symposium} on {User} {Interface} {Software} and {Technology}},
	publisher = {Association for Computing Machinery},
	author = {Leong, Joanne and Parzer, Patrick and Perteneder, Florian and Babic, Teo and Rendl, Christian and Vogl, Anita and Egger, Hubert and Olwal, Alex and Haller, Michael},
	year = {2016},
	pages = {335--346},
	file = {Full Text PDF:C\:\\Users\\giand\\Zotero\\storage\\V9JSQ3J3\\Leong et al. - 2016 - proCover Sensory Augmentation of Prosthetic Limbs Using Smart Textile Covers.pdf:application/pdf},
}

@inproceedings{parzer_smartsleeve_2017,
	address = {New York, NY, USA},
	series = {{UIST} '17},
	title = {{SmartSleeve}: {Real}-time {Sensing} of {Surface} and {Deformation} {Gestures} on {Flexible}, {Interactive} {Textiles}, using a {Hybrid} {Gesture} {Detection} {Pipeline}},
	isbn = {978-1-4503-4981-9},
	shorttitle = {{SmartSleeve}},
	url = {https://dl.acm.org/doi/10.1145/3126594.3126652},
	doi = {10.1145/3126594.3126652},
	abstract = {Over the last decades, there have been numerous efforts in wearable computing research to enable interactive textiles. Most work focus, however, on integrating sensors for planar touch gestures, and thus do not fully take advantage of the flexible, deformable and tangible material properties of textile. In this work, we introduce SmartSleeve, a deformable textile sensor, which can sense both surface and deformation gestures in real-time. It expands the gesture vocabulary with a range of expressive interaction techniques, and we explore new opportunities using advanced deformation gestures, such as, Twirl, Twist, Fold, Push and Stretch. We describe our sensor design, hardware implementation and its novel non-rigid connector architecture. We provide a detailed description of our hybrid gesture detection pipeline that uses learning-based algorithms and heuristics to enable real-time gesture detection and tracking. Its modular architecture allows us to derive new gestures through the combination with continuous properties like pressure, location, and direction. Finally, we report on the promising results from our evaluations which demonstrate real-time classification.},
	urldate = {2025-07-09},
	booktitle = {Proceedings of the 30th {Annual} {ACM} {Symposium} on {User} {Interface} {Software} and {Technology}},
	publisher = {Association for Computing Machinery},
	author = {Parzer, Patrick and Sharma, Adwait and Vogl, Anita and Steimle, Jürgen and Olwal, Alex and Haller, Michael},
	year = {2017},
	pages = {565--577},
	file = {Full Text PDF:C\:\\Users\\giand\\Zotero\\storage\\97FEYM5V\\Parzer et al. - 2017 - SmartSleeve Real-time Sensing of Surface and Deformation Gestures on Flexible, Interactive Textiles.pdf:application/pdf},
}

@inproceedings{schneegass_gesturesleeve_2016,
	address = {New York, NY, USA},
	series = {{ISWC} '16},
	title = {{GestureSleeve}: using touch sensitive fabrics for gestural input on the forearm for controlling smartwatches},
	isbn = {978-1-4503-4460-9},
	shorttitle = {{GestureSleeve}},
	url = {https://dl.acm.org/doi/10.1145/2971763.2971797},
	doi = {10.1145/2971763.2971797},
	abstract = {Smartwatches provide quick and easy access to information. Due to their wearable nature, users can perceive the information while being stationary or on the go. The main drawback of smartwatches, however, is the limited input possibility. They use similar input methods as smartphones but thereby suffer from a smaller form factor. To extend the input space of smartwatches, we present GestureSleeve, a sleeve made out of touch enabled textile. It is capable of detecting different gestures such as stroke based gestures or taps. With these gestures, the user can control various smartwatch applications. Exploring the performance of the GestureSleeve approach, we conducted a user study with a running application as use case. In this study, we show that input using the GestureSleeve outperforms touch input on the smartwatch. In the future the GestureSleeve can be integrated into regular clothing and be used for controlling various smart devices.},
	urldate = {2025-07-09},
	booktitle = {Proceedings of the 2016 {ACM} {International} {Symposium} on {Wearable} {Computers}},
	publisher = {Association for Computing Machinery},
	author = {Schneegass, Stefan and Voit, Alexandra},
	month = sep,
	year = {2016},
	pages = {108--115},
	file = {Full Text PDF:C\:\\Users\\giand\\Zotero\\storage\\9J9NFGM3\\Schneegass and Voit - 2016 - GestureSleeve using touch sensitive fabrics for gestural input on the forearm for controlling smart.pdf:application/pdf},
}

@inproceedings{jones_wearable_2020,
	address = {New York, NY, USA},
	series = {{TEI} '20},
	title = {Wearable {Bits}: {Scaffolding} {Creativity} with a {Prototyping} {Toolkit} for {Wearable} {E}-textiles},
	isbn = {978-1-4503-6107-1},
	shorttitle = {Wearable {Bits}},
	url = {https://dl.acm.org/doi/10.1145/3374920.3374954},
	doi = {10.1145/3374920.3374954},
	abstract = {Smart garment and wearable e-textile prototypes are difficult to co-design because of the variety of expertise needed (garment design, sewing skills, hardware prototyping, and software programming). To help with this, we developed a toolkit for prototyping wearable e-textiles, named Wearable Bits, which enables co-design with non-expert users without demanding sewing, hardware or software skills. We developed a low-fidelity and medium-fidelity experience prototype of the toolkit and ran a series of workshops where non-expert users designed their own e-textile wearables using Wearable Bits. In this paper, we discuss the ideas they developed, their construction techniques, the roles individuals took on while building, and suggestions for future toolkits.},
	urldate = {2025-07-09},
	booktitle = {Proceedings of the {Fourteenth} {International} {Conference} on {Tangible}, {Embedded}, and {Embodied} {Interaction}},
	publisher = {Association for Computing Machinery},
	author = {Jones, Lee and Nabil, Sara and McLeod, Amanda and Girouard, Audrey},
	month = feb,
	year = {2020},
	pages = {165--177},
	file = {Full Text PDF:C\:\\Users\\giand\\Zotero\\storage\\MSEWYHAP\\Jones et al. - 2020 - Wearable Bits Scaffolding Creativity with a Prototyping Toolkit for Wearable E-textiles.pdf:application/pdf},
}

@inproceedings{nabil_soft_2021,
	address = {New York, NY, USA},
	series = {{TEI} '21},
	title = {Soft {Speakers}: {Digital} {Embroidering} of {DIY} {Customizable} {Fabric} {Actuators}},
	isbn = {978-1-4503-8213-7},
	shorttitle = {Soft {Speakers}},
	url = {https://dl.acm.org/doi/10.1145/3430524.3440630},
	doi = {10.1145/3430524.3440630},
	abstract = {We introduce Soft Speakers, a systematic approach for designing custom fabric actuators that can be used as audio speakers and vibro-haptic actuators. Digitally-embroidered with e-textiles, we implement Soft Speakers as tactile, malleable and aesthetic designs to be part of wearables, soft furnishing and fabric objects. We present a rapid technique for the DIY fabrication of audio feedback into soft interfaces. We also discuss and evaluate 7 factors for their parametric design in additive and constructive methods. To demonstrate the feasibility of our approach and the breadth of new designs that it enables, we developed 5 prototypes: 3 wearables, a piece of furniture and a soft toy. Studying Soft Speakers with maker-users expanded the design space, empowering users and supporting inclusive design. Our study includes insights on user experience of real-world interactive applications for remote communication, e-learning, entertainment, navigation and gaming, enabled by Soft Speakers’ customizable and scalable form factor.},
	urldate = {2025-07-09},
	booktitle = {Proceedings of the {Fifteenth} {International} {Conference} on {Tangible}, {Embedded}, and {Embodied} {Interaction}},
	publisher = {Association for Computing Machinery},
	author = {Nabil, Sara and Jones, Lee and Girouard, Audrey},
	month = feb,
	year = {2021},
	pages = {1--12},
	file = {Full Text PDF:C\:\\Users\\giand\\Zotero\\storage\\ASRCN8DU\\Nabil et al. - 2021 - Soft Speakers Digital Embroidering of DIY Customizable Fabric Actuators.pdf:application/pdf},
}

@inproceedings{petersen_squeeze_2007,
	address = {New York, NY, USA},
	series = {{CHI} {EA} '07},
	title = {Squeeze: designing for playful experiences among co-located people in homes},
	isbn = {978-1-59593-642-4},
	shorttitle = {Squeeze},
	url = {https://dl.acm.org/doi/10.1145/1240866.1241050},
	doi = {10.1145/1240866.1241050},
	abstract = {Squeeze is a multi-person, flexible and interactive furniture that allows for collective and playful exploration of the family history among co-located people in homes. It is designed to explore how we can use digital technology to create settings where co-located family members can collectively and actively engage in playful activities as part of their everyday lives at home. It is argued that this is for the most part an unexplored design space, which is awaiting the interest of the CHI community. Our work has both a strategic and theoretical outset. It is designed from a strategic point to open up the design space for digital domestic technology emphasizing the potential in designing for playful experiences among co-located family members. Secondly, it is designed from a theoretical perspective, namely that of designing for playfulness and aesthetics of interaction.},
	urldate = {2025-07-09},
	booktitle = {{CHI} '07 {Extended} {Abstracts} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Petersen, Marianne Graves},
	month = apr,
	year = {2007},
	pages = {2609--2614},
	file = {Full Text PDF:C\:\\Users\\giand\\Zotero\\storage\\UBH3BNBW\\Petersen - 2007 - Squeeze designing for playful experiences among co-located people in homes.pdf:application/pdf},
}

@inproceedings{yoon_timmi_2015,
	address = {New York, NY, USA},
	series = {{TEI} '15},
	title = {{TIMMi}: {Finger}-worn {Textile} {Input} {Device} with {Multimodal} {Sensing} in {Mobile} {Interaction}},
	isbn = {978-1-4503-3305-4},
	shorttitle = {{TIMMi}},
	url = {https://dl.acm.org/doi/10.1145/2677199.2680560},
	doi = {10.1145/2677199.2680560},
	abstract = {We introduce TIMMi, a textile input device for mobile interactions. TIMMi is worn on the index finger to provide a multimodal sensing input metaphor. The prototype is fabricated on a single layer of textile where the conductive silicone rubber is painted and the conductive threads are stitched. The sensing area comprises of three equally spaced dots and a separate wide line. Strain and pressure values are extracted from the line and three dots, respectively via voltage dividers. Regression analysis is performed to model the relationship between sensing values and finger pressure and bending. A multi-level thresholding is applied to capture different levels of finger bending and pressure. A temporal position tracking algorithm is implemented to capture the swipe gesture. In this preliminary study, we demonstrate TIMMi as a finger-worn input device with two applications: controlling music player and interacting with smartglasses.},
	urldate = {2025-07-09},
	booktitle = {Proceedings of the {Ninth} {International} {Conference} on {Tangible}, {Embedded}, and {Embodied} {Interaction}},
	publisher = {Association for Computing Machinery},
	author = {Yoon, Sang Ho and Huo, Ke and Nguyen, Vinh P. and Ramani, Karthik},
	month = jan,
	year = {2015},
	pages = {269--272},
	file = {Full Text PDF:C\:\\Users\\giand\\Zotero\\storage\\KI2J7KS2\\Yoon et al. - 2015 - TIMMi Finger-worn Textile Input Device with Multimodal Sensing in Mobile Interaction.pdf:application/pdf},
}

@inproceedings{strohmeier_zpatch_2018,
	address = {New York, NY, USA},
	series = {{TEI} '18},
	title = {{zPatch}: {Hybrid} {Resistive}/{Capacitive} {eTextile} {Input}},
	isbn = {978-1-4503-5568-1},
	shorttitle = {{zPatch}},
	url = {https://dl.acm.org/doi/10.1145/3173225.3173242},
	doi = {10.1145/3173225.3173242},
	abstract = {We present zPatch: an eTextile patch for hover, touch, and pressure input, using both resistive and capacitive sensing. zPatches are made by layering a piezo-resistive material between silver-plated ripstop, and embedding it in non-conductive fabric to form a patch. zPatches can be easily ironed onto most fabrics, in any location, enabling easy prototyping or ad hoc modifications of existing garments. We provide open-source resources for building and programming zPatches and present measures of the achieva-ble sensing resolution of a zPatch. A pressure based targeting task demonstrated users could reliably hit pressure tar-gets at up to 13 levels, given appropriate feedback. We demonstrate that the hybrid sensing approach reduces false activations and helps distinguish between gestures. Finally, we present example applications in which we use zPatches for controlling a music player, text entry and gaming input.},
	urldate = {2025-07-09},
	booktitle = {Proceedings of the {Twelfth} {International} {Conference} on {Tangible}, {Embedded}, and {Embodied} {Interaction}},
	publisher = {Association for Computing Machinery},
	author = {Strohmeier, Paul and Knibbe, Jarrod and Boring, Sebastian and Hornbæk, Kasper},
	year = {2018},
	pages = {188--198},
	file = {Full Text PDF:C\:\\Users\\giand\\Zotero\\storage\\R6Y6DGJN\\Strohmeier et al. - 2018 - zPatch Hybrid ResistiveCapacitive eTextile Input.pdf:application/pdf},
}

@inproceedings{heller_fabritouch_2014,
	address = {New York, NY, USA},
	series = {{ISWC} '14},
	title = {{FabriTouch}: exploring flexible touch input on textiles},
	isbn = {978-1-4503-2969-9},
	shorttitle = {{FabriTouch}},
	url = {https://dl.acm.org/doi/10.1145/2634317.2634345},
	doi = {10.1145/2634317.2634345},
	abstract = {Touch-sensitive fabrics let users operate wearable devices unobtrusively and with rich input gestures similar to those on modern smartphones and tablets. While hardware prototypes exist in the DIY crafting community, HCI designers and researchers have little data about how well these devices actually work in realistic situations. FabriTouch is the first flexible touch-sensitive fabric that provides such scientifically validated information. We show that placing a FabriTouch pad onto clothing and the body instead of a rigid support surface significantly reduces input speed but still allows for basic gestures. We also show the impact of sitting, standing, and walking on horizontal and vertical swipe gesture performance in a menu navigation task. Finally, we provide the details necessary to replicate our FabriTouch pad, to enable both the DIY crafting community and HCI researchers and designers to build on our work.},
	urldate = {2025-07-09},
	booktitle = {Proceedings of the 2014 {ACM} {International} {Symposium} on {Wearable} {Computers}},
	publisher = {Association for Computing Machinery},
	author = {Heller, Florian and Ivanov, Stefan and Wacharamanotham, Chat and Borchers, Jan},
	month = sep,
	year = {2014},
	pages = {59--62},
	file = {Full Text PDF:C\:\\Users\\giand\\Zotero\\storage\\LQ8M4GVP\\Heller et al. - 2014 - FabriTouch exploring flexible touch input on textiles.pdf:application/pdf},
}

@inproceedings{karrer_pinstripe_2011,
	address = {New York, NY, USA},
	series = {{CHI} '11},
	title = {Pinstripe: eyes-free continuous input on interactive clothing},
	isbn = {978-1-4503-0228-9},
	shorttitle = {Pinstripe},
	url = {https://dl.acm.org/doi/10.1145/1978942.1979137},
	doi = {10.1145/1978942.1979137},
	abstract = {We present Pinstripe, a textile user interface element for eyes-free, continuous value input on smart garments that uses pinching and rolling a piece of cloth between your fingers. The input granularity can be controlled in a natural way by varying the amount of cloth pinched. Pinstripe input elements physically consist of fields of parallel conductive lines sewn onto the fabric. This way, they can be invisible, and can be included across large areas of a garment. Pinstripe also addresses several problems previously identified in the placement and operation of textile UI elements on smart clothing. Two user studies evaluate ideal placement and orientation of Pinstripe elements on the users' garments as well as acceptance and perceived ease of use of this novel textile input technique.},
	urldate = {2025-07-09},
	booktitle = {Proceedings of the {SIGCHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Karrer, Thorsten and Wittenhagen, Moritz and Lichtschlag, Leonhard and Heller, Florian and Borchers, Jan},
	year = {2011},
	pages = {1313--1322},
	file = {Full Text PDF:C\:\\Users\\giand\\Zotero\\storage\\J6K39YVV\\Karrer et al. - 2011 - Pinstripe eyes-free continuous input on interactive clothing.pdf:application/pdf},
}

@inproceedings{luo_knitui_2021,
	address = {New York, NY, USA},
	series = {{CHI} '21},
	title = {{KnitUI}: {Fabricating} {Interactive} and {Sensing} {Textiles} with {Machine} {Knitting}},
	isbn = {978-1-4503-8096-6},
	shorttitle = {{KnitUI}},
	url = {https://dl.acm.org/doi/10.1145/3411764.3445780},
	doi = {10.1145/3411764.3445780},
	abstract = {With the recent interest in wearable electronics and smart garments, digital fabrication of sensing and interactive textiles is in increasing demand. Recently, advances in digital machine knitting offer opportunities for the programmable, rapid fabrication of soft, breathable textiles. In this paper, we present KnitUI, a novel, accessible machine-knitted user interface based on resistive pressure sensing. Employing conductive yarns and various machine knitting techniques, we computationally design and automatically fabricate the double-layered resistive sensing structures as well as the coupled conductive connection traces with minimal manual post-processing. We present an interactive design interface for users to customize KnitUI’s colors, sizes, positions, and shapes. After investigating design parameters for the optimized sensing and interactive performance, we demonstrate KnitUI as a portable, deformable, washable, and customizable interactive and sensing platform. It obtains diverse applications, including wearable user interfaces, tactile sensing wearables, and artificial robot skin.},
	urldate = {2025-07-09},
	booktitle = {Proceedings of the 2021 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Luo, Yiyue and Wu, Kui and Palacios, Tomás and Matusik, Wojciech},
	year = {2021},
	pages = {1--12},
	file = {Full Text PDF:C\:\\Users\\giand\\Zotero\\storage\\FCF8BEYZ\\Luo et al. - 2021 - KnitUI Fabricating Interactive and Sensing Textiles with Machine Knitting.pdf:application/pdf},
}

@misc{heller_gardeene_2016,
	title = {Gardeene! {Textile} {Controls} for the {Home} {Environment}},
	url = {https://dl.gi.de/handle/20.500.12116/195},
	doi = {10.18420/MUC2016-MCI-0239},
	abstract = {Textile controls so far, have mostly been envisioned to be integrated to clothing. In our environment, however, much more textile interaction surfaces are available. In this paper, we present a capacitive textile sensor, seamlessly integrated into a motorized curtain. While the basic functionality is simply to open and close the curtain, its design allows a much richer gestural interaction.},
	language = {en},
	urldate = {2025-07-09},
	publisher = {Gesellschaft für Informatik e.V.},
	author = {Heller, Florian and Oßmann, Lukas and Hamdan, Nur and Brauner, Philipp and Van Heek, Julia and Scheulen, Klaus and Möllering, Christian and Goßen, Laura and Witsch, Rouven and Ziefle, Martina and Gries, Thomas and Borchers, Jan},
	year = {2016},
	keywords = {capacitive sensing, curtain, fabric, home, textile interfaces},
}

@inproceedings{ono_textile_2017,
	address = {New York, NY, USA},
	series = {{SIGGRAPH} '17},
	title = {Textile++: low cost textile interface using the principle of resistive touch sensing},
	isbn = {978-1-4503-5009-9},
	shorttitle = {Textile++},
	url = {https://dl.acm.org/doi/10.1145/3084863.3084868},
	doi = {10.1145/3084863.3084868},
	abstract = {Here we introduce our system Textile++, a touch-sensitive cloth consisting of fiber materials. With this system, it is possible to detect the XY coordinate position of the substance touching the cloth. In addition, pressure can be detected. Textile++ is flexible and lightweight, making it is easy to apply to conventional clothes. Compared to existing methods, the structure is simple, so it is possible to manufacture at very low cost. This paper explains the proposed Textile ++ system and its application to a cuff-based user interface (UI) created for a jacket (Figure 1).},
	urldate = {2025-07-09},
	booktitle = {{ACM} {SIGGRAPH} 2017 {Studio}},
	publisher = {Association for Computing Machinery},
	author = {Ono, Keisuke and Iwamura, Shinichiro and Ogie, Akira and Baba, Tetsuaki and Haimes, Paul},
	month = jul,
	year = {2017},
	pages = {1--2},
	file = {Full Text PDF:C\:\\Users\\giand\\Zotero\\storage\\GR74DSMS\\Ono et al. - 2017 - Textile++ low cost textile interface using the principle of resistive touch sensing.pdf:application/pdf},
}

@article{weiser_computer_1991,
	title = {The {Computer} for the 21st {Century}},
	volume = {265},
	issn = {0036-8733},
	url = {https://www.scientificamerican.com/article/the-computer-for-the-21st-century},
	doi = {10.1038/scientificamerican0991-94},
	number = {3},
	urldate = {2025-07-10},
	journal = {Scientific American},
	author = {Weiser, Mark},
	month = sep,
	year = {1991},
	note = {Publisher: Springer Science and Business Media LLC},
	pages = {94--104},
}


@article{van_langenhove_smart_2004,
	title = {Smart {Textiles} in {Vehicles}: {A} {Foresight}},
	volume = {3},
	issn = {1533-0915},
	url = {http://hdl.handle.net/1854/LU-296011},
	language = {English},
	number = {4, Winter},
	journal = {Journal of textile and apparel technology and management},
	author = {Van Langenhove, Lieva and Hertleer, Carla},
	year = {2004},
	pages = {1--6},
}

@incollection{wagner_16_2013,
	series = {Woodhead {Publishing} {Series} in {Textiles}},
	title = {16 - {Automotive} applications of smart textiles},
	isbn = {978-0-85709-342-4},
	url = {https://www.sciencedirect.com/science/article/pii/B978085709342450016X},
	abstract = {Smart textiles have become a new topic in vehicle engineering. New applications in the automotive industry seem to have potential and may give access to entirely new system approaches. This chapter presents some of them and focuses especially on the potential of measuring physiological parameters such as heart rate, electrodermal activity and others. Investigations on prototype systems of car seats and steering wheels will be discussed.},
	urldate = {2025-07-10},
	booktitle = {Multidisciplinary {Know}-{How} for {Smart}-{Textiles} {Developers}},
	publisher = {Woodhead Publishing},
	author = {Wagner, M.},
	editor = {Kirstein, Tünde},
	month = jan,
	year = {2013},
	doi = {10.1533/9780857093530.3.444},
	keywords = {capacitive coupled electrocardiogram, car seats, INSITEX, sensor steering wheel, smart textiles, textile multilayer electrode, vital parameters},
	pages = {444--467},
	file = {ScienceDirect Snapshot:C\:\\Users\\giand\\Zotero\\storage\\HZ3F9RYX\\B978085709342450016X.html:text/html},
}

@inproceedings{caon_wearable_2014,
	address = {New York, NY, USA},
	series = {{AutomotiveUI} '14},
	title = {Wearable {Technologies} for {Automotive} {User} {Interfaces}: {Danger} or {Opportunity}?},
	isbn = {978-1-4503-0725-3},
	shorttitle = {Wearable {Technologies} for {Automotive} {User} {Interfaces}},
	url = {https://dl.acm.org/doi/10.1145/2667239.2667314},
	doi = {10.1145/2667239.2667314},
	abstract = {Wearable technologies are spreading into human's everyday life. Smart bracelets, watches and glasses promise to provide us with ready-at-hand access to several information and interaction possibilities. What happens when these technologies enter the car? Are they a mere danger or can also offer information and interaction opportunities that can improve the vehicle inhabitants' user experience and safety? This workshop aims to discuss all the opportunities and dangers that such technologies not only are already bringing in nowadays vehicles, but could also bring in future semi-autonomous and autonomous vehicles.},
	urldate = {2025-07-10},
	booktitle = {Adjunct {Proceedings} of the 6th {International} {Conference} on {Automotive} {User} {Interfaces} and {Interactive} {Vehicular} {Applications}},
	publisher = {Association for Computing Machinery},
	author = {Caon, Maurizio and Tagliabue, Michele and Angelini, Leonardo and Perego, Paolo and Mugellini, Elena and Andreoni, Giuseppe},
	month = sep,
	year = {2014},
	pages = {1--5},
	file = {Full Text PDF:C\:\\Users\\giand\\Zotero\\storage\\8FMYDLHI\\Caon et al. - 2014 - Wearable Technologies for Automotive User Interfaces Danger or Opportunity.pdf:application/pdf},
}

@misc{poupyrev_more_2017,
	title = {More than just a jacket: {Levi}’s {Commuter} {Trucker} {Jacket} powered by {Jacquard} technology},
	shorttitle = {More than just a jacket},
	url = {https://blog.google/products/atap/more-just-jacket-levis-commuter-trucker-jacket-powered-jacquard-technology/},
	abstract = {A Levi’s jacket with Jacquard technology woven in},
	language = {en-us},
	note = {Accessed on 10.07.2025},
	journal = {Google - The Keyword Blog},
	author = {Poupyrev, Ivan},
	month = sep,
	year = {2017},
	file = {Snapshot:C\:\\Users\\giand\\Zotero\\storage\\KTIYJTF4\\more-just-jacket-levis-commuter-trucker-jacket-powered-jacquard-technology.html:text/html},
}

@misc{poupyrev_smarter_2019,
	title = {A smarter wardrobe with {Jacquard} by {Google}},
	url = {https://blog.google/products/atap/smarter-wardrobe-jacquard-google/},
	abstract = {Jacquard by Google announces new hardware and software, redesigned app interface and more partners, including four new  jacket styles with Levi’s.},
	language = {en-us},
	note = {Accessed on 10.07.2025},
	journal = {Google - The Keyword Blog},
	author = {Poupyrev, Ivan},
	month = oct,
	year = {2019},
	file = {Snapshot:C\:\\Users\\giand\\Zotero\\storage\\FDKRJ4V4\\smarter-wardrobe-jacquard-google.html:text/html},
}

@misc{poupyrev_make_2020,
	title = {Make your everyday smarter with {Jacquard}},
	url = {https://blog.google/products/atap/jacquard-samsonite-backpacks/},
	abstract = {Jacquard by Google announces new hardware and software, including two backpacks with Samsonite.},
	language = {en-us},
	note = {Accessed on 10.07.2025},
	journal = {Google - The Keyword Blog},
	author = {Poupyrev, Ivan},
	month = oct,
	year = {2020},
	file = {Snapshot:C\:\\Users\\giand\\Zotero\\storage\\IYQP8WYN\\jacquard-samsonite-backpacks.html:text/html},
}

@misc{bradshaw_google_2023,
	title = {Google shutting down the {Jacquard} smart fabric app in {April} [{Updated}]},
	url = {https://9to5google.com/2023/03/28/google-shutting-down-jacquard-app/},
	abstract = {Google has confirmed it is shutting down the app responsible for the Jacquard accessories made by Google ATAP. Project Jacquard...},
	language = {en-US},
	note = {Accessed on 10.07.2025},
	journal = {9to5Google},
	author = {Bradshaw, Kyle},
	month = mar,
	year = {2023},
}

@misc{google_store_google_nodate,
	title = {Google {Nest} {Mini} {Tech} {Specs}},
	url = {https://store.google.com/product/google_nest_mini_specs?hl=en-US},
	note = {Accessed on 10.07.2025},
	journal = {Google Store},
	author = {{Google Store}},
}


@article{mignonneau_designing_2005,
	title = {Designing emotional, metaphoric, natural and intuitive interfaces for interactive art, edutainment and mobile communications},
	volume = {29},
	issn = {0097-8493},
	url = {https://www.sciencedirect.com/science/article/pii/S009784930500155X},
	doi = {10.1016/j.cag.2005.09.001},
	abstract = {We are artists working since 1991 on the creation of interactive computer installations for which we design metaphoric, emotional, natural, intuitive and multi-modal interfaces. The interactive experiences we create are situated between art, design, entertainment and edutainment. When creating our interactive systems we often develop novel interface technologies that match conceptual and metaphoric content with technically novel interface solutions. While our main focus is to design interactive systems for the art context, our interactive or immersive systems also often find use in edutainment and in mobile communications areas. The following article summarizes some of our key concepts for our interface designs and presents some of our interactive technologies in more detail.},
	number = {6},
	urldate = {2025-07-10},
	journal = {Computers \& Graphics},
	author = {Mignonneau, Laurent and Sommerer, Christa},
	month = dec,
	year = {2005},
	keywords = {Computer interaction, Interactive art, Mobile communications, Multi-modal interfaces},
	pages = {837--851},
	file = {PDF:C\:\\Users\\giand\\Zotero\\storage\\3H9HEF9W\\Mignonneau and Sommerer - 2005 - Designing emotional, metaphoric, natural and intuitive interfaces for interactive art, edutainment a.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\giand\\Zotero\\storage\\3LPUL6N8\\S009784930500155X.html:text/html},
}

@inproceedings{khan_intuitive_2017,
	title = {Intuitive and effective gestures for conceptual architectural design},
	abstract = {Gesture-based natural interfaces necessitate research into gestures that are intuitive for designers and effective for natural interaction. Intuitive knowledge is significant for conceptual design as it reduces tme taken to complete tasks and improves usability of products. In a previously conducted experiment, we elicited gestures for 3D CAD modeling tasks for conceptual architectural design. In this study, we present a preliminary analysis of intuitiveness scores of gestures and evaluators' ratngs to analyze which gestures were more intuitive and effective for CAD manipulation tasks. Results show that gestures with high intuitive scores were not necessarily rated as effective by evaluators and that bimanual symmetric gestures consistently scored high for both intuitiveness and effectiveness. Based on our findings we give recommendations for the design of gesture-based CAD modeling systems for single and multple users.},
	language = {English},
	booktitle = {Disciplines and {Disruption} - {Proceedings} {Catalog} of the 37th {Annual} {Conference} of the {Association} for {Computer} {Aided} {Design} in {Architecture}, {ACADIA} 2017},
	publisher = {ACADIA},
	author = {Khan, Sumbul and Tunçer, Bige},
	editor = {Nagakura, Takehiko and Mueller, Caitlin and Tibbits, Skylar and Ibanez, Mariana},
	year = {2017},
	pages = {318--323},
}

@article{chen_affordance_2017,
	series = {Complex {Systems} {Engineering} and {Development} {Proceedings} of the 27th {CIRP} {Design} {Conference} {Cranfield} {University}, {UK} 10th – 12th {May} 2017},
	title = {Affordance and {Intuitive} {Interface} {Design} for {Elder} {Users} with {Dementia}},
	volume = {60},
	issn = {2212-8271},
	url = {https://www.sciencedirect.com/science/article/pii/S2212827117301117},
	doi = {10.1016/j.procir.2017.02.015},
	abstract = {Elderly users with dementia often forget how to perform activities of daily living (ADLs) because of declined cognitive ability. Affordance emphasises intuitive relationships and interaction and has potentials for product design for elderly users or users with dementia. This study investigated the intuitive interaction and affordance relationship between elderly users with dementia and the user-interface characteristics of ADLs. We used the user interfaces of microwave ovens as a research tool for recording participants’ initial reaction time for a specific operating task and the time for task completion. In addition, we observed and recorded the problems experienced by the participants during the tasks for examining the user-interface characteristics that possess superior usability and can induce the intuitive interaction of elderly users with dementia. The research results indicated that interface designs with simple layouts were optimal for elderly users with dementia in intuitive operation and usability; thus, complex arrangements and information presentations that require imaginative association should be avoided when designing interfaces. The results provide references for designing intuitive and humanised user interfaces for elderly users with dementia.},
	urldate = {2025-07-10},
	journal = {Procedia CIRP},
	author = {Chen, Li-Hao and Liu, Yi-Chien},
	month = jan,
	year = {2017},
	keywords = {Affordance, Dementia in old age, Intuitive interaction},
	pages = {470--475},
	file = {ScienceDirect Snapshot:C\:\\Users\\giand\\Zotero\\storage\\GHTQXQ2C\\S2212827117301117.html:text/html},
}

@article{blackler_towards_2015,
	title = {Towards {Intuitive} {Interaction} {Theory}},
	volume = {27},
	issn = {0953-5438},
	url = {https://doi.org/10.1093/iwc/iwv011},
	doi = {10.1093/iwc/iwv011},
	number = {3},
	urldate = {2025-07-10},
	journal = {Interacting with Computers},
	author = {Blackler, Alethea and Popovic, Vesna},
	month = may,
	year = {2015},
	pages = {203--209},
	file = {Snapshot:C\:\\Users\\giand\\Zotero\\storage\\DST96YGV\\iwv011.html:text/html;Submitted Version:C\:\\Users\\giand\\Zotero\\storage\\MXQK5CDI\\Blackler and Popovic - 2015 - Towards Intuitive Interaction Theory.pdf:application/pdf},
}

@book{norman_design_2013,
	address = {Cambridge (Mass.)},
	edition = {Rev. and expanded edition},
	title = {The design of everyday things},
	isbn = {978-0-465-05065-9},
	abstract = {"Even the smartest among us can feel inept as we fail to figure out which light switch or oven burner to turn on, or whether to push, pull, or slide a door. The fault, argues this ingenious-even liberating-book, lies not in ourselves, but in product design that ignores the needs of users and the principles of cognitive psychology. The problems range from ambiguous and hidden controls to arbitrary relationships between controls and functions, coupled with a lack of feedback or other assistance and unreasonable demands on memorization. The Design of Everyday Things shows that good, usable design is possible. The rules are simple : make things visible, exploit natural relationships that couple function and control, and make intelligent use of constraints. The goal : guide the user effortlessly to the right action on the right control at the right time. In this entertaining and insightful analysis, cognitive scientist Don Norman hails excellence of design as the most important key to regaining the competitive edge in influencing consumer behavior. Now fully expanded and updated, with a new introduction by the author, The Design of Everyday Things is a powerful primer on how-and why-some products satisfy customers while others only frustrate them."},
	language = {eng},
	publisher = {MIT press},
	author = {Norman, Donald A.},
	year = {2013},
}

@misc{harpercollins_publishers_american_nodate,
	title = {The {American} {Heritage} {Dictionary} entry: feedback},
	url = {https://ahdictionary.com/word/search.html?q=feedback},
	abstract = {The American Heritage Dictionary entry: feedback},
	language = {English},
	urldate = {2025-07-10},
	journal = {The American Heritage Dictionary of the English Language},
	author = {{HarperCollins Publishers}},
	file = {Snapshot:C\:\\Users\\giand\\Zotero\\storage\\NF8YATW4\\search.html:text/html},
}

@article{gibson_theory_1977,
	title = {The theory of affordances. {Perceiving}, acting, and knowing: toward an ecological psychology},
	journal = {Perceiving, Acting, and Knowing: Toward an Ecological Psychology},
	author = {Gibson, James J},
	year = {1977},
	note = {Publisher: Routledge London, UK},
	pages = {67--82},
}

@inproceedings{vermeulen_crossing_2013,
	address = {New York, NY, USA},
	series = {{CHI} '13},
	title = {Crossing the bridge over {Norman}'s {Gulf} of {Execution}: revealing feedforward's true identity},
	isbn = {978-1-4503-1899-0},
	shorttitle = {Crossing the bridge over {Norman}'s {Gulf} of {Execution}},
	url = {https://dl.acm.org/doi/10.1145/2470654.2466255},
	doi = {10.1145/2470654.2466255},
	abstract = {Feedback and affordances are two of the most well-known principles in interaction design. Unfortunately, the related and equally important notion of feedforward has not been given as much consideration. Nevertheless, feedforward is a powerful design principle for bridging Norman's Gulf of Execution. We reframe feedforward by disambiguating it from related design principles such as feedback and perceived affordances, and identify new classes of feedforward. In addition, we present a reference framework that provides a means for designers to explore and recognize different opportunities for feedforward.},
	urldate = {2025-07-10},
	booktitle = {Proceedings of the {SIGCHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Vermeulen, Jo and Luyten, Kris and van den Hoven, Elise and Coninx, Karin},
	month = apr,
	year = {2013},
	pages = {1931--1940},
	file = {Full Text PDF:C\:\\Users\\giand\\Zotero\\storage\\U9BH7WSR\\Vermeulen et al. - 2013 - Crossing the bridge over Norman's Gulf of Execution revealing feedforward's true identity.pdf:application/pdf},
}

@article{norman_way_2008,
	title = {{THE} {WAY} {I} {SEE} {ITSignifiers}, not affordances},
	volume = {15},
	issn = {1072-5520},
	url = {https://dl.acm.org/doi/10.1145/1409040.1409044},
	doi = {10.1145/1409040.1409044},
	number = {6},
	urldate = {2025-07-10},
	journal = {interactions},
	author = {Norman, Donald A.},
	month = nov,
	year = {2008},
	pages = {18--19},
	file = {Full Text PDF:C\:\\Users\\giand\\Zotero\\storage\\YJJH5RAD\\Norman - 2008 - THE WAY I SEE ITSignifiers, not affordances.pdf:application/pdf},
}

@inproceedings{gaver_technology_1991,
	address = {New York, NY, USA},
	series = {{CHI} '91},
	title = {Technology affordances},
	isbn = {978-0-89791-383-6},
	url = {https://dl.acm.org/doi/10.1145/108844.108856},
	doi = {10.1145/108844.108856},
	urldate = {2025-07-10},
	booktitle = {Proceedings of the {SIGCHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Gaver, William W.},
	year = {1991},
	pages = {79--84},
	file = {Full Text PDF:C\:\\Users\\giand\\Zotero\\storage\\6USV76VQ\\Gaver - 1991 - Technology affordances.pdf:application/pdf},
}

@article{hartson_cognitive_2003,
	title = {Cognitive, physical, sensory, and functional affordances in interaction design},
	volume = {22},
	issn = {0144-929X},
	url = {https://doi.org/10.1080/01449290310001592587},
	doi = {10.1080/01449290310001592587},
	abstract = {In reaction to Norman's (1999) essay on misuse of the term affordance in human-computer interaction literature, this article is a concept paper affirming the importance of this powerful concept, reinforcing Norman's distinctions of terminology, and expanding on the usefulness of the concepts in terms of their application to interaction design and evaluation. We define and use four complementary types of affordance in the context of interaction design and evaluation: cognitive affordance, physical affordance, sensory affordance, and functional affordance. The terms cognitive affordance (Norman's perceived affordance) and physical affordance (Norman's real affordance) refer to parallel and equally important usability concepts for interaction design, to which sensory affordance plays a supporting role. We argue that the concept of physical affordance carries a mandatory component of utility or purposeful action (functional affordance). Finally, we provide guidelines to help designers think about how these four kinds of affordance work together naturally in contextualized HCI design or evaluation.},
	number = {5},
	urldate = {2025-07-10},
	journal = {Behaviour \& Information Technology},
	author = {Hartson, Rex},
	month = sep,
	year = {2003},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/01449290310001592587},
	pages = {315--338},
}

@inproceedings{mlakar_signifiers_2025,
	address = {New York, NY, USA},
	series = {{TEI} '25},
	title = {Signifiers in {Textile}-{Specific} {Interaction} {Design}},
	isbn = {979-8-4007-1197-8},
	url = {https://dl.acm.org/doi/10.1145/3689050.3704431},
	doi = {10.1145/3689050.3704431},
	abstract = {This pictorial explores textile-specific interaction and various signifiers to communicate them. In a textile workshop, nine designers created 50 samples of potential interfaces, based on everyday actions people perform with textiles and with a specific focus on signifiers. The samples were analysed and categorized as annotated portfolios, which revealed three categories of signifiers relevant to textile-specific interaction design: Visual signifiers, Textile signifiers, and Staging signifiers. The pictorial offers more details on each category and further discusses the Staging category. Following the annotations, a subset of the textile samples from the workshop was further explored in an exploration session to gain insights into users' perceptions and interpretations of signifiers and interactions. The paper concludes with a high-level reflection on the use of signifiers in textile-specific interaction design, as well as considerations for future designers of smart textile interfaces.},
	urldate = {2025-04-14},
	booktitle = {Proceedings of the {Nineteenth} {International} {Conference} on {Tangible}, {Embedded}, and {Embodied} {Interaction}},
	publisher = {Association for Computing Machinery},
	author = {Mlakar, Sara and Haberfellner, Mira A. and Probst, Kathrin},
	year = {2025},
	keywords = {To Read, Important},
	pages = {1--14},
	file = {Full Text PDF:C\:\\Users\\giand\\Zotero\\storage\\NDFKI3VR\\Mlakar et al. - 2025 - Signifiers in Textile-Specific Interaction Design.pdf:application/pdf},
}

@inproceedings{nowak_investigating_2025,
	address = {New York, NY, USA},
	series = {{TEI} '25},
	title = {Investigating {Eyes}-{Free} {Recognition} and {Distinguishability} of {Textile} {Icons} in {Pairs}},
	isbn = {979-8-4007-1197-8},
	url = {https://dl.acm.org/doi/10.1145/3689050.3704931},
	doi = {10.1145/3689050.3704931},
	abstract = {Textile interfaces enable silent and discreet input on clothing, accessories, and smart home furniture. While researchers already presented approaches to make them technologically feasible, it is not fully clear how users experience textile interfaces and how well users perform when vision-free usage is encouraged. Recently, designs of single textile icons, i.e., symbols used as textile buttons or labels, were investigated. Practical user interfaces, however, typically consist of entire groups of nearby icons. Their haptic distinguishability is key for seamless operation. Furthermore, it is unclear whether icon recognition benefits or suffers when comparing neighboring icons is possible. We conducted a study where users blindly palpated icon pairs, tried to recognize the individual shapes and rated how easy they were to tell apart. We present our observations on haptic distinguishability, which, inter alia, show that more haptic cues via neighboring icons do not impact shape recognition.},
	urldate = {2025-04-14},
	booktitle = {Proceedings of the {Nineteenth} {International} {Conference} on {Tangible}, {Embedded}, and {Embodied} {Interaction}},
	publisher = {Association for Computing Machinery},
	author = {Nowak, Oliver and Schäfer, René and Buttkus, Elisabeth Jane and Schirp, Lea Emilia and Müller, Heiko and Borchers, Jan},
	year = {2025},
	keywords = {To Read},
	pages = {1--13},
	file = {Full Text PDF:C\:\\Users\\giand\\Zotero\\storage\\4UI3YL93\\Nowak et al. - 2025 - Investigating Eyes-Free Recognition and Distinguishability of Textile Icons in Pairs.pdf:application/pdf},
}

@article{wicaksono_fabrickeyboard_2017,
	title = {Fabrickeyboard: {Multimodal} {Textile} {Sensate} {Media} {As} {An} {Expressive} {And} {Deformable} {Musical} {Interface}},
	copyright = {Creative Commons Attribution 4.0, Open Access},
	shorttitle = {Fabrickeyboard},
	url = {https://zenodo.org/record/1176278},
	doi = {10.5281/ZENODO.1176278},
	abstract = {This paper presents FabricKeyboard: a novel deformable keyboard interface based on a multi-modal fabric sensate surface. Multi-layer fabric sensors that detect touch, proximity, electric field, pressure, and stretch are machine-sewn in a keyboard pattern on a stretchable substrate. The result is a fabric-based musical controller that combines both the discrete controls of a keyboard and various continuous controls from the embedded fabric sensors. This enables unique tactile experiences and new interactions both with physical and non-contact gestures: physical by pressing, pulling, stretching, and twisting the keys or the fabric and non-contact by hovering and waving towards/against the keyboard and an electromagnetic source. We have also developed additional fabric-based modular interfaces such as a ribbon-controller and trackpad, allowing performers to add more expressive and continuous controls. This paper will discuss implementation strategies for our system-on-textile, fabric-based sensor developments, as well as sensor-computer interfacing and musical mapping examples of this multi-modal and expressive fabric keyboard.},
	urldate = {2025-07-11},
	author = {Wicaksono, Irmandy and Paradiso, Joseph},
	month = jun,
	year = {2017},
	note = {Publisher: Zenodo},
}

@inproceedings{vanderloock_skweezee_2013,
	address = {New York, NY, USA},
	series = {{UIST} '13},
	title = {The skweezee system: enabling the design and the programming of squeeze interactions},
	isbn = {978-1-4503-2268-3},
	shorttitle = {The skweezee system},
	url = {https://dl.acm.org/doi/10.1145/2501988.2502033},
	doi = {10.1145/2501988.2502033},
	abstract = {The Skweezee System is an easy, flexible and open system for designing and developing squeeze-based, gestural interactions. It consists of Skweezees, which are soft objects, filled with conductive padding, that can be deformed or squeezed by applying pressure. These objects contain a number of electrodes that are dispersed over the shape. The electrodes sense the shape shifting of the conductive filling by measuring the changing resistance between every possible pair of electrodes. In addition, the Skweezee System contains user-friendly software that allows end-users to define and to record their own squeeze gestures. These gestures are distinguished using a Support Vector Machine (SVM) classifier. In this paper we introduce the concept and the underlying technology of the Skweezee System and we demonstrate the robustness of the SVM based classifier via two experimental user studies. The results of these studies demonstrate accuracies of 81\% (8 gestures, user-defined) to 97\% (3 gestures, user-defined), with an accuracy of 90\% for 7 pre-defined gestures.},
	urldate = {2025-07-11},
	booktitle = {Proceedings of the 26th annual {ACM} symposium on {User} interface software and technology},
	publisher = {Association for Computing Machinery},
	author = {Vanderloock, Karen and Vanden Abeele, Vero and Suykens, Johan A.K. and Geurts, Luc},
	year = {2013},
	pages = {521--530},
	file = {Full Text PDF:C\:\\Users\\giand\\Zotero\\storage\\WQVAPAZV\\Vanderloock et al. - 2013 - The skweezee system enabling the design and the programming of squeeze interactions.pdf:application/pdf},
}

@inproceedings{hamdan_grabrics_2016,
	address = {New York, NY, USA},
	series = {{CHI} {EA} '16},
	title = {Grabrics: {A} {Foldable} {Two}-{Dimensional} {Textile} {Input} {Controller}},
	isbn = {978-1-4503-4082-3},
	shorttitle = {Grabrics},
	url = {https://dl.acm.org/doi/10.1145/2851581.2892529},
	doi = {10.1145/2851581.2892529},
	abstract = {Textile interfaces can be ubiquitously integrated into the fabrics that already surround us. So far, existing interfaces transfer concepts, such as buttons and sliders, to the textile domain without leveraging the affordances and qualities of fabric. This paper presents Grabrics, a two-dimensional textile sensor that is manipulated by grabbing a fold and moving it between your fingers. Grabrics can be integrated invisibly into everyday clothing or into textile objects, like a living room sofa, while minimizing accidental activation. We describe the construction and the fold-based interaction technique of our Grabrics sensor. A preliminary study shows that Grabrics can be folded and manipulated from any arbitrary position, and it can detect 2D stroke gestures.},
	urldate = {2025-07-11},
	booktitle = {Proceedings of the 2016 {CHI} {Conference} {Extended} {Abstracts} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Hamdan, Nur Al-huda and Heller, Florian and Wacharamanotham, Chat and Thar, Jan and Borchers, Jan},
	year = {2016},
	pages = {2497--2503},
	file = {Full Text PDF:C\:\\Users\\giand\\Zotero\\storage\\2ALCA48Z\\Hamdan et al. - 2016 - Grabrics A Foldable Two-Dimensional Textile Input Controller.pdf:application/pdf},
}

@book{barati_affordances_2019,
	title = {Affordances as {Materials} {Potential}:  {What} {Design} {Can} {Do} for {Materials} {Development}},
	url = {https://ijdesign.org/index.php/IJDesign/article/view/3419},
	abstract = {Given the growing interest in “upstream” collaborative projects between designers and materials scientists, it is crucial to scrutinize designers’ creative contribution to materials development beyond “coming up with” application ideas. Overcoming this outdated preconception requires a shift away from the dominant perspective of cognitive psychology that understands creativity as being in the designer’s mind, to an understanding of it as being distributed between the designer and the material world. Creativity as such requires designers’ active participation in “discovering” the novel potentials of materials rather than merely translating the “given” materials information to product applications. In this paper we propose the Materials Potential Framework to liberate materials from the stigma of a purely solutionist approach (e.g., materials selection and application potential), and open up the possibility to approach materials generatively, for all they have to offer (i.e., materials potential). To that aim, our paper explores existing notions in the discussions of materials potential, namely form, function, and experience as materials potential, and provides a conceptualization beyond the evident merits of product applications. The conceptualization of “affordances as material potentials” shifts the focus to designers’ skillful acts of making and fabricating as ways of unlocking novel affordances of conventional and emerging materials.},
	author = {Barati, Bahareh and Karana, Elvin},
	year = {2019},
	note = {Publication Title: 2019},
}

@MISC{JASP2025,
AUTHOR = {{JASP Team}},
TITLE = {{JASP (Version 0.19.3)[Computer software]}},
YEAR = {2025},
URL = {https://jasp-stats.org/}
}


@article{blackler_investigating_2010,
	title = {Investigating users’ intuitive interaction with complex artefacts},
	volume = {41},
	issn = {0003-6870},
	url = {https://www.sciencedirect.com/science/article/pii/S0003687009000593},
	doi = {10.1016/j.apergo.2009.04.010},
	abstract = {This paper examines the role of intuition in the way that people operate unfamiliar devices. Intuition is a type of cognitive processing that is often non-conscious and utilises stored experiential knowledge. Intuitive interaction involves the use of knowledge gained from other products and/or experiences. Two initial experimental studies revealed that prior exposure to products employing similar features helped participants to complete set tasks more quickly and intuitively, and that familiar features were intuitively used more often than unfamiliar ones. A third experiment confirmed that performance is affected by a person's level of familiarity with similar technologies, and also revealed that appearance (shape, size and labelling of features) seems to be the variable that most affects time spent on a task and intuitive uses during that time. Age also seems to have an effect. These results and their implications are discussed.},
	number = {1},
	urldate = {2025-07-12},
	journal = {Applied Ergonomics},
	author = {Blackler, Alethea and Popovic, Vesna and Mahar, Doug},
	month = jan,
	year = {2010},
	keywords = {Interface design, Intuitive interaction, Intuitive use, Observational analysis, Prior experience, Product design},
	pages = {72--92},
	file = {ScienceDirect Snapshot:C\:\\Users\\giand\\Zotero\\storage\\D5NZMTQU\\S0003687009000593.html:text/html},
}

@article{Bangor_SUS_2008,
author = {Aaron Bangor and Philip T. Kortum and James T. Miller},
title = {An Empirical Evaluation of the System Usability Scale},
journal = {International Journal of Human–Computer Interaction},
volume = {24},
number = {6},
pages = {574--594},
year = {2008},
publisher = {Taylor \& Francis},
doi = {10.1080/10447310802205776},
URL = {https://doi.org/10.1080/10447310802205776},
eprint = {https://doi.org/10.1080/10447310802205776}
}


@book{hassenzahl_experience_2010,
	address = {San Rafael},
	series = {Synthesis lectures on human-centered informatics},
	title = {Experience design: technology for all the right reasons},
	isbn = {978-1-60845-047-3 978-1-60845-048-0},
	shorttitle = {Experience design},
	language = {eng},
	publisher = {Morgan \& Claypool Publishers},
	editor = {Hassenzahl, Marc},
	year = {2010},
}

@misc{noauthor_din-9241-410_nodate,
	title = {{DIN} {EN} {ISO} 9241-410:2012-12, {Ergonomie} der {Mensch}-{System}-{Interaktion}\_- {Teil}\_410: {Gestaltungskriterien} für physikalische {Eingabegeräte} ({ISO}\_9241-410:2008\_+ {Amd}.1:2012); {Deutsche} {Fassung} {EN}\_ISO\_9241-410:2008\_+ {A1}:2012},
	shorttitle = {{DIN} {EN} {ISO} 9241-410},
	url = {https://www.dinmedia.de/de/-/-/152326163},
	doi = {10.31030/1890752},
	urldate = {2025-04-17},
	publisher = {DIN Media GmbH},
	file = {PDF:C\:\\Users\\giand\\Zotero\\storage\\LH53A6UH\\DIN EN ISO 9241-4102012-12, Ergonomie der Mensch-System-Interaktion_- Teil_410 Gestaltungskriterie.pdf:application/pdf},
}

@misc{noauthor_din-9241-110_nodate,
	address = {Berlin},
	title = {{DIN} {EN} {ISO} 9241-110:2020-10, {Ergonomie} der {Mensch}-{System}-{Interaktion}\_- {Teil}\_110: {Interaktionsprinzipien} ({ISO}\_9241-110:2020); {Deutsche} {Fassung} {EN}\_ISO\_9241-110:2020},
	shorttitle = {{DIN} {EN} {ISO} 9241-110},
	url = {https://www.dinmedia.de/de/-/-/320862700},
	doi = {10.31030/3147467},
	urldate = {2025-07-14},
	publisher = {DIN Media GmbH},
}


@inproceedings{challis_design_2001,
	title = {Design principles for tactile interaction},
	isbn = {978-3-540-44589-0},
	url = {https://link.springer.com/chapter/10.1007/3-540-44589-7_2},
	doi = {10.1007/3-540-44589-7_2},
	abstract = {Although the integration of tactile feedback within the humancomputer interface could have considerable benefits this channel of communication is often overlooked or, at most, employed on an ad hoc basis. One contributing factor to the reluctance of interface...},
	language = {en},
	urldate = {2025-07-16},
	booktitle = {Haptic {Human}-{Computer} {Interaction}},
	publisher = {Springer, Berlin, Heidelberg},
	author = {Challis, Ben P. and Edwards, Alistair D. N.},
	year = {2001},
	pages = {17--24},
	file = {Submitted Version:C\:\\Users\\giand\\Zotero\\storage\\BTRJD63V\\Challis and Edwards - 2001 - Design principles for tactile interaction.pdf:application/pdf},
}

@inproceedings{hamdan_grabbing_2016,
	address = {New York, NY, USA},
	series = {{ISWC} '16},
	title = {Grabbing at an angle: menu selection for fabric interfaces},
	isbn = {978-1-4503-4460-9},
	shorttitle = {Grabbing at an angle},
	url = {https://dl.acm.org/doi/10.1145/2971763.2971786},
	doi = {10.1145/2971763.2971786},
	abstract = {This paper investigates the pinch angle as a menu selection technique for two-dimensional foldable textile controllers. Based on the principles of marking menus, the selection of a menu item is performed by grabbing a fold at a specific angle, while changing value is performed by rolling the fold between the fingers. In a first experiment we determined an upper bound for the number of different angles users can reliably grab into a piece of fabric on their forearm. Our results show that users can, without looking at it, reliably grab fabric on their forearm with an average accuracy between 30° and 45°, which would provide up to six different menu options selectable with the initial pinch. In a second experiment, we show that our textile sensor, Grabrics, can detect fold angles at 45° spacing with up to 85\% accuracy. Our studies also found that user performance and workload are independent of the fabric types that were tested.},
	urldate = {2025-07-16},
	booktitle = {Proceedings of the 2016 {ACM} {International} {Symposium} on {Wearable} {Computers}},
	publisher = {Association for Computing Machinery},
	author = {Hamdan, Nur Al-huda and Blum, Jeffrey R. and Heller, Florian and Kosuru, Ravi Kanth and Borchers, Jan},
	month = sep,
	year = {2016},
	pages = {1--7},
	file = {Full Text PDF:C\:\\Users\\giand\\Zotero\\storage\\6BHD38XJ\\Hamdan et al. - 2016 - Grabbing at an angle menu selection for fabric interfaces.pdf:application/pdf},
}

@article{jacob_eye_1993,
	title = {Eye movement-based human-computer interaction techniques: {Toward} non-command interfaces},
	volume = {4},
	journal = {Advances in human-computer interaction},
	author = {Jacob, Robert JK},
	year = {1993},
	note = {Publisher: Ablex Norwood},
	pages = {151--190},
}

@inproceedings{kalantari_finding_2016,
	address = {New York, NY, USA},
	series = {{ISS} '16},
	title = {Finding the {Minimum} {Perceivable} {Size} of a {Tactile} {Element} on an {Ultrasonic} {Based} {Haptic} {Tablet}},
	isbn = {978-1-4503-4248-3},
	url = {https://dl.acm.org/doi/10.1145/2992154.2996785},
	doi = {10.1145/2992154.2996785},
	abstract = {Tactile devices with ultrasonic vibrations (based on squeeze film effect) using piezoelectric actuators are one of the existing haptic feedback technologies. In this study we have performed two psychophysical experiments on an ultrasonic haptic tablet, in order to find the minimum size of a tactile element on which all the users are able to perfectly identify different types of textures. Our results show that the spatial resolution of the tactile element on haptic touchscreen actually varies, depending on the number and types of tactile feedback information. A first experiment exhibits three different tactile textures, chosen as being easily recognized by users. We use these textures in a second experiment, and evaluate minimal spatial area on which the chosen set of textures can be recognized. Among other, we find the minimal size depends on the texture nature.},
	urldate = {2025-07-16},
	booktitle = {Proceedings of the 2016 {ACM} {International} {Conference} on {Interactive} {Surfaces} and {Spaces}},
	publisher = {Association for Computing Machinery},
	author = {Kalantari, Farzan and Grisoni, Laurent and Giraud, Frédéric and Rekik, Yosra},
	month = nov,
	year = {2016},
	pages = {379--384},
	file = {Full Text PDF:C\:\\Users\\giand\\Zotero\\storage\\YF6C2VAN\\Kalantari et al. - 2016 - Finding the Minimum Perceivable Size of a Tactile Element on an Ultrasonic Based Haptic Tablet.pdf:application/pdf},
}


@book{fashionary_textilepedia_2022,
	address = {Hong Kong},
	title = {Textilepedia: the complete fabric guide},
	isbn = {978-988-77110-9-4},
	shorttitle = {Textilepedia},
	abstract = {This is an encyclopaedia of textile information, from material to yarn, from fabric structure to the finishing process. Encompassing practical tips for a range of textiles and detailed visuals, this ultra-accessible manual is the perfect companion for fashion aficionados and aspiring fashion designers},
	language = {eng},
	publisher = {Fashionary},
	author = {{Fashionary}},
	year = {2022},
	keywords = {Started Reading/Skimmed},
}

@incollection{zuo_chapter_2014,
	address = {Boston},
	title = {Chapter 3 - {Tactile} {Aesthetics} of {Materials} and {Design}},
	isbn = {978-0-08-099359-1},
	url = {https://www.sciencedirect.com/science/article/pii/B9780080993591000035},
	abstract = {During the user-product interaction process, tactile feeling of materials plays a vital role. This chapter starts from understanding the essence of texture beyond the visual domain, explores the perception dimensions of material textures via the sense of touch, i.e., geometrical dimension, physical-chemical dimension, emotional dimension and associative dimension. The concept and method of optimum texture design will be discussed, where the correlations between the perception dimensions and the relationships between subjective feelings and underlying physical properties or parameters of materials are brought to attention. To bring the findings of the research into practical application within design projects, a material-aesthetics database has been developed.},
	urldate = {2025-07-17},
	booktitle = {Materials {Experience}},
	publisher = {Butterworth-Heinemann},
	author = {Zuo, Hengfeng and Hope, Tony and Jones, Mark},
	editor = {Karana, Elvin and Pedgley, Owain and Rognoli, Valentina},
	month = jan,
	year = {2014},
	doi = {10.1016/B978-0-08-099359-1.00003-5},
	keywords = {aesthetic experience, material texture, physical parameters, tactility, touch},
	pages = {27--37},
	file = {ScienceDirect Snapshot:C\:\\Users\\giand\\Zotero\\storage\\EHTYPJ49\\B9780080993591000035.html:text/html},
}

@misc{fried_phosphor_nodate,
	title = {Phosphor {Icons}},
	url = {https://phosphoricons.com},
	abstract = {A flexible icon family for interfaces, diagrams, presentations — whatever, really.},
	language = {en},
	urldate = {2025-07-17},
	journal = {Phosphor Icons},
	author = {Fried, Tobias and Zhang, Helena},
	file = {Snapshot:C\:\\Users\\giand\\Zotero\\storage\\FTPH5BGH\\phosphoricons.com.html:text/html},
}

@misc{kennedy_figtree_nodate,
	title = {Figtree – {Erik} {D}. {Kennedy}},
	url = {https://www.erikdkennedy.com/projects/figtree.html#download},
	urldate = {2025-07-17},
	journal = {Figtree},
	author = {Kennedy, Erik D.},
	file = {Figtree – Erik D. Kennedy:C\:\\Users\\giand\\Zotero\\storage\\JELRIUBH\\figtree.html:text/html},
}

@misc{seeed_studio_grove_2023,
	title = {Grove {Ecosystem} {Introduction} {\textbar} {Seeed} {Studio} {Wiki}},
	url = {https://wiki.seeedstudio.com/Grove_System/},
	abstract = {Grove Ecosystem Introduction},
	language = {en-US},
	urldate = {2025-07-18},
	journal = {Seeed Studio Wiki},
	author = {{Seeed Studio}},
	month = mar,
	year = {2023},
	file = {Snapshot:C\:\\Users\\giand\\Zotero\\storage\\RA52HWSN\\Grove_System.html:text/html},
}

@misc{seeed_studio_grove_2022,
	title = {Grove - {Servo} {\textbar} {Seeed} {Studio} {Wiki}},
	url = {https://wiki.seeedstudio.com/Grove-Servo/},
	abstract = {Grove - Servo is DC motor with gearing and feedback system. It is used in driving mechanism of robots. The module is a bonus product for Grove lovers. We regulated the three-wire servo into a Grove standard connector. You can plug and play it as a typical Grove module now, without jumper wires clutter.},
	language = {en-US},
	urldate = {2025-07-18},
	journal = {Seeed Studio Wiki},
	author = {{Seeed Studio}},
	month = jan,
	year = {2022},
}

@misc{seeed_studio_grove_2022-1,
	title = {Grove - {I2C} {Motor} {Driver} ({L298P}) {\textbar} {Seeed} {Studio} {Wiki}},
	url = {https://wiki.seeedstudio.com/Grove-I2C-Motor-Driver-L298P/},
	abstract = {Grove - I2C Motor Driver(L298P) is a common-use motor driver for stepping motor and servo motor. It embeds an STM32 chip for burning the code to control the},
	language = {en-US},
	urldate = {2025-07-18},
	journal = {Seeed Studio Wiki},
	author = {{Seeed Studio}},
	month = jan,
	year = {2022},
}

@misc{arduino_r3_2025,
	title = {{UNO} {R3} {\textbar} {Arduino} {Documentation}},
	url = {https://docs.arduino.cc/hardware/uno-rev3/},
	abstract = {The Arduino UNO is the best board to get started with electronics and coding. If this is your first experience tinkering with the platform, the UNO is the most robust board you can start playing with…},
	urldate = {2025-07-18},
	journal = {Arduino Documentation},
	author = {{Arduino}},
	year = {2025},
	file = {Snapshot:C\:\\Users\\giand\\Zotero\\storage\\26N37XVY\\uno-rev3.html:text/html},
}

@misc{dfrobot_turbo_2025,
	title = {Turbo {Metal} {Gear} {Worm} {Motor} ({6V} {40RPM} 10kg/cm) - {DFRobot}},
	url = {https://www.dfrobot.com/product-1481.html},
	urldate = {2025-07-18},
	journal = {DFRobot},
	author = {{DFRobot}},
	year = {2025},
	file = {Turbo Metal Gear Worm Motor (6V 40RPM 10kg/cm) - DFRobot:C\:\\Users\\giand\\Zotero\\storage\\4LX3JBEZ\\product-1481.html:text/html},
}

@misc{figma_figma_2025,
	title = {Figma: {The} {Collaborative} {Interface} {Design} {Tool}},
	shorttitle = {Figma},
	url = {https://www.figma.com/},
	abstract = {Figma is the leading collaborative design tool for building meaningful products. Seamlessly design, prototype, develop, and collect feedback in a single platform.},
	language = {en},
	urldate = {2025-07-18},
	journal = {Figma},
	author = {{Figma}},
	year = {2025},
}

@misc{studio_xid_protopie_2025,
	title = {{ProtoPie}: {Interactive} {Prototyping} {Tool}},
	url = {https://www.protopie.io/},
	urldate = {2025-07-18},
	journal = {ProtoPie},
	author = {{Studio XID}},
	year = {2025},
	file = {ProtoPie\: Interactive Prototyping Tool:C\:\\Users\\giand\\Zotero\\storage\\TU4UQDXU\\www.protopie.io.html:text/html},
}

@misc{blockdots_blokdots_2025,
	title = {blokdots},
	url = {https://blokdots.com/},
	abstract = {blokdots is a simple to use software to build interactive hardware prototypes without a line of code.},
	urldate = {2025-07-18},
	journal = {blokdots},
	author = {{blockdots}},
	year = {2025},
	file = {Snapshot:C\:\\Users\\giand\\Zotero\\storage\\WD2CFGPU\\blokdots.com.html:text/html},
}

@article{shneiderman_direct_1983,
	title = {Direct manipulation: {A} step beyond programming languages},
	volume = {16},
	number = {08},
	journal = {Computer},
	author = {Shneiderman, Ben},
	year = {1983},
	note = {Publisher: IEEE Computer Society},
	pages = {57--69},
}

@article{marcus_metaphor_1998,
	title = {Metaphor design in user interfaces},
	volume = {22},
	number = {2},
	journal = {ACM SIGDOC Asterisk Journal of Computer Documentation},
	author = {Marcus, Aaron},
	year = {1998},
	note = {Publisher: ACM New York, NY, USA},
	pages = {43--57},
}

@article{sandnes_smart_2007,
	title = {From smart light dimmers to the {IPOD}: text-input with circular gestures on wheel-controlled devices},
	volume = {1},
	number = {2},
	journal = {International Journal of Smart Home},
	author = {Sandnes, Frode Eika and Huang, Yo-Ping},
	year = {2007},
	note = {Publisher: Science and Engineering Research Support Society},
	pages = {97--108},
	file = {PDF:C\:\\Users\\giand\\Zotero\\storage\\REBEZBBU\\Sandnes and Huang - 2007 - From smart light dimmers to the IPOD text-input with circular gestures on wheel-controlled devices.pdf:application/pdf},
}

@incollection{neale_chapter_1997,
	address = {Amsterdam},
	title = {Chapter 20 - {The} {Role} of {Metaphors} in {User} {Interface} {Design}},
	isbn = {978-0-444-81862-1},
	url = {https://www.sciencedirect.com/science/article/pii/B9780444818621500868},
	abstract = {One common approach that designers have exploited for controlling complexity is to ground user interface actions, tasks, and goals in a familiar framework of concepts that are already understood. Such a framework is called a user interface metaphor. The extensive use of metaphors has had a dramatic impact on user interface design practices. Metaphors allow the transference or mapping of knowledge from a source domain to a target domain, enabling humans to use specific prior knowledge and experience for understanding and behaving in situations that are novel or unfamiliar. Through this process, one's knowledge in the target domain is enriched by borrowing existing representations from the source domain. The fact that the associations between the source and target are hidden is the essence of metaphor. The user interface of the computer is the target domain for interface metaphors. Interface metaphors help establish user expectations and encourage predictions about system behavior. A good example is the desktop metaphor. This metaphor portrays the operating system of the computer as similar to objects, tasks, and behaviors found in physical office environments. The desktop metaphor is actually a composite of many metaphors. Most systems have a global metaphor to provide the basis of interaction that is supported by many auxiliary metaphors. This chapter presents a variety of examples that illustrate the use of metaphor. The chapter reviews classifications of interface metaphor types. Mismatches between source and target domains and the circumstances that create them are also described in the chapter. This chapter discusses the role that metaphors have in communicating the designer's model, structuring users' models of the interface, and their impact on the human-machine communication process.},
	urldate = {2025-07-19},
	booktitle = {Handbook of {Human}-{Computer} {Interaction} ({Second} {Edition})},
	publisher = {North-Holland},
	author = {Neale, Dennis C. and Carroll, John M.},
	editor = {Helander, Marting G. and Landauer, Thomas K. and Prabhu, Prasad V.},
	month = jan,
	year = {1997},
	doi = {10.1016/B978-044481862-1.50086-8},
	pages = {441--462},
	file = {ScienceDirect Snapshot:C\:\\Users\\giand\\Zotero\\storage\\6KDA6CC3\\B9780444818621500868.html:text/html},
}

@incollection{carroll_chapter_1988,
	address = {Amsterdam},
	title = {Chapter 3 - {Interface} {Metaphors} and {User} {Interface} {Design}},
	isbn = {978-0-444-70536-5},
	url = {https://www.sciencedirect.com/science/article/pii/B9780444705365500087},
	abstract = {This chapter discusses interface metaphors and the user interface design. The integration of operational, structural, and pragmatic approaches to metaphors can provide guidance and a starting point for the design of a user interface that integrates a central metaphor, with a carefully analyzed similarity basis and a set of planned mismatches, with myriad other interface elements that support and exploit the matches and mismatches inhering in the metaphor. Metaphoric comparisons and interface presentations do more than render static denotative correspondences. They have motivational and affective consequences for users. They interact with and frame users' problem-solving efforts in learning about the target domain. Metaphors have been employed to increase the initial familiarity of the target domain, but they have an inevitable further role to play. The ultimate problem that the user should solve is to develop an understanding of the target domain itself—a mental model. Interface metaphors should also be viewed as tools proffered to users for articulating mental models.},
	urldate = {2025-07-19},
	booktitle = {Handbook of {Human}-{Computer} {Interaction}},
	publisher = {North-Holland},
	author = {Carroll, John M. and Mack, Robert L. and Kellogg, Wendy A.},
	editor = {Helander, MARTIN},
	month = jan,
	year = {1988},
	doi = {10.1016/B978-0-444-70536-5.50008-7},
	pages = {67--85},
	file = {ScienceDirect Snapshot:C\:\\Users\\giand\\Zotero\\storage\\GVEU24TZ\\B9780444705365500087.html:text/html},
}

@misc{nielsen_why_2000,
	title = {Why {You} {Only} {Need} to {Test} with 5 {Users}},
	url = {https://www.nngroup.com/articles/why-you-only-need-to-test-with-5-users/},
	abstract = {Elaborate usability tests are a waste of resources. The best results come from testing no more than 5 users and running as many small tests as you can afford.},
	language = {en},
	note = {Accessed on 19.07.2025},
	journal = {Nielsen Norman Group},
	author = {Nielsen, Jakob},
	month = mar,
	year = {2000},
	file = {Snapshot:C\:\\Users\\giand\\Zotero\\storage\\LJ52JNFR\\why-you-only-need-to-test-with-5-users.html:text/html},
}

@misc{nielsen_thinking_2012,
	title = {Thinking {Aloud}: {The} \#1 {Usability} {Tool}},
	shorttitle = {Thinking {Aloud}},
	url = {https://www.nngroup.com/articles/thinking-aloud-the-1-usability-tool/},
	abstract = {Simple usability tests where users think out loud are cheap, robust, flexible, and easy to learn. Thinking aloud should be the first tool in your UX toolbox, even though it entails some risks and doesn't solve all problems.},
	language = {en},
	note = {Accessed on 19.07.2025},
	journal = {Nielsen Norman Group},
	author = {Nielsen, Jakob},
	month = jan,
	year = {2012},
	file = {Snapshot:C\:\\Users\\giand\\Zotero\\storage\\229LLJS7\\thinking-aloud-the-1-usability-tool.html:text/html},
}

@misc{moran_usability_2019,
	title = {Usability ({User}) {Testing} 101},
	url = {https://www.nngroup.com/articles/usability-testing-101/},
	abstract = {UX researchers use this popular observational methodology to uncover problems and opportunities in designs.},
	language = {en},
	note = {Accessed on 19.07.2025},
	journal = {Nielsen Norman Group},
	author = {Moran, Kate},
	month = dec,
	year = {2019},
	file = {Snapshot:C\:\\Users\\giand\\Zotero\\storage\\T9CDA95V\\usability-testing-101.html:text/html},
}

@misc{budiu_quantitative_2017,
	title = {Quantitative vs. {Qualitative} {Usability} {Testing}},
	url = {https://www.nngroup.com/articles/quant-vs-qual/},
	abstract = {Qualitative research informs the design process; quantitative research provides a basis for benchmarking programs and ROI calculations.},
	language = {en},
	note = {Accessed on 19.07.2025},
	journal = {Nielsen Norman Group},
	author = {Budiu, Raluca},
	month = oct,
	year = {2017},
	file = {Snapshot:C\:\\Users\\giand\\Zotero\\storage\\4GR9GX6H\\quant-vs-qual.html:text/html},
}

@misc{fessenden_focus_2022,
	title = {Focus {Groups} 101},
	url = {https://www.nngroup.com/articles/focus-groups-definition/},
	abstract = {In a focus group, a facilitator solicits feedback from a small group of people. While insufficient as a standalone research method, data from a focus group still has value.},
	language = {en},
	note = {Accessed on 19.07.2025},
	journal = {Nielsen Norman Group},
	author = {Fessenden, Therese},
	month = jul,
	year = {2022},
	file = {Snapshot:C\:\\Users\\giand\\Zotero\\storage\\A6WXR5KK\\focus-groups-definition.html:text/html},
}

@misc{rosala_probing_2022,
	title = {Probing in {User} {Interviews} ({Video})},
	url = {https://www.nngroup.com/videos/probing-user-interviews/},
	abstract = {Follow-up questions in user interviews gather more detailed information from participants than they provided in their initial answers to our planned questions. This video provides examples of two main forms of probing questions.},
	language = {en},
	note = {Accessed on 19.07.2025},
	author = {Rosala, Maria and {Nielsen Norman Group}},
	month = jan,
	year = {2022},
	file = {Snapshot:C\:\\Users\\giand\\Zotero\\storage\\U6GIBT3Q\\probing-user-interviews.html:text/html},
}

@misc{budiu_ux_2023,
	title = {{UX} {Research} {Methods}: {Glossary} - {Participatory} {Design}},
	shorttitle = {{UX} {Research} {Methods}},
	url = {https://www.nngroup.com/articles/research-methods-glossary/#Participatory%20Design},
	abstract = {Use this glossary to quickly clarify key terms and concepts related to research methods in UX.},
	language = {en},
	note = {Accessed on 19.07.2025},
	journal = {Nielsen Norman Group},
	author = {Budiu, Raluca},
	month = sep,
	year = {2023},
	file = {Snapshot:C\:\\Users\\giand\\Zotero\\storage\\GP7H5XFF\\research-methods-glossary.html:text/html},
}

@article{nakayama_inattentional_1999,
	title = {Inattentional {Blindness}: by {Arien} {Mack} and {Irvine} {Rock}},
	volume = {3},
	number = {1},
	journal = {Trends in Cognitive Sciences},
	author = {Nakayama, Ken},
	year = {1999},
	note = {Publisher: Elsevier},
	pages = {39},
}

@article{simons_gorillas_1999,
	title = {Gorillas in {Our} {Midst}: {Sustained} {Inattentional} {Blindness} for {Dynamic} {Events}},
	volume = {28},
	issn = {0301-0066},
	shorttitle = {Gorillas in {Our} {Midst}},
	url = {https://doi.org/10.1068/p281059},
	doi = {10.1068/p281059},
	abstract = {With each eye fixation, we experience a richly detailed visual world. Yet recent work on visual integration and change direction reveals that we are surprisingly unaware of the details of our environment from one view to the next: we often do not detect large changes to objects and scenes (‘change blindness’). Furthermore, without attention, we may not even perceive objects (‘inattentional blindness’). Taken together, these findings suggest that we perceive and remember only those objects and details that receive focused attention. In this paper, we briefly review and discuss evidence for these cognitive forms of ‘blindness’. We then present a new study that builds on classic studies of divided visual attention to examine inattentional blindness for complex objects and events in dynamic scenes. Our results suggest that the likelihood of noticing an unexpected object depends on the similarity of that object to other objects in the display and on how difficult the priming monitoring task is. Interestingly, spatial proximity of the critical unattended object to attended locations does not appear to affect detection, suggesting that observers attend to objects and events, not spatial positions. We discuss the implications of these results for visual representations and awareness of our visual environment.},
	language = {EN},
	number = {9},
	urldate = {2025-07-21},
	journal = {Perception},
	author = {Simons, Daniel J and Chabris, Christopher F},
	month = sep,
	year = {1999},
	note = {Publisher: SAGE Publications Ltd STM},
	pages = {1059--1074},
}

@misc{google_sound_2025,
	title = {Sound {Resources} - {Material} {Design}},
	url = {https://m2.material.io/design/sound/sound-resources.html#},
	abstract = {Download Material Design audio files here.},
	language = {en},
	urldate = {2025-07-23},
	journal = {Material Design},
	author = {{Google}},
	year = {2025},
	file = {Snapshot:C\:\\Users\\giand\\Zotero\\storage\\Z7MXEZ29\\sound-resources.html:text/html},
}

@article{wickens_multiple_2008,
	title = {Multiple {Resources} and {Mental} {Workload}},
	volume = {50},
	copyright = {https://journals.sagepub.com/page/policies/text-and-data-mining-license},
	issn = {0018-7208, 1547-8181},
	url = {https://journals.sagepub.com/doi/10.1518/001872008X288394},
	doi = {10.1518/001872008x288394},
	abstract = {Objective: The objective is to lay out the rationale for multiple resource theory and the particular 4-D multiple resource model, as well as to show how the model is useful both as a design tool and as a means of predicting multitask workload overload. Background: I describe the discoveries and developments regarding multiple resource theory that have emerged over the past 50 years that contribute to performance and workload prediction. Method: The article presents a history of the multiple resource concept, a computational version of the multiple resource model applied to multitask driving simulation data, and the relation of multiple resources to workload. Results: Research revealed the importance of the four dimensions in accounting for task interference and the association of resources with brain structure. Multiple resource models yielded high correlations between model predictions and data. Lower correlations also identified the existence of additional resources. Conclusion: The model was shown to be partially relevant to the concept of mental workload, with greatest relevance to performance breakdowns related to dual-task overload. Future challenges are identified. Application: The most important application of the multiple resource model is to recommend design changes when conditions of multitask resource overload exist.},
	language = {en},
	number = {3},
	urldate = {2025-07-23},
	journal = {Human Factors: The Journal of the Human Factors and Ergonomics Society},
	author = {Wickens, Christopher D.},
	month = jun,
	year = {2008},
	note = {Publisher: SAGE Publications},
	pages = {449--455},
}

@misc{team_ueq_ueq_2024,
	title = {{UEQ} - {User} {Experience} {Questionnaire}},
	url = {https://www.ueq-online.org/},
	urldate = {2025-04-05},
	author = {{Team UEQ}},
	year = {2024},
	file = {PDF:C\:\\Users\\giand\\Zotero\\storage\\YMX6J3JN\\Team UEQ - 2024 - UEQ - User Experience Questionnaire.pdf:application/pdf},
}

@inproceedings{laugwitz_construction_2008,
	title = {Construction and {Evaluation} of a {User} {Experience} {Questionnaire}},
	isbn = {978-3-540-89350-9},
	url = {https://link.springer.com/chapter/10.1007/978-3-540-89350-9_6},
	doi = {10.1007/978-3-540-89350-9_6},
	abstract = {An end-user questionnaire to measure user experience quickly in a simple and immediate way while covering a preferably comprehensive impression of the product user experience was the goal of the reported construction process. An empirical approach for the item...},
	language = {en},
	urldate = {2025-04-05},
	booktitle = {{HCI} and {Usability} for {Education} and {Work}},
	publisher = {Springer, Berlin, Heidelberg},
	author = {Laugwitz, Bettina and Held, Theo and Schrepp, Martin},
	year = {2008},
	note = {ISSN: 1611-3349},
	pages = {63--76},
	file = {PDF:C\:\\Users\\giand\\Zotero\\storage\\9NASHFPM\\Laugwitz et al. - 2008 - Construction and Evaluation of a User Experience Questionnaire.pdf:application/pdf},
}

@inproceedings{schrepp_applying_2014,
	title = {Applying the {User} {Experience} {Questionnaire} ({UEQ}) in {Different} {Evaluation} {Scenarios}},
	isbn = {978-3-319-07668-3},
	url = {https://link.springer.com/chapter/10.1007/978-3-319-07668-3_37},
	doi = {10.1007/978-3-319-07668-3_37},
	abstract = {A good user experience is central for the success of interactive products. To improve products concerning these quality aspects it is thus also important to be able to measure user experience in an efficient and reliable way. But measuring user experience is not an...},
	language = {en},
	urldate = {2025-04-05},
	booktitle = {Design, {User} {Experience}, and {Usability}. {Theories}, {Methods}, and {Tools} for {Designing} the {User} {Experience}},
	publisher = {Springer, Cham},
	author = {Schrepp, Martin and Hinderks, Andreas and Thomaschewski, Jörg},
	year = {2014},
	note = {ISSN: 1611-3349},
	pages = {383--392},
	file = {Full Text PDF:C\:\\Users\\giand\\Zotero\\storage\\7EX56HI6\\Schrepp et al. - 2014 - Applying the User Experience Questionnaire (UEQ) in Different Evaluation Scenarios.pdf:application/pdf},
}

@incollection{brooke_sus_1996,
	title = {{SUS}: {A} '{Quick} and {Dirty}' {Usability} {Scale}},
	isbn = {978-0-429-15701-1},
	shorttitle = {{SUS}},
	abstract = {Usability is not a quality that exists in any real or absolute sense. Perhaps it can be 
best summed up as being a general quality of the appropriateness to a purpose of 
any particular artefact. This notion is neatly summed up by Terry Pratchett in his 
novel Moving Pictures:In just the same way, the usability of any tool or system has to be viewed in terms 
of the context in which it is used, and its appropriateness to that context. With 
particular reference to information systems, this view of usability is reflected in the 
current draft international standard ISO 9241-11 and in the European Community 
ESPRIT project MUSiC (Measuring Usability of Systems in Context) (e.g. Bevan 
et al., 1991). In general, it is impossible to specify the usability of a system (i.e. its 
fitness for purpose) without first defining who are the intended users of the system, 
the tasks those users will perform with it, and the characteristics of the physical, 
organizational and social environment in which it will be used.},
	booktitle = {Usability {Evaluation} {In} {Industry}},
	publisher = {CRC Press},
	author = {Brooke, john},
	year = {1996},
	note = {Num Pages: 6},
	file = {PDF:C\:\\Users\\giand\\Zotero\\storage\\EXYBGUE3\\Brooke - 1996 - SUS A 'Quick and Dirty' Usability Scale.pdf:application/pdf},
}

@incollection{hassenzahl_attrakdiff_2003,
	title = {{AttrakDiff}: {Ein} {Fragebogen} zur {Messung} wahrgenommener hedonischer und pragmatischer {Qualität}},
	isbn = {978-3-322-80058-9},
	shorttitle = {{AttrakDiff}},
	url = {https://link.springer.com/chapter/10.1007/978-3-322-80058-9_19},
	abstract = {Die Evaluation interaktiver Produkte ist eine wichtige Aktivit\&\#228;t im Rahmen benutzerzentrierter Gestaltung. Eine Evaluationstechnik, die sich meist auf die Nutzungsqualit\&\#228;t oder \&\#8222;Gebrauchstauglichkeit\&\#8220; eines Produkts konzentriert, stellen...},
	
	urldate = {2025-04-05},
	booktitle = {Mensch \& {Computer} 2003},
	publisher = {Vieweg+Teubner Verlag},
	author = {Hassenzahl, Marc and Burmester, Michael and Koller, Franz},
	year = {2003},
	doi = {10.1007/978-3-322-80058-9_19},
	pages = {187--196},
	file = {Full Text PDF:C\:\\Users\\giand\\Zotero\\storage\\YVQ8RGQG\\Hassenzahl et al. - 2003 - AttrakDiff Ein Fragebogen zur Messung wahrgenommener hedonischer und pragmatischer Qualität.pdf:application/pdf},
}

@inproceedings{klapperich_hotzenplotz_2016,
	address = {New York, NY, USA},
	series = {{NordiCHI} '16},
	title = {Hotzenplotz: {Reconciling} {Automation} with {Experience}},
	isbn = {978-1-4503-4763-1},
	shorttitle = {Hotzenplotz},
	url = {https://dl.acm.org/doi/10.1145/2971485.2971532},
	doi = {10.1145/2971485.2971532},
	abstract = {Technology is able to free people from daily chores and to empower activities, which had not been possible before. At the same time, technology, especially automation, causes many mundane and potentially meaningful activities to disappear. In this sense, each convenient "enhancement" could also be understood as an experiential "amputation." This paper presents an exploration of an approach to automation, which seeks to reconcile the advantages of automation with meaningful experience. Hotzenplotz is an electrical coffee grinder combined with a functionally unnecessary manual interaction to create meaning. We empirically compared Hotzenplotz to an off-the-shelf manual and electrical grinder and found the resulting experience to be more fulfilling than the electric grinder and at least as fulfilling as the manual grinder, in terms of, for example, affective experience, meaning, and fulfillment of psychological needs. Hotzenplotz as a viable example of the subtle role an experience-oriented approach to the design of technology can play in shaping our everyday lives.},
	urldate = {2025-04-06},
	booktitle = {Proceedings of the 9th {Nordic} {Conference} on {Human}-{Computer} {Interaction}},
	publisher = {Association for Computing Machinery},
	author = {Klapperich, Holger and Hassenzahl, Marc},
	year = {2016},
	pages = {1--10},
	file = {Full Text PDF:C\:\\Users\\giand\\Zotero\\storage\\UIVVH26M\\Klapperich and Hassenzahl - 2016 - Hotzenplotz Reconciling Automation with Experience.pdf:application/pdf},
}

@article{hassenzahl_experience-oriented_2015,
	title = {Experience-{Oriented} and {Product}-{Oriented} {Evaluation}: {Psychological} {Need} {Fulfillment}, {Positive} {Affect}, and {Product} {Perception}},
	volume = {31},
	issn = {1044-7318},
	shorttitle = {Experience-{Oriented} and {Product}-{Oriented} {Evaluation}},
	url = {https://www.tandfonline.com/doi/full/10.1080/10447318.2015.1064664},
	doi = {10.1080/10447318.2015.1064664},
	number = {8},
	urldate = {2025-04-06},
	journal = {International Journal of Human–Computer Interaction},
	author = {Hassenzahl, Marc and , Annika, Wiklund-Engblom and , Anette, Bengs and , Susanne, Hägglund and and Diefenbach, Sarah},
	month = aug,
	year = {2015},
	note = {Publisher: Taylor \& Francis},
	pages = {530--544},
	file = {PDF:C\:\\Users\\giand\\Zotero\\storage\\8D97TGVR\\Hassenzahl et al. - 2015 - Experience-Oriented and Product-Oriented Evaluation Psychological Need Fulfillment, Positive Affect.pdf:application/pdf},
}

@article{hassenzahl_needs_2010,
	title = {Needs, affect, and interactive products – {Facets} of user experience},
	volume = {22},
	issn = {0953-5438},
	url = {https://doi.org/10.1016/j.intcom.2010.04.002},
	doi = {10.1016/j.intcom.2010.04.002},
	abstract = {Subsumed under the umbrella of User Experience (UX), practitioners and academics of Human–Computer Interaction look for ways to broaden their understanding of what constitutes “pleasurable experiences” with technology. The present study considered the fulfilment of universal psychological needs, such as competence, relatedness, popularity, stimulation, meaning, security, or autonomy, to be the major source of positive experience with interactive technologies. To explore this, we collected over 500 positive experiences with interactive products (e.g., mobile phones, computers). As expected, we found a clear relationship between need fulfilment and positive affect, with stimulation, relatedness, competence and popularity being especially salient needs. Experiences could be further categorized by the primary need they fulfil, with apparent qualitative differences among some of the categories in terms of the emotions involved. Need fulfilment was clearly linked to hedonic quality perceptions, but not as strongly to pragmatic quality (i.e., perceived usability), which supports the notion of hedonic quality as “motivator” and pragmatic quality as “hygiene factor.” Whether hedonic quality ratings reflected need fulfilment depended on the belief that the product was responsible for the experience (i.e., attribution).},
	number = {5},
	urldate = {2025-04-06},
	journal = {Interacting with Computers},
	author = {Hassenzahl, Marc and Diefenbach, Sarah and Göritz, Anja},
	month = sep,
	year = {2010},
	pages = {353--362},
	file = {PDF:C\:\\Users\\giand\\Zotero\\storage\\YGPZU2W9\\Hassenzahl et al. - 2010 - Needs, affect, and interactive products – Facets of user experience.pdf:application/pdf;Snapshot:C\:\\Users\\giand\\Zotero\\storage\\HBN5YICN\\684432.html:text/html},
}

@article{sheldon_what_2001,
	title = {What is satisfying about satisfying events? {Testing} 10 candidate psychological needs},
	volume = {80},
	issn = {1939-1315},
	shorttitle = {What is satisfying about satisfying events?},
	doi = {10.1037/0022-3514.80.2.325},
	abstract = {Three studies compared 10 candidate psychological needs in an attempt to determine which are truly most fundamental for humans. Participants described "most satisfying events" within their lives and then rated the salience of each of the 10 candidate needs within these events. Supporting self-determination theory postulates (Ryan \& Deci, 2000)—autonomy, competence, and relatedness, were consistently among the top 4 needs, in terms of both their salience and their association with event-related affect. Self-esteem was also important, whereas self-actualization or meaning, physical thriving, popularity or influence, and money–luxury were less important. This basic pattern emerged within three different time frames and within both U.S. and South Korean samples and also within a final study that asked, "What's unsatisfying about unsatisfying events?" Implications for hierarchical theories of needs are discussed. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
	number = {2},
	journal = {Journal of Personality and Social Psychology},
	author = {Sheldon, Kennon M. and Elliot, Andrew J. and Kim, Youngmee and Kasser, Tim},
	year = {2001},
	note = {Place: US
Publisher: American Psychological Association},
	keywords = {Competence, Cross Cultural Differences, Independence (Personality), Life Experiences, Life Satisfaction, Personality, Psychological Needs, Satisfaction, Self-Concept, Self-Determination, Self-Esteem},
	pages = {325--339},
	file = {Snapshot:C\:\\Users\\giand\\Zotero\\storage\\AGIRDIWV\\2001-16163-011.html:text/html;Submitted Version:C\:\\Users\\giand\\Zotero\\storage\\42KIGHZQ\\Sheldon et al. - 2001 - What is satisfying about satisfying events Testing 10 candidate psychological needs.pdf:application/pdf},
}

@article{watson_development_1988,
	title = {Development and validation of brief measures of positive and negative affect: {The} {PANAS} scales},
	volume = {54},
	issn = {1939-1315},
	shorttitle = {Development and validation of brief measures of positive and negative affect},
	doi = {10.1037/0022-3514.54.6.1063},
	abstract = {In recent studies of the structure of affect, positive and negative affect have consistently emerged as two dominant and relatively independent dimensions. A number of mood scales have been created to measure these factors; however, many existing measures are inadequate, showing low reliability or poor convergent or discriminant validity. To fill the need for reliable and valid Positive Affect and Negative Affect scales that are also brief and easy to administer, we developed two 10-item mood scales that comprise the Positive and Negative Affect Schedule (PANAS). The scales are shown to be highly internally consistent, largely uncorrelated, and stable at appropriate levels over a 2-month time period. Normative data and factorial and external evidence of convergent and discriminant validity for the scales are also presented. (PsycINFO Database Record (c) 2017 APA, all rights reserved)},
	number = {6},
	journal = {Journal of Personality and Social Psychology},
	author = {Watson, David and Clark, Lee Anna and Tellegen, Auke},
	year = {1988},
	note = {Place: US
Publisher: American Psychological Association},
	keywords = {Emotional States, Measurement, Test Construction, Test Reliability, Test Validity},
	pages = {1063--1070},
	file = {PDF:C\:\\Users\\giand\\Zotero\\storage\\FNB9V2RZ\\Watson et al. - 1988 - Development and validation of brief measures of positive and negative affect The PANAS scales.pdf:application/pdf;Snapshot:C\:\\Users\\giand\\Zotero\\storage\\APTYIE35\\1988-31508-001.html:text/html},
}

@article{thompson_development_2007,
	title = {Development and {Validation} of an {Internationally} {Reliable} {Short}-{Form} of the {Positive} and {Negative} {Affect} {Schedule} ({PANAS})},
	volume = {38},
	issn = {0022-0221},
	url = {https://doi.org/10.1177/0022022106297301},
	doi = {10.1177/0022022106297301},
	abstract = {This article reports the development and validation of a 10-item international Positive and Negative Affect Schedule (PANAS) Short Form (I-PANAS-SF) in English. A qualitative study (N = 18) and then an exploratory quantitative study (N = 407), each using informants from a range of cultural backgrounds, were used to identify systematically which 10 of the original 20 PANAS items to retain or remove. A same-sample retest study (N = 163) was used in an initial examination of the new 10-item international PANAS's psychometric properties and to assess its correlation with the full, 20-item, original PANAS. In a series of further validation studies (N = 1,789), the cross-sample stability, internal reliability, temporal stability, cross-cultural factorial invariance, and convergent and criterion-related validities of the I-PANAS-SF were examined and found to be psychometrically acceptable.},
	language = {EN},
	number = {2},
	urldate = {2025-04-06},
	journal = {Journal of Cross-Cultural Psychology},
	author = {Thompson, Edmund R.},
	month = mar,
	year = {2007},
	note = {Publisher: SAGE Publications Inc},
	pages = {227--242},
	file = {SAGE PDF Full Text:C\:\\Users\\giand\\Zotero\\storage\\RY8GJNIT\\Thompson - 2007 - Development and Validation of an Internationally Reliable Short-Form of the Positive and Negative Af.pdf:application/pdf},
}

@article{kercher_assessing_1992,
	title = {Assessing {Subjective} {Well}-{Being} in the {Old}-{Old}: {The} {PANAS} as a {Measure} of {Orthogonal} {Dimensions} of {Positive} and {Negative} {Affect}},
	volume = {14},
	issn = {0164-0275},
	shorttitle = {Assessing {Subjective} {Well}-{Being} in the {Old}-{Old}},
	url = {https://doi.org/10.1177/0164027592142001},
	doi = {10.1177/0164027592142001},
	abstract = {A review of past research reveals apparent gaps in many current measures of positive affect (PA) and negative affect (NA) including the Bradburn (1969) Affect Balance subscales popular among gerontologists and other social scientists. In many cases, the measures produce PA/NA correlations so high that some researchers claim subjective well-being is unidimensional. A viable alternative measure of positive and negative affect is the PANAS (Watson, Clark, and Tellegen 1988), which appears to distinguish clearly between these two emotional dimensions of subjective well-being. Unfortunately, however, only younger samples have served as subjects in research on the PANAS. Accordingly, the current study assessed the psychometric qualities of the PANAS applied to a sample of the old-old. Consistent with prior studies of younger samples, the results here clearly support the viability of the measure among the elderly. Of particular significance, the PA and NA dimensions appear completely independent of each other. More broadly, the results also support using the circumplex model of emotions when selecting mood adjectives to represent the affective dimensions of subjective well-being.},
	language = {EN},
	number = {2},
	urldate = {2025-04-06},
	journal = {Research on Aging},
	author = {Kercher, Kyle},
	month = jun,
	year = {1992},
	note = {Publisher: SAGE Publications Inc},
	pages = {131--168},
	file = {SAGE PDF Full Text:C\:\\Users\\giand\\Zotero\\storage\\XJMBPVVI\\Kercher - 1992 - Assessing Subjective Well-Being in the Old-Old The PANAS as a Measure of Orthogonal Dimensions of P.pdf:application/pdf},
}

@article{bradley_measuring_1994,
	title = {Measuring emotion: {The} self-assessment manikin and the semantic differential},
	volume = {25},
	issn = {0005-7916},
	shorttitle = {Measuring emotion},
	url = {https://www.sciencedirect.com/science/article/pii/0005791694900639},
	doi = {10.1016/0005-7916(94)90063-9},
	abstract = {The Self-Assessment Manikin (SAM) is a non-verbal pictorial assessment technique that directly measures the pleasure, arousal, and dominance associated with a person's affective reaction to a wide variety of stimuli. In this experiment, we compare reports of affective experience obtained using SAM, which requires only three simple judgments, to the Semantic Differential scale devised by Mehrabian and Russell (An approach to environmental psychology, 1974) which requires 18 different ratings. Subjective reports were measured to a series of pictures that varied in both affective valence and intensity. Correlations across the two rating methods were high both for reports of experienced pleasure and felt arousal. Differences obtained in the dominance dimension of the two instruments suggest that SAM may better track the personal response to an affective stimulus. SAM is an inexpensive, easy method for quickly assessing reports of affective response in many contexts.},
	number = {1},
	urldate = {2025-04-06},
	journal = {Journal of Behavior Therapy and Experimental Psychiatry},
	author = {Bradley, Margaret M. and Lang, Peter J.},
	month = mar,
	year = {1994},
	pages = {49--59},
	file = {PDF:C\:\\Users\\giand\\Zotero\\storage\\9U5UN323\\Bradley and Lang - 1994 - Measuring emotion The self-assessment manikin and the semantic differential.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\giand\\Zotero\\storage\\M3CY2S68\\0005791694900639.html:text/html},
}

@article{russell_affect_1989,
	title = {Affect {Grid}: {A} single-item scale of pleasure and arousal},
	volume = {57},
	issn = {1939-1315},
	shorttitle = {Affect {Grid}},
	doi = {10.1037/0022-3514.57.3.493},
	abstract = {This article introduces a single-item scale, the Affect Grid, designed as a quick means of assessing affect along the dimensions of pleasure–displeasure and arousal–sleepiness. The Affect Grid is potentially suitable for any study that requires judgments about affect of either a descriptive or a subjective kind. The scale was shown to have adequate reliability, convergent validity, and discriminant validity in 4 studies in which college students used the Affect Grid to describe (a) their current mood, (b) the meaning of emotion-related words, and (c) the feelings conveyed by facial expressions. Other studies (e.g., J. Snodgrass et al; see record 1989-13842-001) are cited to illustrate the potential uses of the Affect Grid as a measure of mood. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
	number = {3},
	journal = {Journal of Personality and Social Psychology},
	author = {Russell, James A. and Weiss, Anna and Mendelsohn, Gerald A.},
	year = {1989},
	note = {Place: US
Publisher: American Psychological Association},
	keywords = {Test Reliability, Test Validity, Physiological Arousal, Pleasure, Rating Scales},
	pages = {493--502},
	file = {PDF:C\:\\Users\\giand\\Zotero\\storage\\YW3WRSER\\Russell et al. - 1989 - Affect Grid A single-item scale of pleasure and arousal.pdf:application/pdf;Snapshot:C\:\\Users\\giand\\Zotero\\storage\\MU96LL37\\1990-00158-001.html:text/html},
}

@article{venkatesh_technology_2008,
	title = {Technology {Acceptance} {Model} 3 and a {Research} {Agenda} on {Interventions}},
	volume = {39},
	copyright = {© 2008, The Author Journal compilation © 2008, Decision Sciences Institute},
	issn = {1540-5915},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1540-5915.2008.00192.x},
	doi = {10.1111/j.1540-5915.2008.00192.x},
	abstract = {Prior research has provided valuable insights into how and why employees make a decision about the adoption and use of information technologies (ITs) in the workplace. From an organizational point of view, however, the more important issue is how managers make informed decisions about interventions that can lead to greater acceptance and effective utilization of IT. There is limited research in the IT implementation literature that deals with the role of interventions to aid such managerial decision making. Particularly, there is a need to understand how various interventions can influence the known determinants of IT adoption and use. To address this gap in the literature, we draw from the vast body of research on the technology acceptance model (TAM), particularly the work on the determinants of perceived usefulness and perceived ease of use, and: (i) develop a comprehensive nomological network (integrated model) of the determinants of individual level (IT) adoption and use; (ii) empirically test the proposed integrated model; and (iii) present a research agenda focused on potential pre- and postimplementation interventions that can enhance employees' adoption and use of IT. Our findings and research agenda have important implications for managerial decision making on IT implementation in organizations.},
	language = {en},
	number = {2},
	urldate = {2025-04-06},
	journal = {Decision Sciences},
	author = {Venkatesh, Viswanath and Bala, Hillol},
	year = {2008},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1540-5915.2008.00192.x},
	keywords = {and User Participation, Design Characteristics, Interventions, Management Support, Organizational Support, Peer Support, Technology Acceptance Model (TAM), Technology Adoption, Training, User Acceptance, User Involvement},
	pages = {273--315},
	file = {Full Text PDF:C\:\\Users\\giand\\Zotero\\storage\\WHBATA2V\\Venkatesh and Bala - 2008 - Technology Acceptance Model 3 and a Research Agenda on Interventions.pdf:application/pdf;Snapshot:C\:\\Users\\giand\\Zotero\\storage\\U9SFF5FW\\j.1540-5915.2008.00192.html:text/html},
}

@article{venkatesh_consumer_2012,
	title = {Consumer {Acceptance} and {Use} of {Information} {Technology}: {Extending} the {Unified} {Theory} of {Acceptance} and {Use} of {Technology}},
	volume = {36},
	issn = {0276-7783},
	shorttitle = {Consumer {Acceptance} and {Use} of {Information} {Technology}},
	url = {https://www.jstor.org/stable/41410412},
	doi = {10.2307/41410412},
	abstract = {This paper extends the unified theory of acceptance and use of technology (UTAUT) to study acceptance and use of technology in a consumer context. Our proposed UTAUT2 incorporates three constructs into UTAUT: hedonic motivation, price value, and habit. Individual differences — namely, age, gender, and experience — are hypothesized to moderate the effects of these constructs on behavioral intention and technology use. Results from a two-stage online survey, with technology use data collected four months after the first survey, of 1,512 mobile Internet consumers supported our model Compared to UTAUT, the extensions proposed in UTAUT2 produced a substantial improvement in the variance explained in behavioral intention (56 percent to 74 percent) and technology use (40 percent to 52 percent). The theoretical and managerial implications of these results are discussed.},
	number = {1},
	urldate = {2025-04-06},
	journal = {MIS Quarterly},
	author = {Venkatesh, Viswanath and Thong, James Y. L. and Xu, Xin},
	year = {2012},
	note = {Publisher: Management Information Systems Research Center, University of Minnesota},
	pages = {157--178},
	file = {PDF:C\:\\Users\\giand\\Zotero\\storage\\DG6NK24A\\Venkatesh et al. - 2012 - Consumer Acceptance and Use of Information Technology Extending the Unified Theory of Acceptance an.pdf:application/pdf},
}

@misc{noauthor_pdf_nodate,
	title = {({PDF}) {FSS} - {Flow} {Short} {Scale} ( {English} {Version})},
	url = {https://www.researchgate.net/publication/373975862_FSS_-_Flow_Short_Scale_English_Version},
	abstract = {PDF {\textbar} Diagnostic objective The FSS is used to measure the flow state and can be used in different contexts such as computer games or in experimental... {\textbar} Find, read and cite all the research you need on ResearchGate},
	language = {en},
	urldate = {2025-04-07},
	journal = {ResearchGate},
	file = {PDF:C\:\\Users\\giand\\Zotero\\storage\\ZKD4DXSJ\\(PDF) FSS - Flow Short Scale ( English Version).pdf:application/pdf;Snapshot:C\:\\Users\\giand\\Zotero\\storage\\4IBAXPGI\\373975862_FSS_-_Flow_Short_Scale_English_Version.html:text/html},
}

@incollection{hart_development_1988,
	series = {Human {Mental} {Workload}},
	title = {Development of {NASA}-{TLX} ({Task} {Load} {Index}): {Results} of {Empirical} and {Theoretical} {Research}},
	volume = {52},
	shorttitle = {Development of {NASA}-{TLX} ({Task} {Load} {Index})},
	url = {https://www.sciencedirect.com/science/article/pii/S0166411508623869},
	abstract = {The results of a multi-year research program to identify the factors associated with variations in subjective workload within and between different types of tasks are reviewed. Subjective evaluations of 10 workload-related factors were obtained from 16 different experiments. The experimental tasks included simple cognitive and manual control tasks, complex laboratory and supervisory control tasks, and aircraft simulation. Task-, behavior-, and subject-related correlates of subjective workload experiences varied as a function of difficulty manipulations within experiments, different sources of workload between experiments, and individual differences in workload definition. A multi-dimensional rating scale is proposed in which information about the magnitude and sources of six workload-related factors are combined to derive a sensitive and reliable estimate of workload.},
	urldate = {2025-04-07},
	booktitle = {Advances in {Psychology}},
	publisher = {North-Holland},
	author = {Hart, Sandra G. and Staveland, Lowell E.},
	editor = {Hancock, Peter A. and Meshkati, Najmedin},
	month = jan,
	year = {1988},
	doi = {10.1016/S0166-4115(08)62386-9},
	pages = {139--183},
	file = {PDF:C\:\\Users\\giand\\Zotero\\storage\\H9RHSLBJ\\Hart and Staveland - 1988 - Development of NASA-TLX (Task Load Index) Results of Empirical and Theoretical Research.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\giand\\Zotero\\storage\\ESZN4MXX\\S0166411508623869.html:text/html},
}

@misc{noauthor_nasa-task_nodate,
	title = {Nasa-{Task} {Load} {Index} ({NASA}-{TLX}); 20 {Years} {Later} - {Sandra} {G}. {Hart}, 2006},
	url = {https://journals-sagepub-com.thi.idm.oclc.org/doi/abs/10.1177/154193120605000909?casa_token=G7z5Vq3INigAAAAA:QyKKbtlePgVqrGCpeWSbjnIzFqHeEIlUk1KaZcYob3o-3dYffJkJiHzxJqk5g0wdkYlqZCrU7x4&casa_token=R-Brkvj0uhkAAAAA:I2xXyzM-MntGeISB0ZszH-V7cAZV6gq1XyTeCmVaqrtPw8MDTXBteLDMfGF_nGJS3p__Wp9Oi90},
	urldate = {2025-04-07},
	file = {Nasa-Task Load Index (NASA-TLX)\; 20 Years Later - Sandra G. Hart, 2006:C\:\\Users\\giand\\Zotero\\storage\\U9S4VASR\\154193120605000909.html:text/html;PDF:C\:\\Users\\giand\\Zotero\\storage\\2D95WJXU\\Nasa-Task Load Index (NASA-TLX)\; 20 Years Later - Sandra G. Hart, 2006.pdf:application/pdf},
}

@misc{noauthor_tlx_nodate,
	title = {{TLX} @ {NASA} {Ames} - {Home}},
	url = {https://humansystems.arc.nasa.gov/groups/TLX/},
	urldate = {2025-04-07},
	file = {PDF:C\:\\Users\\giand\\Zotero\\storage\\43IJ3JHC\\TLX_pappen_manual.pdf:application/pdf;TLX @ NASA Ames - Home:C\:\\Users\\giand\\Zotero\\storage\\RXRDS442\\TLX.html:text/html;TLXScale:C\:\\Users\\giand\\Zotero\\storage\\L8KQGGLC\\TLXScale.pdf:application/pdf},
}

@inproceedings{naumann_benchmarks_2010,
	address = {New York, NY, USA},
	series = {{MobileHCI} '10},
	title = {Benchmarks for intuitive interaction with mobile devices},
	isbn = {978-1-60558-835-3},
	url = {https://dl.acm.org/doi/10.1145/1851600.1851685},
	doi = {10.1145/1851600.1851685},
	abstract = {The QUESI (Questionnaire for the subjective consequences of intuitive use), a specific measure of the satisfaction of users interacting with a product, is presented. In addition, first benchmark values for mobile devices and applications are provided.},
	urldate = {2025-04-07},
	booktitle = {Proceedings of the 12th international conference on {Human} computer interaction with mobile devices and services},
	publisher = {Association for Computing Machinery},
	author = {Naumann, Anja and Hurtienne, Jörn},
	month = sep,
	year = {2010},
	keywords = {Important},
	pages = {401--402},
	file = {Full Text PDF:C\:\\Users\\giand\\Zotero\\storage\\LEE43PXL\\Naumann and Hurtienne - 2010 - Benchmarks for intuitive interaction with mobile devices.pdf:application/pdf},
}

@article{hurtienne_quesi_nodate,
	title = {{QUESI} - {Measuring} the {Subjective} {Consequences} of {Intuitive} {Use}},
	language = {en},
	author = {Hurtienne, Jörn and Naumann, Anja},
	file = {PDF:C\:\\Users\\giand\\Zotero\\storage\\W5THSUSH\\Hurtienne and Naumann - QUESI - Measuring the Subjective Consequences of Intuitive Use.pdf:application/pdf},
}


@article{hurtienne_quesiquestionnaire_2010,
	title = {{QUESI}—{A} questionnaire for measuring the subjective consequences of intuitive use},
	volume = {536},
	url = {https://joernhurtienne.com/Publications.html},
	journal = {Interdisciplinary College},
	author = {Hurtienne, Jörn and Naumann, Anja},
	year = {2010},
}


@incollection{ziegler_intui_2010,
	title = {{INTUI}. {Exploring} the {Facets} of {Intuitive} {Interaction}},
	isbn = {978-3-486-70408-2},
	url = {https://www.degruyter.com/document/doi/10.1524/9783486853483.251/html},
	urldate = {2025-04-07},
	booktitle = {Mensch \& {Computer} 2010},
	publisher = {OLDENBOURG WISSENSCHAFTSVERLAG},
	author = {Ullrich, Daniel and Diefenbach, Sarah},
	editor = {Ziegler, Jürgen and Schmidt, Albrecht},
	month = dec,
	year = {2010},
	doi = {10.1524/9783486853483.251},
	keywords = {Important},
	pages = {251--260},
	file = {PDF:C\:\\Users\\giand\\Zotero\\storage\\GYEUPFQE\\Ullrich and Diefenbach - 2010 - INTUI. Exploring the Facets of Intuitive Interaction.pdf:application/pdf},
}

@misc{noauthor_intuitve_nodate,
	title = {Intuitve {Interaction}},
	url = {http://intuitiveinteraction.net/method/#download},
	urldate = {2025-04-07},
	file = {Intuitve Interaction:C\:\\Users\\giand\\Zotero\\storage\\VD2RQ23E\\method.html:text/html;Questionnaire Template:C\:\\Users\\giand\\Zotero\\storage\\9QZQAB64\\Intuitve Interaction.pdf:application/pdf},
}

@inproceedings{sauro_comparison_2009,
	address = {New York, NY, USA},
	series = {{CHI} '09},
	title = {Comparison of three one-question, post-task usability questionnaires},
	isbn = {978-1-60558-246-7},
	url = {https://dl.acm.org/doi/10.1145/1518701.1518946},
	doi = {10.1145/1518701.1518946},
	abstract = {Post-task ratings of difficulty in a usability test have the potential to provide diagnostic information and be an additional measure of user satisfaction. But the ratings need to be reliable as well as easy to use for both respondents and researchers. Three one-question rating types were compared in a study with 26 participants who attempted the same five tasks with two software applications. The types were a Likert scale, a Usability Magnitude Estimation (UME) judgment, and a Subjective Mental Effort Question (SMEQ). All three types could distinguish between the applications with 26 participants, but the Likert and SMEQ types were more sensitive with small sample sizes. Both the Likert and SMEQ types were easy to learn and quick to execute. The online version of the SMEQ question was highly correlated with other measures and had equal sensitivity to the Likert question type.},
	urldate = {2025-04-07},
	booktitle = {Proceedings of the {SIGCHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Sauro, Jeff and Dumas, Joseph S.},
	month = apr,
	year = {2009},
	pages = {1599--1608},
	file = {Full Text PDF:C\:\\Users\\giand\\Zotero\\storage\\DC6PQSBB\\Sauro and Dumas - 2009 - Comparison of three one-question, post-task usability questionnaires.pdf:application/pdf},
}

@article{lewis_psychometric_1991,
	title = {Psychometric evaluation of an after-scenario questionnaire for computer usability studies: the {ASQ}},
	volume = {23},
	issn = {0736-6906},
	shorttitle = {Psychometric evaluation of an after-scenario questionnaire for computer usability studies},
	url = {https://dl.acm.org/doi/10.1145/122672.122692},
	doi = {10.1145/122672.122692},
	abstract = {A three-item after-scenario questionnaire was used in three related usability tests in different areas of the United States. The studies had eight scenarios in common. After participants finished a scenario, they completed the After-Scenario Questionnaire (the ASQ). A factor analysis of the responses to the ASQ items revealed that an eight-factor solution explained 94 percent of the variability of the 24 (eight scenarios by three items per scenario) items. The varimax-rotated factor pattern showed that these eight factors were clearly associated with the eight scenarios. The benefit of this research to system designers is that this three-item questionnaire has acceptable psychometric properties of reliability, sensitivity, and concurrent validity, and may be used with confidence in other, similar usability studies.},
	number = {1},
	urldate = {2025-04-07},
	journal = {SIGCHI Bull.},
	author = {Lewis, James R.},
	month = jan,
	year = {1991},
	pages = {78--81},
	file = {Full Text PDF:C\:\\Users\\giand\\Zotero\\storage\\GKR9DLGZ\\Lewis - 1991 - Psychometric evaluation of an after-scenario questionnaire for computer usability studies the ASQ.pdf:application/pdf},
}

@misc{minge_mecue_nodate,
	title = {{meCUE}},
	url = {https://mecue.de/english/home.html},
	language = {English},
	urldate = {2025-04-07},
	journal = {meCUE},
	author = {Minge, Michael and Riedel, Laura and Thüring, Manfred},
	file = {Home:C\:\\Users\\giand\\Zotero\\storage\\JBKMBL8I\\home.html:text/html;meCUE_EV:C\:\\Users\\giand\\Zotero\\storage\\SA6BBBER\\meCUE_EV.pdf:application/pdf;meCUE_PV:C\:\\Users\\giand\\Zotero\\storage\\UYG6Q4NY\\Home.pdf:application/pdf},
}

@incollection{minge_mecue_2017,
	title = {The {meCUE} {Questionnaire}: {A} {Modular} {Tool} for {Measuring} {User} {Experience}},
	isbn = {978-3-319-41685-4},
	shorttitle = {The {meCUE} {Questionnaire}},
	url = {https://link.springer.com/chapter/10.1007/978-3-319-41685-4_11},
	abstract = {Nowadays, a satisfying user experience is the goal of any user-centered design activity and the key to success for any technical device. User experience (UX) is a holistic concept that emphasizes the importance of subjective appraisals, feelings and motivational...},
	language = {en},
	urldate = {2025-07-24},
	booktitle = {Advances in {Ergonomics} {Modeling}, {Usability} \& {Special} {Populations}},
	publisher = {Springer, Cham},
	author = {Minge, Michael and Thüring, Manfred and Wagner, Ingmar and Kuhr, Carina V.},
	year = {2017},
	doi = {10.1007/978-3-319-41685-4\_11},
	note = {ISSN: 2194-5365},
	pages = {115--128},
	file = {Full Text PDF:C\:\\Users\\giand\\Zotero\\storage\\DF7CPXWQ\\Minge et al. - 2017 - The meCUE Questionnaire A Modular Tool for Measuring User Experience.pdf:application/pdf},
}

@book{boll_mensch_2013,
	title = {Mensch \& {Computer} 2013 - {Tagungsband}: 13. fachübergreifende {Konferenz} für interaktive und kooperative {Medien}},
	isbn = {978-3-486-77856-4},
	shorttitle = {Mensch \& {Computer} 2013 - {Tagungsband}},
	url = {https://www.degruyter.com/document/doi/10.1524/9783486781229/html},
	urldate = {2025-04-07},
	publisher = {OLDENBOURG WISSENSCHAFTSVERLAG},
	editor = {Boll, Susanne and Maaß, Susanne and Malaka, Rainer},
	month = aug,
	year = {2013},
	doi = {10.1524/9783486781229},
	file = {PDF:C\:\\Users\\giand\\Zotero\\storage\\DMQ7RFS8\\Boll et al. - 2013 - Mensch & Computer 2013 - Tagungsband 13. fachübergreifende Konferenz für interaktive und kooperativ.pdf:application/pdf},
}

@article{kujala_ux_2011,
	title = {{UX} {Curve}: {A} method for evaluating long-term user experience},
	volume = {23},
	issn = {0953-5438},
	shorttitle = {{UX} {Curve}},
	url = {https://academic.oup.com/iwc/article-lookup/doi/10.1016/j.intcom.2011.06.005},
	doi = {10.1016/j.intcom.2011.06.005},
	language = {en},
	number = {5},
	urldate = {2025-07-24},
	journal = {Interacting with Computers},
	author = {Kujala, Sari and Roto, Virpi and Väänänen-Vainio-Mattila, Kaisa and Karapanos, Evangelos and Sinnelä, Arto},
	month = sep,
	year = {2011},
	note = {Publisher: Oxford University Press (OUP)},
	pages = {473--483},
	file = {Accepted Version:C\:\\Users\\giand\\Zotero\\storage\\S2H3LBUH\\Kujala et al. - 2011 - UX Curve A method for evaluating long-term user experience.pdf:application/pdf;PDF:C\:\\Users\\giand\\Zotero\\storage\\M4M5NP46\\UX Curve A method for evaluating long-term user experience  Interacting with Computers  Oxford Ac.pdf:application/pdf},
}

@misc{budiu_between-subjects_2023,
	title = {Between-{Subjects} vs. {Within}-{Subjects} {Study} {Design}},
	url = {https://www.nngroup.com/articles/between-within-subjects/},
	abstract = {In user research, between-groups designs reduce learning effects; repeated-measures designs require fewer participants and minimize the random noise.},
	language = {en},
	note = {Accessed on 24.07.2025},
	journal = {Nielsen Norman Group},
	author = {Budiu, Raluca},
	month = jul,
	year = {2023},
	file = {Snapshot:C\:\\Users\\giand\\Zotero\\storage\\4QEBNJKD\\between-within-subjects.html:text/html},
}

@misc{kendrick_formative_2019,
	title = {Formative vs. {Summative} {Evaluations}},
	url = {https://www.nngroup.com/articles/formative-vs-summative-evaluations/},
	abstract = {Formative evaluations are used in an iterative process to make improvements before production. Summative evaluations are used to evaluate a shipped product in comparison to a benchmark.},
	language = {en},
	note = {Accessed on 24.07.2025},
	journal = {Nielsen Norman Group},
	author = {Kendrick, Alita},
	month = jul,
	year = {2019},
	file = {Snapshot:C\:\\Users\\giand\\Zotero\\storage\\DMHBDNLV\\formative-vs-summative-evaluations.html:text/html},
}

@misc{krause_affinity_2024,
	title = {Affinity {Diagramming}: {Collaboratively} {Sort} {UX} {Findings} \& {Design} {Ideas}},
	shorttitle = {Affinity {Diagramming}},
	url = {https://www.nngroup.com/articles/affinity-diagram/},
	abstract = {Use affinity diagramming to cluster and organize research findings or to sort design ideas in ideation workshops.},
	language = {en},
	note = {Accessed on 25.07.2025},
	journal = {Nielsen Norman Group},
	author = {Krause, Rachel and Pernice, Kara},
	month = apr,
	year = {2024},
	file = {Snapshot:C\:\\Users\\giand\\Zotero\\storage\\BRCBHLI3\\affinity-diagram.html:text/html},
}

@misc{azarova_hawthorne_2023,
	title = {The {Hawthorne} {Effect} or {Observer} {Bias} in {User} {Research}},
	url = {https://www.nngroup.com/articles/hawthorne-effect-observer-bias-user-research/},
	abstract = {Observer bias and Hawthorne effect in user research. Mitigation strategies for balancing observer effect in field studies, diary studies, usability testing, and surveys.},
	language = {en},
	note = {Accessed on 31.07.2025},
	journal = {Nielsen Norman Group},
	author = {Azarova, Mayya},
	month = may,
	year = {2023},
	file = {Snapshot:C\:\\Users\\giand\\Zotero\\storage\\F384XIDQ\\hawthorne-effect-observer-bias-user-research.html:text/html},
}

@article{jones_courtesy_1993,
	title = {The courtesy bias in {South}-{East} {Asian} surveys},
	journal = {Social research in developing countries},
	author = {Jones, Emily L.},
	year = {1993},
	note = {Publisher: UCL Press London},
	pages = {253--9},
}

@article{macefield_usability_2007,
	title = {Usability studies and the {Hawthorne} effect},
	volume = {2},
	abstract = {This paper provides a brief review of the Hawthorne effect, a discussion of how this effect relates to usability studies, and help for practitioners in defending their studies against criticisms made on the basis of this effect.},
	number = {3},
	journal = {J. Usability Studies},
	author = {Macefield, Ritch},
	month = may,
	year = {2007},
	note = {Place: Bloomingdale, IL
Publisher: Usability Professionals' Association},
	keywords = {experimenter effects, Hawthorne effect, usability study},
	pages = {145--154},
}

@article{natesan_cognitive_2016,
	title = {Cognitive {Bias} in {Usability} {Testing}},
	volume = {5},
	issn = {2327-8595},
	url = {https://doi.org/10.1177/2327857916051015},
	doi = {10.1177/2327857916051015},
	abstract = {Cognitive bias is the tendency to subconsciously change ones actions or thought process based on someone else’s comments or behavior. It is important to consider cognitive bias when performing a usability study because it can significantly alter or impair the validity of the results. While cognitive bias cannot always be entirely eliminated, identifying key cognitive biases to which usability study results are particularly susceptible is the first step to mitigating them. Once experimenters are alert to these subtle traps, they can consider approaches that sidestep the biases and greatly improve the accuracy and overall effectiveness of a usability study.},
	language = {EN},
	number = {1},
	urldate = {2025-07-31},
	journal = {Proceedings of the International Symposium on Human Factors and Ergonomics in Health Care},
	author = {Natesan, Divya and Walker, Morgan and Clark, Shannon},
	month = jun,
	year = {2016},
	note = {Publisher: SAGE Publications},
	pages = {86--88},
}

@misc{bmw_neueklasse_2023,
	title = {Digital, elektrisch, zirkulär: Auf dem Weg zur Neuen Klasse.},
	shorttitle = {Digital, elektrisch, zirkulär},
	url = {https://www.bmwgroup.com/de/news/allgemein/2023/bmwvisionneueklasse.html},
	note = {Accesed on 02.08.2025},
	author = {{BMW Group}},
	month = sep,
	year = {2023},
	file = {Snapshot:/Users/sofiaheurich/Zotero/storage/STYMXTIC/bmwvisionneueklasse.html:text/html},
}