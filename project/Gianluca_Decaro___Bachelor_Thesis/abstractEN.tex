%----------Zusammenfassung Englisch/Abstract----------------------------------------------------------------
\addsec{Abstract}
% Here goes the English Abstract... 
% Abstract
% As automated vehicles transform car interiors into versatile living spaces, current human-machine interfaces, predominantly touchscreens, are becoming inadequate due to poor ergonomics, a lack of hedonic appeal, and their potential to induce motion sickness. Interactive electronic textiles (e-textiles) present a promising alternative, offering seamless integration and a richer tactile experience. However, their novelty poses a significant challenge: designing them to be intuitively understood and used by untrained, first-time users.

% This thesis investigates how different levels of feedforward cues can support intuitive yet engaging interactions with a novel HMI paradigm combining a shape-shifting e-textile interface on the center armrest with a windshield display for visual output. Following a human-centered design process, a high-fidelity prototype was developed and iteratively refined through a qualitative pre-study (n=5). A subsequent summative, between-subjects user study (n=30) quantitatively and qualitatively evaluated the performance, usability, and user experience of three distinct feedforward conditions: Inherent Cues (relying solely on the physical form), Augmented Light Cues (dynamic light projections on the textile), and Augmented Text Cues (explicit instructions on the windshield display).

% The results demonstrate that augmented feedforward is critical for the usability of a complex textile interface. Relying on inherent physical cues alone resulted in poor initial performance, significant usability issues, and a negative emotional response. In contrast, the Augmented Light Cues condition proved to be the superior solution, leading to significantly higher task success rates, fewer errors, and a more intuitive, usable, and emotionally positive user experience compared to both other conditions.

% These findings imply that for novel textile HMIs, the optimal user experience is achieved not by relying on physical form alone or explicit textual instruction, but through a balanced approach that enhances inherent physical properties with seamlessly integrated, non-verbal guidance. This work provides evidence for the high potential of the proposed HMI paradigm to create more ergonomic, safer, and hedonically rich in-vehicle experiences and offers concrete design recommendations for developing intuitive textile interfaces for future automated vehicles.


% ----


% As automated driving transforms vehicles into multifunctional living spaces, the need for new human-machine interfaces that are intuitive, engaging, and aesthetically aligned with a comfortable interior becomes paramount. Current touchscreen-dominated paradigms are ill-suited for this shift, creating ergonomic challenges and failing to provide a hedonically rich experience. Interactive electronic textiles (e-textiles) combined with windshield displays (WSDs) present a promising alternative, yet their novelty creates a significant learnability challenge for first-time users. This thesis addresses this gap by investigating how different levels of feedforward—cues that guide users before an action—can support intuitive, "walk-up-and-use" interactions with a non-wearable textile interface in an automotive context. Following a human-centered design process, a high-fidelity, shape-shifting textile prototype was developed for the vehicle's armrest, accompanied by a WSD. A between-subjects user study (n=30) was conducted to evaluate three feedforward conditions: a baseline with only the interface's inherent physical cues, a version augmented with abstract light projections on the textile, and a version with explicit text cues on the WSD. The results show that while a steep initial learning curve existed across all conditions, the augmented light cues significantly improved objective performance, perceived usability, and overall user experience, eliciting the most positive emotional response. Relying on inherent physical cues alone proved insufficient, leading to usability issues and user frustration, while remote text cues were less effective than integrated light due to cognitive load and discoverability issues. These findings demonstrate that for novel textile systems, integrated, non-verbal augmented feedforward is a prerequisite for creating a positive, intuitive, and engaging user experience. This work contributes empirically-grounded design recommendations, highlighting that the optimal approach balances inherent physical affordances with a seamlessly integrated layer of augmented guidance, thereby unlocking the full potential of textile interfaces for future vehicle interiors.


% ----


% As vehicle automation advances, the role of drivers shifts toward passive passengers, transforming car interiors into multifunctional living spaces. Traditional touchscreen-based interfaces, while widespread, are ill-suited for this new paradigm due to their reliance on visual attention and lack of tactile engagement. This thesis investigates how interactive, non-wearable textile surfaces, combined with windshield displays, can provide intuitive and emotionally engaging interaction experiences for passengers in automated vehicles. To explore this, a two-part study was conducted. A co-design pre-study (n=6) identified intuitive gestures and feedforward cues, which informed the development of a multimodal prototype combining tactile, abstract visual, and explicit textual feedforward. In the main user study (n=30), participants interacted with one of three interface versions, each representing a different level of feedforward. Quantitative data (e.g., success rates, SUS, UEQ, QUESI, meCUE) and qualitative feedback (e.g., interviews, observations) were collected to evaluate intuitiveness, user experience, and emotional engagement. Results show that while inherent feedforward supports intuitive use, combining it with abstract or explicit augmented cues significantly enhances user understanding and enjoyment. Participants favored playful, tactile elements and appreciated guidance that maintained a sense of autonomy. However, overly explicit cues occasionally disrupted the immersive experience. The findings suggest that carefully layered feedforward can balance usability and delight, making textile interfaces a promising HMI paradigm for future AVs. Limitations include the lab setting and use of Wizard-of-Oz techniques. Future work should explore long-term use and real-world integration to further assess feasibility and acceptance.


% ---- 


% As automated vehicles (AVs) transform car interiors into multifunctional living spaces, the need arises for novel human-machine interfaces (HMIs) that move beyond the ergonomic and experiential limitations of today's dominant touchscreen controls. This thesis explores how interactive e-textiles, combined with a windshield display (WSD), can offer a more intuitive, engaging, and seamlessly integrated alternative for passengers. The central research question investigates how different levels of feedforward can guide first-time, untrained users to interact with such a novel interface. Following a Quad-Diamond design process, a high-fidelity, shape-shifting textile prototype was developed and evaluated in a controlled lab study using a Wizard of Oz methodology. A between-subjects user study (N=30) compared three feedforward conditions: a baseline with only the interface's inherent physical cues, a version with augmented, on-surface light cues, and a version with augmented, textual cues on the WSD. The results from quantitative analysis of performance data and standardized questionnaires (SUS, UEQ, QUESI, meCUE), along with qualitative analysis of user interviews, consistently demonstrated that augmented feedforward is critical for the usability and user experience of a novel textile HMI. While inherent physical cues alone resulted in poor performance and a frustrating user experience, the condition with augmented light cues significantly outperformed the others, yielding the highest task success rates, best usability scores, and a more intuitive and emotionally positive experience. The findings imply that for novel textile interfaces to be successful in "walk-up-and-use" scenarios, designers must provide robust guidance to overcome the steep initial learning curve. Integrated, non-verbal cues, like projected light, are significantly more effective than remote, text-based instructions at supporting this learning process by clarifying affordances and aiding discoverability. While the study is limited by its lab setting and specific participant demographics, this work demonstrates the high potential of the textile HMI paradigm and provides a set of actionable design recommendations, highlighting the importance of balancing inherent physical affordances with seamlessly integrated augmented guidance to create interfaces that are not only functional but also hedonically rich and intuitive from the very first interaction.


% -------
% As vehicle automation advances, the role of drivers shifts toward passive passengers, transforming car interiors into multifunctional living spaces.
% As automated driving transforms vehicle interiors into multifunctional living spaces, the need for new human-machine interfaces that support a wide range of non-driving related activities, while being unobtrusive and hedonically rich, becomes critical. Current touchscreen-dominant paradigms suffer from poor ergonomics, can induce motion sickness, and lack the aesthetic qualities suited for a comfortable environment. Interactive textiles, combined with windshield displays, offer a promising alternative by enabling seamless, tactile, and low-attention interactions. However, their novelty presents a significant learnability challenge for first-time users. This thesis addresses this gap by investigating how different levels of feedforward can support intuitive, "walk-up-and-use" interactions with a non-wearable textile interface designed for non-driving-related activities in automated vehicles. Following a human-centered design process, a high-fidelity, shape-shifting textile interface on a central armrest was prototyped in conjunction with a windshield display. A between-subjects user study (n=30) evaluated three feedforward conditions using a Wizard of Oz methodology: (1) Inherent Cues from the interface's physical form, (2) Augmented Light Cues projected directly onto the textile, and (3) Augmented Text Cues displayed on the WSD. Data was collected through performance metrics and standardized questionnaires (SUS, UEQ, QUESI, meCUE), supplemented by qualitative interviews. The results demonstrate that while the novel interface has a steep initial learning curve, augmented feedforward is crucial for usability. The Light Cues condition significantly outperformed the others, yielding higher success rates, superior perceived usability and intuitiveness, and a more positive emotional response. In contrast, relying on inherent cues alone led to significant usability issues and user frustration. These findings imply that for complex, novel textile systems, integrated, non-verbal guidance is superior to remote textual instructions or physical cues alone, as it effectively bridges the learnability gap by aiding discoverability and supporting users' mental models. This work concludes that the proposed HMI paradigm holds high potential for user acceptance due to its perceived ergonomic and hedonic benefits over conventional screens, but its success hinges on implementing robust, integrated feedforward to ensure a positive and intuitive initial user experience. Future work should validate these findings in more realistic, dynamic environments and with more diverse user demographics.

% -------

% As automated vehicles (AVs) transform vehicle interiors into multifunctional living spaces, current in-vehicle human-machine interfaces, dominated by touchscreens, are becoming inadequate due to poor ergonomics, high visual demand, and a lack of hedonic quality. Interactive e-textiles, paired with windshield displays, present a promising alternative for creating more intuitive and engaging passenger experiences. However, the novelty of e-textiles creates a significant learnability gap for first-time users. This thesis investigates how different levels of feedforward can support an intuitive "walk-up-and-use" interaction with a novel, non-wearable textile interface for non-driving-related activities in AVs. Following a human-centered design process, a high-fidelity prototype featuring a shape-shifting textile surface on the central armrest and a corresponding windshield display interface was developed and iteratively refined through a qualitative pre-study ($N=5$). A subsequent summative user study with $N=30$ participants employed a between-subjects design to evaluate three feedforward conditions: a baseline with only inherent physical cues, a condition with augmented light cues projected onto the textile, and a condition with augmented text cues on the windshield display. The results revealed that while the core interface possesses strong inherent hedonic qualities, augmented feedforward is critical for usability and intuitiveness. The seamlessly integrated light cues significantly outperformed the other conditions, leading to higher task success, lower error rates, superior perceived usability and intuitiveness, and a more positive emotional experience. The findings imply that for novel textile systems, designers must provide robust, integrated, non-verbal guidance to help users overcome a steep initial learning curve. The study demonstrates the high potential of the textile interface paradigm to offer a more ergonomic, safer, and engaging experience than conventional touchscreens, with the proposed Feedforward Matrix serving as a valuable tool for designers to achieve an optimal balance of guidance for future in-vehicle HMIs.

% ----

As automated driving transforms vehicle interiors into multifunctional living spaces, the need for new human-machine interfaces that support a wide range of non-driving related activities, while remaining unobtrusive and hedonically rich, becomes critical. Current touchscreen-dominant paradigms suffer from poor ergonomics, high visual demand, and lack the aesthetic qualities suited for a comfortable environment. Interactive textiles, combined with windshield displays, offer a promising alternative by enabling seamless, tactile, and low-attention interactions. However, their novelty presents a significant learnability challenge for first-time users. This thesis addresses this gap by investigating how different levels of feedforward can support intuitive  interactions with a non-wearable textile interface designed for non-driving-related activities in automated vehicles.
Following a human-centered design process, a high-fidelity prototype featuring a shape-shifting textile surface on the central armrest and a corresponding windshield display interface were developed and iteratively refined through a qualitative pre-study ($N=5$). A subsequent summative user study with $N=30$ participants employed a between-subjects design to evaluate three feedforward conditions using a Wizard of Oz methodology: (1) Inherent Cues from the interface's physical form, (2) abstract Augmented Light Cues projected directly onto the textile surface, and (3) explicit Augmented Text Cues displayed on the windshield display.
The results revealed that while the core interface possesses strong inherent hedonic qualities, augmented feedforward is critical for achieving a usable and intuitive experience. In objective performance, the seamlessly integrated light cues led to significantly higher task success rates and fewer errors compared to both text and inherent cues. In subjective ratings of usability, intuitiveness, user experience, and emotional response, both augmented conditions performed closely and were often rated significantly better than inherent cues alone, with no significant statistical difference between them. Despite this, a consistent trend favoring the light cues over the text cues was observed across all measures. 
The findings imply that for novel textile systems, designers must provide robust guidance, balancing affordance-clarifying and function-revealing cues that bridge the learnability gap, to help users overcome a steep initial learning curve. Integrated, non-verbal light cues represent an optimal "sweet spot", proving most effective in objective performance while demonstrating a consistent subjective advantage. This work concludes that the proposed \gls{HMI} paradigm holds high potential for user acceptance due to its perceived ergonomic and hedonic benefits over conventional screens, but its success hinges on implementing robust, integrated feedforward to ensure a positive and intuitive initial user experience. Future work should validate these findings in more realistic, dynamic environments and with more diverse user demographics.


